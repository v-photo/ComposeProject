"""
GPU-Accelerated Block Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æ¨¡å—
GPU-Accelerated Block Kriging Ã— PINN Coupling Reconstruction Tools

åŠŸèƒ½æ¦‚è¿° (Functionality Overview):
- é€šç”¨å·¥å…· (Common Tools): æ•°æ®æ ‡å‡†åŒ–ã€è¯¯å·®ç»Ÿè®¡ã€å¯è§†åŒ–
- æ–¹æ¡ˆ1ä¸“ç”¨ (Mode 1 Specific): PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ
- æ–¹æ¡ˆ2ä¸“ç”¨ (Mode 2 Specific): Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
from typing import Dict, List, Tuple, Optional, Union, Any
import warnings
import time
from dataclasses import dataclass
from pathlib import Path

# å°è¯•å¯¼å…¥æ‰€éœ€çš„ç¬¬ä¸‰æ–¹åº“
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    warnings.warn("PyTorchä¸å¯ç”¨ï¼Œéƒ¨åˆ†GPUåŠ é€ŸåŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False
    warnings.warn("CuPyä¸å¯ç”¨ï¼ŒGPUåŠ é€ŸåŠŸèƒ½å°†è¢«ç¦ç”¨")

# å¯¼å…¥ç°æœ‰æ¨¡å— - éœ€è¦ç¡®ä¿è·¯å¾„æ­£ç¡®
# Import existing modules - ensure correct paths
current_dir = Path(__file__).parent
project_root = current_dir.parent

# æ·»åŠ Krigingå’ŒPINNæ¨¡å—è·¯å¾„
sys.path.insert(0, str(project_root / "Kriging"))
sys.path.insert(0, str(project_root / "PINN"))

try:
    # å¯¼å…¥Krigingæ¨¡å—
    from myKriging import training as kriging_training, testing as kriging_testing
    from myPyKriging3D import MyOrdinaryKriging3D
    KRIGING_AVAILABLE = True
    print("âœ… Krigingæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    KRIGING_AVAILABLE = False
    warnings.warn(f"Krigingæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

try:
    # å¯¼å…¥PINNæ¨¡å—
    from tools import (SimulationConfig, RadiationDataProcessor, DataLoader, 
                      PINNTrainer, ResultAnalyzer, Visualizer)
    PINN_AVAILABLE = True
    print("âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    PINN_AVAILABLE = False
    warnings.warn(f"PINNæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# ==================== å…¨å±€å¸¸é‡ä¸é…ç½® ====================
# Global Constants and Configuration

EPSILON = 1e-30  # æ•°å€¼ç¨³å®šæ€§å¸¸æ•°
DEFAULT_METRICS = ['MAE', 'RMSE', 'MAPE', 'R2']

@dataclass
class ComposeConfig:
    """
    è€¦åˆç³»ç»Ÿå…¨å±€é…ç½®ç±»
    Global configuration for the coupling system
    """
    # é€šç”¨é…ç½® Common settings
    gpu_enabled: bool = True
    verbose: bool = True
    random_seed: int = 42
    
    # Krigingé…ç½® Kriging settings
    kriging_variogram_model: str = "linear"
    kriging_block_size: int = 10000
    kriging_enable_uncertainty: bool = True  # æ³¨æ„ï¼šå½“å‰å®ç°å¯èƒ½ä¸å®Œå…¨æ”¯æŒ
    
    # PINNé…ç½® PINN settings
    pinn_epochs: int = 5000
    pinn_learning_rate: float = 1e-3
    pinn_network_layers: List[int] = None
    
    # è€¦åˆé…ç½® Coupling settings
    fusion_weight: float = 0.5  # æ–¹æ¡ˆ1ä¸­çš„æƒé‡Ï‰
    roi_detection_strategy: str = 'high_density'  # æ–¹æ¡ˆ2ä¸­çš„ROIæ£€æµ‹ç­–ç•¥
    sample_augment_factor: float = 2.0  # æ–¹æ¡ˆ2ä¸­çš„æ ·æœ¬æ‰©å……å€æ•°
    
    def __post_init__(self):
        if self.pinn_network_layers is None:
            self.pinn_network_layers = [50, 50, 50, 50]

# ==================== é€šç”¨å·¥å…· (Common Tools) ====================

@dataclass
class FieldTensor:
    """
    æ ‡å‡†åŒ–çš„åœºæ•°æ®ç»“æ„
    Standardized field data structure
    """
    coordinates: np.ndarray  # (N, 3) - xyzåæ ‡
    values: np.ndarray      # (N,) - åœºå€¼
    uncertainties: Optional[np.ndarray] = None  # (N,) - ä¸ç¡®å®šåº¦
    metadata: Optional[Dict[str, Any]] = None   # å…ƒæ•°æ®
    
    def __post_init__(self):
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§ Validate data consistency"""
        if self.coordinates.shape[0] != self.values.shape[0]:
            raise ValueError("åæ ‡å’Œæ•°å€¼çš„æ•°é‡ä¸åŒ¹é…")
        if self.coordinates.shape[1] != 3:
            raise ValueError("åæ ‡å¿…é¡»æ˜¯3ç»´ (x, y, z)")
        if self.uncertainties is not None and self.uncertainties.shape[0] != self.values.shape[0]:
            raise ValueError("ä¸ç¡®å®šåº¦å’Œæ•°å€¼çš„æ•°é‡ä¸åŒ¹é…")

@dataclass 
class ProbeSet:
    """
    æ ‡å‡†åŒ–çš„æµ‹ç‚¹æ•°æ®ç»“æ„
    Standardized probe data structure
    """
    positions: np.ndarray   # (N, 3) - æµ‹ç‚¹åæ ‡
    measurements: np.ndarray # (N,) - æµ‹é‡å€¼
    weights: Optional[np.ndarray] = None  # (N,) - æƒé‡
    metadata: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        if self.positions.shape[0] != self.measurements.shape[0]:
            raise ValueError("æµ‹ç‚¹ä½ç½®å’Œæµ‹é‡å€¼çš„æ•°é‡ä¸åŒ¹é…")
        if self.positions.shape[1] != 3:
            raise ValueError("æµ‹ç‚¹ä½ç½®å¿…é¡»æ˜¯3ç»´ (x, y, z)")
        if self.weights is not None and self.weights.shape[0] != self.measurements.shape[0]:
            raise ValueError("æƒé‡å’Œæµ‹é‡å€¼çš„æ•°é‡ä¸åŒ¹é…")

class DataNormalizer:
    """
    æ•°æ®å½’ä¸€åŒ–å·¥å…·
    Data normalization utilities
    """
    
    @staticmethod
    def normalize_tensor_to_grid(field_tensor: FieldTensor, 
                               grid_shape: Tuple[int, int, int],
                               world_bounds: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        å°†å¼ é‡æ•°æ®è½¬æ¢ä¸ºç½‘æ ¼æ ¼å¼
        Convert tensor data to grid format
        
        Args:
            field_tensor: è¾“å…¥çš„åœºæ•°æ®å¼ é‡
            grid_shape: ç›®æ ‡ç½‘æ ¼å½¢çŠ¶ (nx, ny, nz)
            world_bounds: ä¸–ç•Œåæ ‡è¾¹ç•Œ {'min': [x,y,z], 'max': [x,y,z]}
            
        Returns:
            DictåŒ…å« 'grid', 'coordinates', 'bounds'
        """
        coordinates = field_tensor.coordinates
        values = field_tensor.values
        
        world_min = world_bounds['min']
        world_max = world_bounds['max']
        
        # åˆ›å»ºè§„åˆ™ç½‘æ ¼
        x_grid = np.linspace(world_min[0], world_max[0], grid_shape[0])
        y_grid = np.linspace(world_min[1], world_max[1], grid_shape[1])  
        z_grid = np.linspace(world_min[2], world_max[2], grid_shape[2])
        
        X, Y, Z = np.meshgrid(x_grid, y_grid, z_grid, indexing='ij')
        grid_coords = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)
        
        # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼å°†ä¸è§„åˆ™æ•°æ®æ˜ å°„åˆ°ç½‘æ ¼
        from scipy.spatial import cKDTree
        tree = cKDTree(coordinates)
        distances, indices = tree.query(grid_coords)
        
        grid_values = values[indices].reshape(grid_shape)
        
        return {
            'grid': grid_values,
            'coordinates': grid_coords.reshape((*grid_shape, 3)),
            'bounds': world_bounds,
            'interpolation_distances': distances.reshape(grid_shape)
        }
    
    @staticmethod
    def robust_normalize(data: np.ndarray, 
                        quantile_range: Tuple[float, float] = (0.01, 0.99)) -> Tuple[np.ndarray, Dict]:
        """
        é²æ£’å½’ä¸€åŒ– (åŸºäºåˆ†ä½æ•°)
        Robust normalization based on quantiles
        """
        q_low, q_high = quantile_range
        low_val = np.quantile(data, q_low)
        high_val = np.quantile(data, q_high)
        
        normalized = np.clip((data - low_val) / (high_val - low_val + EPSILON), 0, 1)
        
        normalization_info = {
            'method': 'robust',
            'low_val': low_val,
            'high_val': high_val,
            'quantile_range': quantile_range
        }
        
        return normalized, normalization_info

class MetricsCalculator:
    """
    è¯¯å·®ç»Ÿè®¡è®¡ç®—å™¨
    Error metrics calculator
    """
    
    @staticmethod
    def compute_metrics(true_values: np.ndarray, 
                       pred_values: np.ndarray,
                       metrics: List[str] = None) -> Dict[str, float]:
        """
        è®¡ç®—é¢„æµ‹è¯¯å·®æŒ‡æ ‡
        Compute prediction error metrics
        
        Args:
            true_values: çœŸå®å€¼
            pred_values: é¢„æµ‹å€¼  
            metrics: è¦è®¡ç®—çš„æŒ‡æ ‡åˆ—è¡¨
            
        Returns:
            Dict[metric_name, metric_value]
        """
        if metrics is None:
            metrics = DEFAULT_METRICS
            
        # ç¡®ä¿è¾“å…¥ä¸ºnumpyæ•°ç»„
        true_values = np.asarray(true_values).flatten()
        pred_values = np.asarray(pred_values).flatten()
        
        if len(true_values) != len(pred_values):
            raise ValueError("çœŸå®å€¼å’Œé¢„æµ‹å€¼çš„é•¿åº¦ä¸åŒ¹é…")
        
        results = {}
        
        # è®¡ç®—æ®‹å·®
        residuals = pred_values - true_values
        
        # å¹³å‡ç»å¯¹è¯¯å·® Mean Absolute Error
        if 'MAE' in metrics:
            results['MAE'] = np.mean(np.abs(residuals))
        
        # å‡æ–¹æ ¹è¯¯å·® Root Mean Square Error  
        if 'RMSE' in metrics:
            results['RMSE'] = np.sqrt(np.mean(residuals**2))
        
        # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® Mean Absolute Percentage Error
        # åªåœ¨éé›¶çœŸå€¼å¤„è®¡ç®—
        if 'MAPE' in metrics:
            nonzero_mask = np.abs(true_values) > EPSILON
            if np.any(nonzero_mask):
                mape_values = np.abs(residuals[nonzero_mask] / true_values[nonzero_mask])
                results['MAPE'] = np.mean(mape_values) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            else:
                results['MAPE'] = float('inf')
        
        # å†³å®šç³»æ•° R-squared
        if 'R2' in metrics:
            ss_res = np.sum(residuals**2)
            ss_tot = np.sum((true_values - np.mean(true_values))**2)
            results['R2'] = 1 - (ss_res / (ss_tot + EPSILON))
        
        # ç›¸å…³ç³»æ•° Pearson correlation
        if 'CORR' in metrics:
            correlation_matrix = np.corrcoef(true_values, pred_values)
            results['CORR'] = correlation_matrix[0, 1] if not np.isnan(correlation_matrix[0, 1]) else 0.0
        
        return results
    
    @staticmethod
    def compute_relative_error_stats(true_values: np.ndarray, 
                                   pred_values: np.ndarray,
                                   percentiles: List[float] = None) -> Dict[str, float]:
        """
        è®¡ç®—ç›¸å¯¹è¯¯å·®çš„ç»Ÿè®¡åˆ†å¸ƒ
        Compute relative error statistics
        """
        if percentiles is None:
            percentiles = [10, 25, 50, 75, 90, 95, 99]
        
        # åªåœ¨éé›¶çœŸå€¼å¤„è®¡ç®—ç›¸å¯¹è¯¯å·®
        nonzero_mask = np.abs(true_values) > EPSILON
        if not np.any(nonzero_mask):
            return {f'P{p}': float('inf') for p in percentiles}
        
        relative_errors = np.abs((pred_values[nonzero_mask] - true_values[nonzero_mask]) 
                                / true_values[nonzero_mask]) * 100
        
        stats = {}
        for p in percentiles:
            stats[f'P{p}'] = np.percentile(relative_errors, p)
        
        stats['mean_rel_error'] = np.mean(relative_errors)
        stats['std_rel_error'] = np.std(relative_errors)
        
        return stats

class VisualizationTools:
    """
    å¯è§†åŒ–å·¥å…·é›†
    Visualization utilities
    """
    
    @staticmethod
    def plot_comparison_2d_slice(true_field: np.ndarray,
                               pred_field: np.ndarray, 
                               slice_axis: int = 2,
                               slice_idx: Optional[int] = None,
                               uncertainty_field: Optional[np.ndarray] = None,
                               save_path: Optional[str] = None,
                               title_prefix: str = "") -> plt.Figure:
        """
        ç»˜åˆ¶2Dåˆ‡ç‰‡å¯¹æ¯”å›¾
        Plot 2D slice comparison
        
        Args:
            true_field: çœŸå®åœº (nx, ny, nz)
            pred_field: é¢„æµ‹åœº (nx, ny, nz)
            slice_axis: åˆ‡ç‰‡è½´ (0=x, 1=y, 2=z)
            slice_idx: åˆ‡ç‰‡ç´¢å¼•ï¼ŒNoneåˆ™ä½¿ç”¨ä¸­é—´åˆ‡ç‰‡
            uncertainty_field: ä¸ç¡®å®šåº¦åœºï¼ˆå¯é€‰ï¼‰
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title_prefix: æ ‡é¢˜å‰ç¼€
            
        Returns:
            matplotlib Figureå¯¹è±¡
        """
        if slice_idx is None:
            slice_idx = true_field.shape[slice_axis] // 2
        
        # æå–åˆ‡ç‰‡
        if slice_axis == 0:
            true_slice = true_field[slice_idx, :, :]
            pred_slice = pred_field[slice_idx, :, :]
            uncertainty_slice = uncertainty_field[slice_idx, :, :] if uncertainty_field is not None else None
        elif slice_axis == 1:
            true_slice = true_field[:, slice_idx, :]
            pred_slice = pred_field[:, slice_idx, :]
            uncertainty_slice = uncertainty_field[:, slice_idx, :] if uncertainty_field is not None else None
        else:  # slice_axis == 2
            true_slice = true_field[:, :, slice_idx]
            pred_slice = pred_field[:, :, slice_idx]
            uncertainty_slice = uncertainty_field[:, :, slice_idx] if uncertainty_field is not None else None
        
        # åˆ›å»ºå­å›¾å¸ƒå±€
        n_plots = 3 if uncertainty_slice is not None else 2
        fig, axes = plt.subplots(1, n_plots, figsize=(5*n_plots, 4))
        if n_plots == 2:
            axes = [axes[0], axes[1]]
        
        # ç»˜åˆ¶çœŸå®åœº
        im1 = axes[0].imshow(true_slice.T, origin='lower', aspect='auto', 
                           norm=LogNorm(vmin=max(true_slice.min(), EPSILON), vmax=true_slice.max()))
        axes[0].set_title(f'{title_prefix}çœŸå®åœº (è½´{slice_axis}, åˆ‡ç‰‡{slice_idx})')
        axes[0].set_xlabel('X' if slice_axis != 0 else ('Y' if slice_axis == 2 else 'Z'))
        axes[0].set_ylabel('Y' if slice_axis != 1 else ('X' if slice_axis == 2 else 'Z'))
        plt.colorbar(im1, ax=axes[0])
        
        # ç»˜åˆ¶é¢„æµ‹åœº
        im2 = axes[1].imshow(pred_slice.T, origin='lower', aspect='auto',
                           norm=LogNorm(vmin=max(pred_slice.min(), EPSILON), vmax=pred_slice.max()))
        axes[1].set_title(f'{title_prefix}é¢„æµ‹åœº')
        axes[1].set_xlabel('X' if slice_axis != 0 else ('Y' if slice_axis == 2 else 'Z'))
        axes[1].set_ylabel('Y' if slice_axis != 1 else ('X' if slice_axis == 2 else 'Z'))
        plt.colorbar(im2, ax=axes[1])
        
        # ç»˜åˆ¶ä¸ç¡®å®šåº¦åœºï¼ˆå¦‚æœæä¾›ï¼‰
        if uncertainty_slice is not None:
            im3 = axes[2].imshow(uncertainty_slice.T, origin='lower', aspect='auto')
            axes[2].set_title(f'{title_prefix}ä¸ç¡®å®šåº¦')
            axes[2].set_xlabel('X' if slice_axis != 0 else ('Y' if slice_axis == 2 else 'Z'))
            axes[2].set_ylabel('Y' if slice_axis != 1 else ('X' if slice_axis == 2 else 'Z'))
            plt.colorbar(im3, ax=axes[2])
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            
        return fig
    
    @staticmethod
    def plot_residual_analysis(residuals: np.ndarray,
                             coordinates: Optional[np.ndarray] = None,
                             save_path: Optional[str] = None) -> plt.Figure:
        """
        ç»˜åˆ¶æ®‹å·®åˆ†æå›¾
        Plot residual analysis
        """
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # æ®‹å·®ç›´æ–¹å›¾
        axes[0, 0].hist(residuals, bins=50, alpha=0.7, edgecolor='black')
        axes[0, 0].set_title('æ®‹å·®åˆ†å¸ƒç›´æ–¹å›¾')
        axes[0, 0].set_xlabel('æ®‹å·®å€¼')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].grid(True, alpha=0.3)
        
        # Q-Qå›¾æ£€éªŒæ­£æ€æ€§
        from scipy import stats
        stats.probplot(residuals, dist="norm", plot=axes[0, 1])
        axes[0, 1].set_title('æ®‹å·®æ­£æ€æ€§Q-Qå›¾')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ®‹å·®vsç´¢å¼•ï¼ˆæ—¶é—´åºåˆ—å›¾ï¼‰
        axes[1, 0].plot(residuals, alpha=0.7)
        axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.7)
        axes[1, 0].set_title('æ®‹å·®åºåˆ—å›¾')
        axes[1, 0].set_xlabel('æ ·æœ¬ç´¢å¼•')
        axes[1, 0].set_ylabel('æ®‹å·®å€¼')
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ®‹å·®çš„ç©ºé—´åˆ†å¸ƒï¼ˆå¦‚æœæä¾›äº†åæ ‡ï¼‰
        if coordinates is not None and coordinates.shape[1] >= 3:
            scatter = axes[1, 1].scatter(coordinates[:, 0], coordinates[:, 1], 
                                       c=residuals, cmap='RdBu_r', alpha=0.7)
            axes[1, 1].set_title('æ®‹å·®ç©ºé—´åˆ†å¸ƒ (X-Yè§†å›¾)')
            axes[1, 1].set_xlabel('Xåæ ‡')
            axes[1, 1].set_ylabel('Yåæ ‡')
            plt.colorbar(scatter, ax=axes[1, 1])
        else:
            axes[1, 1].text(0.5, 0.5, 'æ— åæ ‡ä¿¡æ¯\næ— æ³•ç»˜åˆ¶ç©ºé—´åˆ†å¸ƒ', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('æ®‹å·®ç©ºé—´åˆ†å¸ƒ (ä¸å¯ç”¨)')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            
        return fig

# ==================== é€šç”¨æ¥å£é€‚é…å™¨ ====================

class KrigingAdapter:
    """
    Krigingæ¨¡å—çš„æ ‡å‡†åŒ–æ¥å£é€‚é…å™¨
    Standardized interface adapter for Kriging module
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.model = None
        self.is_fitted = False
        
    def fit(self, X: np.ndarray, y: np.ndarray, **kwargs) -> 'KrigingAdapter':
        """
        æ ‡å‡†åŒ–çš„fitæ¥å£
        Standardized fit interface
        
        Args:
            X: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            y: è®­ç»ƒç‚¹æ•°å€¼ (N,)
            **kwargs: é¢å¤–çš„krigingå‚æ•°
            
        Returns:
            self
        """
        if not KRIGING_AVAILABLE:
            raise RuntimeError("Krigingæ¨¡å—ä¸å¯ç”¨")
            
        # å°†numpyæ•°ç»„è½¬æ¢ä¸ºDataFrameæ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        df = pd.DataFrame({
            'x': X[:, 0],
            'y': X[:, 1], 
            'z': X[:, 2],
            'target': y
        })
        
        # ä½¿ç”¨ç°æœ‰çš„trainingå‡½æ•°
        variogram_model = kwargs.get('variogram_model', self.config.kriging_variogram_model)
        self.model = kriging_training(
            df=df,
            variogram_model=variogram_model,
            nlags=kwargs.get('nlags', 8),
            enable_plotting=kwargs.get('enable_plotting', False),
            weight=kwargs.get('weight', False),
            uk=kwargs.get('uk', False),
            cpu_on=not self.config.gpu_enabled
        )
        
        self.is_fitted = True
        return self
    
    def predict(self, X: np.ndarray, return_std: bool = False, **kwargs) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
        """
        æ ‡å‡†åŒ–çš„predictæ¥å£
        Standardized predict interface
        
        Args:
            X: é¢„æµ‹ç‚¹åæ ‡ (N, 3)
            return_std: æ˜¯å¦è¿”å›æ ‡å‡†å·®ï¼ˆä¸ç¡®å®šåº¦ï¼‰
            **kwargs: é¢å¤–çš„é¢„æµ‹å‚æ•°
            
        Returns:
            predictions æˆ– (predictions, std)
        """
        if not self.is_fitted:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()")
            
        if not KRIGING_AVAILABLE:
            raise RuntimeError("Krigingæ¨¡å—ä¸å¯ç”¨")
        
        # å°†é¢„æµ‹ç‚¹è½¬æ¢ä¸ºDataFrameæ ¼å¼
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æä¾›è™šæ‹Ÿçš„targetåˆ—ï¼Œä½†ä¸ä¼šè¢«ä½¿ç”¨
        df_pred = pd.DataFrame({
            'x': X[:, 0],
            'y': X[:, 1],
            'z': X[:, 2], 
            'target': np.zeros(X.shape[0])  # è™šæ‹Ÿå€¼
        })
        
        # ä½¿ç”¨ç°æœ‰çš„testingå‡½æ•°è¿›è¡Œé¢„æµ‹
        predictions, _ = kriging_testing(
            df=df_pred,
            model=self.model,
            block_size=kwargs.get('block_size', self.config.kriging_block_size),
            cpu_on=not self.config.gpu_enabled,
            style=kwargs.get('style', "gpu_b"),
            multi_process=kwargs.get('multi_process', False),
            print_time=kwargs.get('print_time', False),
            torch_ac=kwargs.get('torch_ac', False),
            compute_precision=False  # å…³é—­ç²¾åº¦è®¡ç®—é¿å…æ··æ·†
        )
        
        if return_std and self.config.kriging_enable_uncertainty:
            # æ³¨æ„ï¼šå½“å‰å®ç°å¯èƒ½ä¸å®Œå…¨æ”¯æŒå…¨å±€ÏƒÂ²è¾“å‡º
            # TODO: éœ€è¦ä¿®æ”¹ç°æœ‰Krigingä»£ç ä»¥æ­£ç¡®è¿”å›ä¸ç¡®å®šåº¦
            warnings.warn("å½“å‰Krigingå®ç°æš‚ä¸å®Œå…¨æ”¯æŒå…¨å±€ÏƒÂ²è¾“å‡ºï¼Œè¿”å›çš„ä¸ç¡®å®šåº¦å¯èƒ½ä¸å‡†ç¡®")
            
            # ä¸´æ—¶æ–¹æ¡ˆï¼šä½¿ç”¨executeæ–¹æ³•ç›´æ¥è·å–æ–¹å·®
            try:
                _, variances = self.model.execute(
                    style='points',
                    xpoints=X[:, 0],
                    ypoints=X[:, 1], 
                    zpoints=X[:, 2],
                    block_size=kwargs.get('block_size', self.config.kriging_block_size),
                    cpu_on=not self.config.gpu_enabled
                )
                std_values = np.sqrt(np.maximum(variances, 0))  # ç¡®ä¿éè´Ÿ
                return predictions, std_values
            except Exception as e:
                warnings.warn(f"è·å–ä¸ç¡®å®šåº¦å¤±è´¥: {e}ï¼Œè¿”å›é›¶ä¸ç¡®å®šåº¦")
                return predictions, np.zeros_like(predictions)
        else:
            return predictions

class PINNAdapter:
    """
    PINNæ¨¡å—çš„æ ‡å‡†åŒ–æ¥å£é€‚é…å™¨  
    Standardized interface adapter for PINN module
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.trainer = None
        self.dose_data = None
        self.is_fitted = False
        
    def fit(self, X: np.ndarray, y: np.ndarray, 
           space_dims: List[float] = None,
           world_bounds: Dict = None,
           **kwargs) -> 'PINNAdapter':
        """
        æ ‡å‡†åŒ–çš„fitæ¥å£
        
        Args:
            X: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            y: è®­ç»ƒç‚¹æ•°å€¼ (N,)
            space_dims: ç‰©ç†ç©ºé—´å°ºå¯¸ [x, y, z]
            world_bounds: ä¸–ç•Œåæ ‡è¾¹ç•Œ
            **kwargs: é¢å¤–çš„PINNå‚æ•°
        """
        if not PINN_AVAILABLE:
            raise RuntimeError("PINNæ¨¡å—ä¸å¯ç”¨")
            
        # åˆ›å»ºè™šæ‹Ÿçš„dose_dataç»“æ„ï¼ˆé€‚é…PINNæ¥å£ï¼‰
        if space_dims is None:
            space_dims = [20.0, 10.0, 10.0]  # é»˜è®¤å°ºå¯¸
            
        if world_bounds is None:
            world_bounds = {
                'min': np.array([-10.0, -5.0, -5.0]),
                'max': np.array([10.0, 5.0, 5.0])
            }
        
        # ä½¿ç”¨RadiationDataProcessoråˆ›å»ºæ ‡å‡†åŒ–æ•°æ®æ ¼å¼
        processor = RadiationDataProcessor(space_dims, world_bounds)
        
        # ä¸ºäº†é€‚é…PINNæ¥å£ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„3Dç½‘æ ¼
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•ï¼šåŸºäºè®­ç»ƒç‚¹åˆ›å»ºæœ€å°è¾¹ç•Œç½‘æ ¼
        grid_shape = (10, 10, 10)  # æœ€å°ç½‘æ ¼ç”¨äºåˆå§‹åŒ–
        dummy_grid = np.zeros(grid_shape)
        
        self.dose_data = processor.load_from_numpy(dummy_grid, space_dims, world_bounds)
        
        # åˆ›å»ºPINNè®­ç»ƒå™¨
        self.trainer = PINNTrainer()
        
        # è½¬æ¢è¾“å…¥æ•°æ®æ ¼å¼
        sampled_log_doses = np.log(y + EPSILON)
        
        # åˆ›å»ºPINNæ¨¡å‹
        network_config = kwargs.get('network_config', {
            'layers': self.config.pinn_network_layers,
            'activation': 'tanh'
        })
        
        self.trainer.create_pinn_model(
            dose_data=self.dose_data,
            sampled_points_xyz=X,
            sampled_log_doses_values=sampled_log_doses,
            include_source=kwargs.get('include_source', False),
            network_config=network_config
        )
        
        # è®­ç»ƒæ¨¡å‹
        epochs = kwargs.get('epochs', self.config.pinn_epochs)
        loss_weights = kwargs.get('loss_weights', None)
        
        self.trainer.train(
            epochs=epochs,
            use_lbfgs=kwargs.get('use_lbfgs', True),
            loss_weights=loss_weights,
            display_every=kwargs.get('display_every', 500)
        )
        
        self.is_fitted = True
        return self
        
    def predict(self, X: np.ndarray, **kwargs) -> np.ndarray:
        """
        æ ‡å‡†åŒ–çš„predictæ¥å£
        
        Args:
            X: é¢„æµ‹ç‚¹åæ ‡ (N, 3)
            **kwargs: é¢å¤–çš„é¢„æµ‹å‚æ•°
            
        Returns:
            predictions: é¢„æµ‹å€¼ (N,)
        """
        if not self.is_fitted:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()")
            
        if not PINN_AVAILABLE:
            raise RuntimeError("PINNæ¨¡å—ä¸å¯ç”¨")
        
        # ä½¿ç”¨PINNè¿›è¡Œé¢„æµ‹
        log_predictions = self.trainer.predict(X)
        predictions = np.exp(log_predictions) - EPSILON  # è½¬å›åŸå§‹å°ºåº¦
        
        return predictions

def validate_compose_environment() -> Dict[str, bool]:
    """
    éªŒè¯è€¦åˆç¯å¢ƒçš„å®Œæ•´æ€§
    Validate the coupling environment integrity
    
    Returns:
        Dict of availability status for each component
    """
    status = {
        'Kriging': KRIGING_AVAILABLE,
        'PINN': PINN_AVAILABLE, 
        'CuPy': CUPY_AVAILABLE,
        'PyTorch': TORCH_AVAILABLE
    }
    
    print("\n=== ç¯å¢ƒæ£€æŸ¥ç»“æœ Environment Check ===")
    for component, available in status.items():
        status_str = "âœ… å¯ç”¨" if available else "âŒ ä¸å¯ç”¨"
        print(f"{component}: {status_str}")
    
    return status 

# ==================== æ–¹æ¡ˆ1ä¸“ç”¨åŠŸèƒ½ (Mode 1 Specific) ====================
# PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ

class Mode1ResidualKriging:
    """
    æ–¹æ¡ˆ1: æ®‹å·®å…‹é‡Œé‡‘æ’å€¼ä¸“ç”¨å·¥å…·
    Mode 1: Residual Kriging specific tools
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.kriging_adapter = KrigingAdapter(config)
        
    def compute_residuals(self, 
                         train_points: np.ndarray,
                         train_values: np.ndarray, 
                         pinn_predictions: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—PINNé¢„æµ‹ä¸çœŸå®å€¼çš„æ®‹å·®
        Compute residuals between PINN predictions and true values
        
        Args:
            train_points: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            train_values: çœŸå®è®­ç»ƒå€¼ (N,)
            pinn_predictions: PINNåœ¨è®­ç»ƒç‚¹çš„é¢„æµ‹å€¼ (N,)
            
        Returns:
            residuals: æ®‹å·® = çœŸå®å€¼ - PINNé¢„æµ‹å€¼ (N,)
        """
        if len(train_values) != len(pinn_predictions):
            raise ValueError("çœŸå®å€¼å’ŒPINNé¢„æµ‹å€¼çš„é•¿åº¦ä¸åŒ¹é…")
            
        residuals = train_values - pinn_predictions
        
        if self.config.verbose:
            print(f"æ®‹å·®ç»Ÿè®¡: å‡å€¼={np.mean(residuals):.4e}, æ ‡å‡†å·®={np.std(residuals):.4e}")
            print(f"æ®‹å·®èŒƒå›´: [{np.min(residuals):.4e}, {np.max(residuals):.4e}]")
            
        return residuals
        
    def residual_kriging(self,
                        train_points: np.ndarray,
                        train_values: np.ndarray,
                        pinn_predictions: np.ndarray,
                        prediction_points: np.ndarray,
                        return_uncertainty: bool = True,
                        **kriging_params) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
        """
        å¯¹æ®‹å·®è¿›è¡Œå…‹é‡Œé‡‘æ’å€¼
        Perform Kriging interpolation on residuals
        
        Args:
            train_points: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            train_values: çœŸå®è®­ç»ƒå€¼ (N,)
            pinn_predictions: PINNåœ¨è®­ç»ƒç‚¹çš„é¢„æµ‹å€¼ (N,)
            prediction_points: é¢„æµ‹ç‚¹åæ ‡ (M, 3)
            return_uncertainty: æ˜¯å¦è¿”å›ä¸ç¡®å®šåº¦
            **kriging_params: å…‹é‡Œé‡‘å‚æ•°
            
        Returns:
            residual_predictions: æ®‹å·®é¢„æµ‹ (M,)
            å¦‚æœreturn_uncertainty=True: (residual_predictions, residual_std)
        """
        # è®¡ç®—æ®‹å·®
        residuals = self.compute_residuals(train_points, train_values, pinn_predictions)
        
        # è®­ç»ƒæ®‹å·®å…‹é‡Œé‡‘æ¨¡å‹
        self.kriging_adapter.fit(train_points, residuals, **kriging_params)
        
        # é¢„æµ‹æ®‹å·®
        if return_uncertainty and self.config.kriging_enable_uncertainty:
            residual_pred, residual_std = self.kriging_adapter.predict(
                prediction_points, return_std=True
            )
            return residual_pred, residual_std
        else:
            residual_pred = self.kriging_adapter.predict(prediction_points, return_std=False)
            if return_uncertainty:
                # å¦‚æœè¯·æ±‚ä¸ç¡®å®šåº¦ä½†ä¸å¯ç”¨ï¼Œè¿”å›é›¶ä¸ç¡®å®šåº¦
                return residual_pred, np.zeros_like(residual_pred)
            else:
                return residual_pred

class Mode1Fusion:
    """
    æ–¹æ¡ˆ1: åŠ æƒèåˆå·¥å…·
    Mode 1: Weighted fusion tools
    """
    
    @staticmethod
    def fuse_residual(pinn_pred: np.ndarray,
                     kriging_residual: np.ndarray, 
                     weight: float = 0.5,
                     uncertainty: Optional[np.ndarray] = None) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
        """
        åŠ æƒèåˆPINNé¢„æµ‹å’Œæ®‹å·®é¢„æµ‹
        Weighted fusion of PINN predictions and residual predictions
        
        Args:
            pinn_pred: PINNé¢„æµ‹å€¼ (N,)
            kriging_residual: Krigingæ®‹å·®é¢„æµ‹å€¼ (N,)  
            weight: æ®‹å·®æƒé‡ Ï‰ âˆˆ (0,1), æœ€ç»ˆé¢„æµ‹ = PINN + Ï‰Ã—æ®‹å·®
            uncertainty: Krigingæ®‹å·®çš„ä¸ç¡®å®šåº¦ (N,) [å¯é€‰]
            
        Returns:
            fused_prediction: èåˆé¢„æµ‹ (N,)
            å¦‚æœæä¾›uncertainty: (fused_prediction, confidence_bounds)
        """
        if len(pinn_pred) != len(kriging_residual):
            raise ValueError("PINNé¢„æµ‹å’Œæ®‹å·®é¢„æµ‹çš„é•¿åº¦ä¸åŒ¹é…")
            
        if not 0 < weight < 1:
            warnings.warn(f"æƒé‡ {weight} ä¸åœ¨æ¨èèŒƒå›´ (0,1) å†…")
        
        # åŠ æƒèåˆ
        fused_pred = pinn_pred + weight * kriging_residual
        
        if uncertainty is not None:
            # è®¡ç®—ç½®ä¿¡ç•Œ (å‡è®¾PINNæ— ä¸ç¡®å®šåº¦ï¼Œåªè€ƒè™‘Krigingæ®‹å·®çš„ä¸ç¡®å®šåº¦)
            # 95%ç½®ä¿¡ç•Œ â‰ˆ Â±1.96Ïƒ  
            confidence_bounds = weight * 1.96 * uncertainty
            return fused_pred, confidence_bounds
        else:
            return fused_pred
    
    @staticmethod
    def adaptive_weight_strategy(residuals: np.ndarray,
                               kriging_std: Optional[np.ndarray] = None,
                               strategy: str = 'variance_based') -> np.ndarray:
        """
        è‡ªé€‚åº”æƒé‡ç­–ç•¥
        Adaptive weighting strategy
        
        Args:
            residuals: æ®‹å·®å€¼ (N,)
            kriging_std: Krigingæ ‡å‡†å·® (N,) [å¯é€‰]
            strategy: æƒé‡ç­–ç•¥ ('variance_based', 'magnitude_based', 'uniform')
            
        Returns:
            weights: è‡ªé€‚åº”æƒé‡ (N,)
        """
        n_points = len(residuals)
        
        if strategy == 'uniform':
            return np.full(n_points, 0.5)
        
        elif strategy == 'magnitude_based':
            # åŸºäºæ®‹å·®å¹…åº¦ï¼šæ®‹å·®è¶Šå¤§ï¼Œæƒé‡è¶Šé«˜
            abs_residuals = np.abs(residuals)
            max_residual = np.max(abs_residuals) 
            weights = 0.1 + 0.8 * (abs_residuals / (max_residual + EPSILON))
            return np.clip(weights, 0.1, 0.9)
        
        elif strategy == 'variance_based' and kriging_std is not None:
            # åŸºäºKrigingä¸ç¡®å®šåº¦ï¼šä¸ç¡®å®šåº¦è¶Šå°ï¼Œæƒé‡è¶Šé«˜
            normalized_std = kriging_std / (np.max(kriging_std) + EPSILON)
            weights = 0.1 + 0.8 * (1 - normalized_std)  # åæ¯”å…³ç³»
            return np.clip(weights, 0.1, 0.9)
        
        else:
            warnings.warn(f"ä¸æ”¯æŒçš„æƒé‡ç­–ç•¥ '{strategy}' æˆ–ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œä½¿ç”¨å‡åŒ€æƒé‡")
            return np.full(n_points, 0.5)

# ==================== æ–¹æ¡ˆ2ä¸“ç”¨åŠŸèƒ½ (Mode 2 Specific) ====================  
# Krigingåœ¨ROIç”Ÿæˆæ–°æ ·æœ¬ â†’ æ‰©å……æ•°æ® â†’ é‡æ–°è®­ç»ƒPINN

class Mode2ROIDetector:
    """
    æ–¹æ¡ˆ2: æ„Ÿå…´è¶£åŒºåŸŸ(ROI)æ£€æµ‹å™¨
    Mode 2: Region of Interest (ROI) detector
    """
    
    @staticmethod
    def detect_roi(train_points: np.ndarray,
                  train_values: np.ndarray,
                  roi_strategy: str = 'high_density',
                  **strategy_params) -> Dict[str, np.ndarray]:
        """
        æ£€æµ‹ç›¸å…³åŒºåŸŸ (Region of Interest)
        Detect region of interest for sample augmentation
        
        Args:
            train_points: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            train_values: è®­ç»ƒç‚¹æ•°å€¼ (N,)
            roi_strategy: ROIæ£€æµ‹ç­–ç•¥
            **strategy_params: ç­–ç•¥ç›¸å…³å‚æ•°
            
        Returns:
            roi_bounds: ROIè¾¹ç•Œä¿¡æ¯ {'min': [x,y,z], 'max': [x,y,z], 'mask': bool_array}
        """
        if roi_strategy == 'high_density':
            return Mode2ROIDetector._detect_high_density_roi(
                train_points, train_values, **strategy_params
            )
        elif roi_strategy == 'high_value':
            return Mode2ROIDetector._detect_high_value_roi(
                train_points, train_values, **strategy_params
            )
        elif roi_strategy == 'bounding_box':
            return Mode2ROIDetector._detect_bounding_box_roi(
                train_points, train_values, **strategy_params
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ROIç­–ç•¥: {roi_strategy}")
    
    @staticmethod
    def _detect_high_density_roi(train_points: np.ndarray,
                               train_values: np.ndarray,
                               density_percentile: float = 75,
                               expansion_factor: float = 1.2) -> Dict[str, np.ndarray]:
        """é«˜å¯†åº¦åŒºåŸŸæ£€æµ‹ç­–ç•¥"""
        from scipy.spatial import cKDTree
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„å±€éƒ¨å¯†åº¦
        tree = cKDTree(train_points)
        # è®¡ç®—åˆ°ç¬¬5è¿‘é‚»çš„è·ç¦»ä½œä¸ºå¯†åº¦çš„é€†æŒ‡æ ‡
        k = min(5, len(train_points) - 1)
        distances, _ = tree.query(train_points, k=k+1)  # k+1å› ä¸ºåŒ…å«è‡ªèº«
        local_density = 1 / (np.mean(distances[:, 1:], axis=1) + EPSILON)  # æ’é™¤è‡ªèº«
        
        # é€‰æ‹©é«˜å¯†åº¦ç‚¹
        density_threshold = np.percentile(local_density, density_percentile)
        high_density_mask = local_density >= density_threshold
        
        if not np.any(high_density_mask):
            # å¦‚æœæ²¡æœ‰é«˜å¯†åº¦ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰ç‚¹
            high_density_mask = np.ones(len(train_points), dtype=bool)
        
        roi_points = train_points[high_density_mask]
        
        # è®¡ç®—ROIè¾¹ç•Œ
        roi_min = np.min(roi_points, axis=0)
        roi_max = np.max(roi_points, axis=0)
        
        # æ‰©å±•è¾¹ç•Œ
        roi_center = (roi_min + roi_max) / 2
        roi_size = (roi_max - roi_min) * expansion_factor
        roi_min = roi_center - roi_size / 2
        roi_max = roi_center + roi_size / 2
        
        return {
            'min': roi_min,
            'max': roi_max, 
            'mask': high_density_mask,
            'density_scores': local_density
        }
    
    @staticmethod
    def _detect_high_value_roi(train_points: np.ndarray,
                             train_values: np.ndarray,
                             value_percentile: float = 80,
                             expansion_factor: float = 1.5) -> Dict[str, np.ndarray]:
        """é«˜æ•°å€¼åŒºåŸŸæ£€æµ‹ç­–ç•¥"""
        # é€‰æ‹©é«˜æ•°å€¼ç‚¹
        value_threshold = np.percentile(train_values, value_percentile)
        high_value_mask = train_values >= value_threshold
        
        if not np.any(high_value_mask):
            # å¦‚æœæ²¡æœ‰é«˜æ•°å€¼ç‚¹ï¼Œä½¿ç”¨æ•°å€¼å¤§äº0çš„ç‚¹
            high_value_mask = train_values > 0
            
        if not np.any(high_value_mask):
            # å¦‚æœä»ç„¶æ²¡æœ‰ï¼Œä½¿ç”¨æ‰€æœ‰ç‚¹
            high_value_mask = np.ones(len(train_points), dtype=bool)
        
        roi_points = train_points[high_value_mask]
        
        # è®¡ç®—ROIè¾¹ç•Œå¹¶æ‰©å±•
        roi_min = np.min(roi_points, axis=0)
        roi_max = np.max(roi_points, axis=0)
        
        roi_center = (roi_min + roi_max) / 2
        roi_size = (roi_max - roi_min) * expansion_factor
        roi_min = roi_center - roi_size / 2
        roi_max = roi_center + roi_size / 2
        
        return {
            'min': roi_min,
            'max': roi_max,
            'mask': high_value_mask,
            'value_scores': train_values
        }
    
    @staticmethod
    def _detect_bounding_box_roi(train_points: np.ndarray,
                               train_values: np.ndarray,
                               expansion_factor: float = 1.1) -> Dict[str, np.ndarray]:
        """åŒ…å›´ç›’ROIæ£€æµ‹ç­–ç•¥"""
        # ä½¿ç”¨æ‰€æœ‰è®­ç»ƒç‚¹çš„åŒ…å›´ç›’
        roi_min = np.min(train_points, axis=0)
        roi_max = np.max(train_points, axis=0)
        
        # è½»å¾®æ‰©å±•
        roi_center = (roi_min + roi_max) / 2
        roi_size = (roi_max - roi_min) * expansion_factor
        roi_min = roi_center - roi_size / 2
        roi_max = roi_center + roi_size / 2
        
        # æ‰€æœ‰ç‚¹éƒ½åœ¨ROIå†…
        all_points_mask = np.ones(len(train_points), dtype=bool)
        
        return {
            'min': roi_min,
            'max': roi_max,
            'mask': all_points_mask,
            'bounding_box': True
        }

class Mode2SampleAugmentor:
    """
    æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……å™¨  
    Mode 2: Sample augmentor using Kriging
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.kriging_adapter = KrigingAdapter(config)
        
    def augment_by_kriging(self,
                          train_points: np.ndarray,
                          train_values: np.ndarray,
                          roi_bounds: Dict[str, np.ndarray],
                          augment_factor: float = 2.0,
                          sampling_strategy: str = 'grid',
                          **kriging_params) -> Tuple[np.ndarray, np.ndarray]:
        """
        åœ¨ROIå†…ç”¨Krigingç”Ÿæˆæ–°æ ·æœ¬
        Generate new samples in ROI using Kriging
        
        Args:
            train_points: åŸå§‹è®­ç»ƒç‚¹åæ ‡ (N, 3)
            train_values: åŸå§‹è®­ç»ƒå€¼ (N,)
            roi_bounds: ROIè¾¹ç•Œä¿¡æ¯
            augment_factor: æ‰©å……å€æ•° (æ–°æ ·æœ¬æ•° = åŸæ ·æœ¬æ•° Ã— (augment_factor - 1))
            sampling_strategy: é‡‡æ ·ç­–ç•¥ ('grid', 'random', 'adaptive')
            **kriging_params: Krigingå‚æ•°
            
        Returns:
            augmented_points: æ‰©å……åçš„åæ ‡ (N+M, 3)
            augmented_values: æ‰©å……åçš„æ•°å€¼ (N+M,)
        """
        # è®­ç»ƒKrigingæ¨¡å‹
        self.kriging_adapter.fit(train_points, train_values, **kriging_params)
        
        # ç”ŸæˆROIå†…çš„æ–°é‡‡æ ·ç‚¹
        n_original = len(train_points) 
        n_new = int(n_original * (augment_factor - 1.0))
        
        if n_new <= 0:
            warnings.warn("æ‰©å……å€æ•°å¤ªå°ï¼Œæ²¡æœ‰ç”Ÿæˆæ–°æ ·æœ¬")
            return train_points, train_values
        
        # æ ¹æ®ç­–ç•¥ç”Ÿæˆæ–°é‡‡æ ·ç‚¹
        new_points = self._generate_sampling_points(
            roi_bounds, n_new, sampling_strategy, train_points
        )
        
        # ä½¿ç”¨Krigingé¢„æµ‹æ–°ç‚¹çš„æ•°å€¼
        new_values = self.kriging_adapter.predict(new_points, return_std=False)
        
        # åˆå¹¶åŸå§‹å’Œæ–°ç”Ÿæˆçš„æ ·æœ¬
        augmented_points = np.vstack([train_points, new_points])
        augmented_values = np.concatenate([train_values, new_values])
        
        if self.config.verbose:
            print(f"æ ·æœ¬æ‰©å……å®Œæˆ: {n_original} â†’ {len(augmented_points)} ä¸ªæ ·æœ¬")
            print(f"æ–°æ ·æœ¬æ•°å€¼èŒƒå›´: [{np.min(new_values):.4e}, {np.max(new_values):.4e}]")
        
        return augmented_points, augmented_values
    
    def _generate_sampling_points(self,
                                roi_bounds: Dict[str, np.ndarray], 
                                n_points: int,
                                strategy: str,
                                existing_points: np.ndarray) -> np.ndarray:
        """åœ¨ROIå†…ç”Ÿæˆé‡‡æ ·ç‚¹"""
        roi_min = roi_bounds['min']
        roi_max = roi_bounds['max']
        
        if strategy == 'grid':
            return self._generate_grid_points(roi_min, roi_max, n_points)
        elif strategy == 'random':
            return self._generate_random_points(roi_min, roi_max, n_points)
        elif strategy == 'adaptive':
            return self._generate_adaptive_points(roi_min, roi_max, n_points, existing_points)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·ç­–ç•¥: {strategy}")
    
    def _generate_grid_points(self, roi_min: np.ndarray, roi_max: np.ndarray, n_points: int) -> np.ndarray:
        """ç”Ÿæˆè§„åˆ™ç½‘æ ¼ç‚¹"""
        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„ç‚¹æ•°ï¼ˆå°½é‡æ¥è¿‘ç«‹æ–¹ä½“ï¼‰
        points_per_dim = int(np.ceil(n_points ** (1/3)))
        
        x = np.linspace(roi_min[0], roi_max[0], points_per_dim)
        y = np.linspace(roi_min[1], roi_max[1], points_per_dim)
        z = np.linspace(roi_min[2], roi_max[2], points_per_dim)
        
        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
        grid_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)
        
        # å¦‚æœç”Ÿæˆçš„ç‚¹æ•°è¶…è¿‡éœ€è¦çš„æ•°é‡ï¼Œéšæœºé€‰æ‹©
        if len(grid_points) > n_points:
            indices = np.random.choice(len(grid_points), n_points, replace=False)
            grid_points = grid_points[indices]
        
        return grid_points
    
    def _generate_random_points(self, roi_min: np.ndarray, roi_max: np.ndarray, n_points: int) -> np.ndarray:
        """ç”Ÿæˆéšæœºé‡‡æ ·ç‚¹"""
        random_points = np.random.rand(n_points, 3)
        random_points = roi_min + random_points * (roi_max - roi_min)
        return random_points
    
    def _generate_adaptive_points(self, roi_min: np.ndarray, roi_max: np.ndarray, 
                                n_points: int, existing_points: np.ndarray) -> np.ndarray:
        """ç”Ÿæˆè‡ªé€‚åº”é‡‡æ ·ç‚¹ï¼ˆé¿å¼€å·²æœ‰ç‚¹å¯†é›†åŒºåŸŸï¼‰"""
        from scipy.spatial import cKDTree
        
        # æ„å»ºå·²æœ‰ç‚¹çš„KDæ ‘
        tree = cKDTree(existing_points)
        
        # ç”Ÿæˆå€™é€‰ç‚¹ï¼ˆæ¯”éœ€è¦çš„å¤šä¸€äº›ï¼‰
        n_candidates = n_points * 3
        candidate_points = self._generate_random_points(roi_min, roi_max, n_candidates)
        
        # è®¡ç®—æ¯ä¸ªå€™é€‰ç‚¹åˆ°æœ€è¿‘å·²æœ‰ç‚¹çš„è·ç¦»
        distances, _ = tree.query(candidate_points)
        
        # é€‰æ‹©è·ç¦»è¾ƒå¤§çš„ç‚¹ï¼ˆè¿œç¦»å·²æœ‰ç‚¹ï¼‰
        sorted_indices = np.argsort(distances)[::-1]  # é™åºæ’åˆ—
        selected_indices = sorted_indices[:n_points]
        
        return candidate_points[selected_indices]

# ==================== ç«¯åˆ°ç«¯è€¦åˆå·¥ä½œæµ ====================
# End-to-end coupling workflows

class CouplingWorkflow:
    """
    è€¦åˆå·¥ä½œæµç®¡ç†å™¨
    Coupling workflow manager
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.mode1_tools = {
            'residual_kriging': Mode1ResidualKriging(config),
            'fusion': Mode1Fusion()
        }
        self.mode2_tools = {
            'roi_detector': Mode2ROIDetector(),
            'augmentor': Mode2SampleAugmentor(config)
        }
        self.pinn_adapter = PINNAdapter(config)
        
    def run_mode1_pipeline(self,
                          train_points: np.ndarray,
                          train_values: np.ndarray,
                          prediction_points: np.ndarray,
                          fusion_weight: Optional[float] = None,
                          **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–¹æ¡ˆ1å®Œæ•´æµç¨‹: PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ
        Execute Mode 1 complete pipeline
        """
        if fusion_weight is None:
            fusion_weight = self.config.fusion_weight
            
        results = {}
        
        # æ­¥éª¤1: è®­ç»ƒPINN
        print("ğŸ”¥ æ­¥éª¤1: è®­ç»ƒPINNæ¨¡å‹...")
        self.pinn_adapter.fit(train_points, train_values, **kwargs)
        
        # æ­¥éª¤2: PINNé¢„æµ‹
        print("ğŸ”® æ­¥éª¤2: PINNå…¨åœºé¢„æµ‹...")
        pinn_train_pred = self.pinn_adapter.predict(train_points)
        pinn_field_pred = self.pinn_adapter.predict(prediction_points)
        results['pinn_predictions'] = pinn_field_pred
        
        # æ­¥éª¤3: æ®‹å·®Kriging
        print("âš¡ æ­¥éª¤3: æ®‹å·®Krigingæ’å€¼...")
        residual_pred, residual_std = self.mode1_tools['residual_kriging'].residual_kriging(
            train_points, train_values, pinn_train_pred, prediction_points,
            return_uncertainty=True, **kwargs.get('kriging_params', {})
        )
        results['residual_predictions'] = residual_pred
        results['residual_std'] = residual_std
        
        # æ­¥éª¤4: åŠ æƒèåˆ
        print("ğŸ”— æ­¥éª¤4: åŠ æƒèåˆ...")
        if residual_std is not None and not np.all(residual_std == 0):
            fused_pred, confidence_bounds = self.mode1_tools['fusion'].fuse_residual(
                pinn_field_pred, residual_pred, fusion_weight, residual_std
            )
            results['confidence_bounds'] = confidence_bounds
        else:
            fused_pred = self.mode1_tools['fusion'].fuse_residual(
                pinn_field_pred, residual_pred, fusion_weight
            )
            results['confidence_bounds'] = None
            
        results['final_predictions'] = fused_pred
        results['fusion_weight'] = fusion_weight
        
        print("âœ… æ–¹æ¡ˆ1æµç¨‹å®Œæˆ!")
        return results
    
    def run_mode2_pipeline(self,
                          train_points: np.ndarray, 
                          train_values: np.ndarray,
                          prediction_points: np.ndarray,
                          roi_strategy: Optional[str] = None,
                          augment_factor: Optional[float] = None,
                          **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–¹æ¡ˆ2å®Œæ•´æµç¨‹: Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ
        Execute Mode 2 complete pipeline  
        """
        if roi_strategy is None:
            roi_strategy = self.config.roi_detection_strategy
        if augment_factor is None:
            augment_factor = self.config.sample_augment_factor
            
        results = {}
        
        # æ­¥éª¤1: ROIæ£€æµ‹
        print("ğŸ¯ æ­¥éª¤1: æ£€æµ‹æ„Ÿå…´è¶£åŒºåŸŸ(ROI)...")
        roi_bounds = self.mode2_tools['roi_detector'].detect_roi(
            train_points, train_values, roi_strategy, **kwargs.get('roi_params', {})
        )
        results['roi_bounds'] = roi_bounds
        
        # æ­¥éª¤2: Krigingæ ·æœ¬æ‰©å……
        print("ğŸ“ˆ æ­¥éª¤2: Krigingæ ·æœ¬æ‰©å……...")
        augmented_points, augmented_values = self.mode2_tools['augmentor'].augment_by_kriging(
            train_points, train_values, roi_bounds, augment_factor,
            **kwargs.get('kriging_params', {})
        )
        results['augmented_points'] = augmented_points
        results['augmented_values'] = augmented_values
        
        # æ­¥éª¤3: ç”¨æ‰©å……æ•°æ®é‡æ–°è®­ç»ƒPINN
        print("ğŸ”¥ æ­¥éª¤3: ç”¨æ‰©å……æ•°æ®é‡æ–°è®­ç»ƒPINN...")
        enhanced_pinn = PINNAdapter(self.config)
        enhanced_pinn.fit(augmented_points, augmented_values, **kwargs)
        
        # æ­¥éª¤4: æœ€ç»ˆé¢„æµ‹
        print("ğŸ”® æ­¥éª¤4: å¢å¼ºPINNå…¨åœºé¢„æµ‹...")
        final_pred = enhanced_pinn.predict(prediction_points)
        results['final_predictions'] = final_pred
        results['enhanced_pinn'] = enhanced_pinn
        
        print("âœ… æ–¹æ¡ˆ2æµç¨‹å®Œæˆ!")
        return results

def print_compose_banner():
    """æ‰“å°é¡¹ç›®æ¨ªå¹…"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æ¨¡å—            â•‘  
    â•‘        GPU-Accelerated Block Kriging Ã— PINN Coupling        â•‘
    â•‘                                                              â•‘
    â•‘  ğŸš€ æ–¹æ¡ˆ1: PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ                     â•‘
    â•‘  ğŸ¯ æ–¹æ¡ˆ2: Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ                  â•‘  
    â•‘                                                              â•‘
    â•‘  ğŸ’¡ æ”¯æŒGPUåŠ é€Ÿ | ğŸ”¬ ç‰©ç†çº¦æŸ | ğŸ“Š ä¸ç¡®å®šåº¦é‡åŒ–              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

if __name__ == "__main__":
    print_compose_banner()
    validate_compose_environment() 