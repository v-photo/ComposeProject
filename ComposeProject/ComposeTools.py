"""
GPU-Accelerated Block Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æ¨¡å—
GPU-Accelerated Block Kriging Ã— PINN Coupling Reconstruction Tools

åŠŸèƒ½æ¦‚è¿° (Functionality Overview):
- é€šç”¨å·¥å…· (Common Tools): æ•°æ®æ ‡å‡†åŒ–ã€è¯¯å·®ç»Ÿè®¡ã€å¯è§†åŒ–
- æ–¹æ¡ˆ1ä¸“ç”¨ (Mode 1 Specific): PINN â†’ Kriging â†’ åŠ æƒèåˆ

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import sys
import numpy as np
from matplotlib.colors import LogNorm
from typing import Dict, List, Tuple, Optional, Union, Any
import warnings
import time
import pandas as pd
from dataclasses import dataclass
from pathlib import Path
import pickle
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
# ==================== è€¦åˆé¡¹ç›®åŸæœ‰å·¥å…·å’Œæ¨¡å—å¯¼å…¥ ====================
from PINN.pinn_core import  PINNTrainer

# å°è¯•å¯¼å…¥æ‰€éœ€çš„ç¬¬ä¸‰æ–¹åº“
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    warnings.warn("PyTorchä¸å¯ç”¨ï¼Œéƒ¨åˆ†GPUåŠ é€ŸåŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False
    warnings.warn("CuPyä¸å¯ç”¨ï¼ŒGPUåŠ é€ŸåŠŸèƒ½å°†è¢«ç¦ç”¨")

# å¯¼å…¥ç°æœ‰æ¨¡å— - éœ€è¦ç¡®ä¿è·¯å¾„æ­£ç¡®
current_dir = Path(__file__).parent
project_root = current_dir.parent

# æ·»åŠ Krigingæ¨¡å—è·¯å¾„
sys.path.insert(0, str(project_root / "Kriging"))

try:
    # å¯¼å…¥Krigingæ¨¡å—
    from myKriging import training as kriging_training, testing as kriging_testing
    from myPyKriging3D import MyOrdinaryKriging3D
    KRIGING_AVAILABLE = True
    print("âœ… Krigingæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    KRIGING_AVAILABLE = False
    warnings.warn(f"Krigingæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# æ·»åŠ PINNæ¨¡å—è·¯å¾„
sys.path.insert(0, str(project_root / "PINN"))
try:
    from PINN.pinn_core import SimulationConfig, PINNTrainer, ResultAnalyzer
    from PINN.data_processing import DataLoader
    from PINN.visualization import Visualizer # <--- ä¿®æ”¹è¿™é‡Œ
    from PINN.tools import setup_deepxde_backend
    from PINN.dataAnalysis import get_data
    PINN_AVAILABLE = True
    print("âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    PINN_AVAILABLE = False
    warnings.warn(f"PINNæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# ==================== å…¨å±€å¸¸é‡ä¸é…ç½® ====================
# Global Constants and Configuration

EPSILON = 1e-30  # æ•°å€¼ç¨³å®šæ€§å¸¸æ•°
DEFAULT_METRICS = ['MAE', 'RMSE', 'MAPE', 'R2', 'MRE']

@dataclass
class ComposeConfig:
    """
    è€¦åˆç³»ç»Ÿå…¨å±€é…ç½®ç±»
    Global configuration for the coupling system
    """
    # é€šç”¨é…ç½® Common settings
    gpu_enabled: bool = True
    verbose: bool = True
    random_seed: int = 42
    
    # Krigingé…ç½® Kriging settings
    kriging_variogram_model: str = "exponential"
    kriging_block_size: int = 10000
    kriging_enable_uncertainty: bool = True  # æ³¨æ„ï¼šå½“å‰å®ç°å¯èƒ½ä¸å®Œå…¨æ”¯æŒ
    
    # [æ–°] è‡ªåŠ¨æ–¹æ³•é€‰æ‹©é˜ˆå€¼
    uniformity_cv_threshold: float = 0.6  # æœ€è¿‘é‚»è·ç¦»çš„å˜å¼‚ç³»æ•°(CV)é˜ˆå€¼ï¼Œä½äºæ­¤å€¼é€‰Kriging

# ==================== é€šç”¨å·¥å…· (Common Tools) ====================
class MetricsCalculator:
    """
    è¯¯å·®ç»Ÿè®¡è®¡ç®—å™¨
    Error metrics calculator
    """
    
    @staticmethod
    def compute_metrics(true_values: np.ndarray, 
                       pred_values: np.ndarray,
                       metrics: List[str] = None) -> Dict[str, float]:
        """
        è®¡ç®—é¢„æµ‹è¯¯å·®æŒ‡æ ‡
        Compute prediction error metrics
        
        Args:
            true_values: çœŸå®å€¼
            pred_values: é¢„æµ‹å€¼  
            metrics: è¦è®¡ç®—çš„æŒ‡æ ‡åˆ—è¡¨
            
        Returns:
            Dict[metric_name, metric_value]
        """
        if metrics is None:
            metrics = DEFAULT_METRICS
            
        # ç¡®ä¿è¾“å…¥ä¸ºnumpyæ•°ç»„
        true_values = np.asarray(true_values).flatten()
        pred_values = np.asarray(pred_values).flatten()
        
        if len(true_values) != len(pred_values):
            raise ValueError("çœŸå®å€¼å’Œé¢„æµ‹å€¼çš„é•¿åº¦ä¸åŒ¹é…")
        
        results = {}
        
        # è®¡ç®—æ®‹å·®
        residuals = pred_values - true_values
        # å¹³å‡ç›¸å¯¹è¯¯å·® Mean Relative Error
        if 'MRE' in metrics:
            results['MRE'] = np.mean(np.abs(residuals / true_values))
        
        # å¹³å‡ç»å¯¹è¯¯å·® Mean Absolute Error
        if 'MAE' in metrics:
            results['MAE'] = np.mean(np.abs(residuals))
        
        # å‡æ–¹æ ¹è¯¯å·® Root Mean Square Error  
        if 'RMSE' in metrics:
            results['RMSE'] = np.sqrt(np.mean(residuals**2))
        
        # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® Mean Absolute Percentage Error
        # åªåœ¨éé›¶çœŸå€¼å¤„è®¡ç®—
        if 'MAPE' in metrics:
            nonzero_mask = np.abs(true_values) > EPSILON
            if np.any(nonzero_mask):
                mape_values = np.abs(residuals[nonzero_mask] / true_values[nonzero_mask])
                results['MAPE'] = np.mean(mape_values) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            else:
                results['MAPE'] = float('inf')
        
        # å†³å®šç³»æ•° R-squared
        if 'R2' in metrics:
            ss_res = np.sum(residuals**2)
            ss_tot = np.sum((true_values - np.mean(true_values))**2)
            results['R2'] = 1 - (ss_res / (ss_tot + EPSILON))
        
        # ç›¸å…³ç³»æ•° Pearson correlation
        if 'CORR' in metrics:
            correlation_matrix = np.corrcoef(true_values, pred_values)
            results['CORR'] = correlation_matrix[0, 1] if not np.isnan(correlation_matrix[0, 1]) else 0.0
        
        return results
    
    @staticmethod
    def compute_relative_error_stats(true_values: np.ndarray, 
                                   pred_values: np.ndarray,
                                   percentiles: List[float] = None) -> Dict[str, float]:
        """
        è®¡ç®—ç›¸å¯¹è¯¯å·®çš„ç»Ÿè®¡åˆ†å¸ƒ
        Compute relative error statistics
        """
        if percentiles is None:
            percentiles = [10, 25, 50, 75, 90, 95, 99]
        
        # åªåœ¨éé›¶çœŸå€¼å¤„è®¡ç®—ç›¸å¯¹è¯¯å·®
        nonzero_mask = np.abs(true_values) > EPSILON
        if not np.any(nonzero_mask):
            return {f'P{p}': float('inf') for p in percentiles}
        
        relative_errors = np.abs((pred_values[nonzero_mask] - true_values[nonzero_mask]) 
                                / true_values[nonzero_mask]) * 100
        
        stats = {}
        for p in percentiles:
            stats[f'P{p}'] = np.percentile(relative_errors, p)
        
        stats['mean_rel_error'] = np.mean(relative_errors)
        stats['std_rel_error'] = np.std(relative_errors)
        
        return stats

    def fuse_predictions(self,
                         pinn_pred: np.ndarray,
                         kriging_pred: np.ndarray,
                         kriging_std: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        [ç­–ç•¥ä¸€] åŸºäºKrigingä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œè¿›è¡Œç¡¬åˆ‡æ¢èåˆ.
        Final = w * Kriging + (1 - w) * PINN
        w = 1 if kriging_variance < threshold, else w = 0
        
        Args:
            pinn_pred: PINNçš„é¢„æµ‹å€¼ (N,)
            kriging_pred: Krigingçš„é¢„æµ‹å€¼ (N,)
            kriging_std: Krigingé¢„æµ‹çš„æ ‡å‡†å·® (N,)
            
        Returns:
            (fused_prediction, fusion_weights): èåˆåçš„é¢„æµ‹å’Œæ‰€ä½¿ç”¨çš„èåˆæƒé‡
        """
        threshold = self.config.kriging_variance_threshold
        
        # 1. è®¡ç®—Krigingæ–¹å·® (ä½¿ç”¨ç»å¯¹å€¼ï¼Œä¸å†å½’ä¸€åŒ–)
        kriging_variance = kriging_std**2
        
        # 2. æ ¹æ®é˜ˆå€¼ç”ŸæˆäºŒå…ƒ(0æˆ–1)æƒé‡
        # æƒé‡ w(x)=1 ä»£è¡¨æˆ‘ä»¬å®Œå…¨ä¿¡ä»»Kriging, w(x)=0 ä»£è¡¨å®Œå…¨ä¿¡ä»»PINN
        fusion_weights = (kriging_variance < threshold).astype(np.float32)
        
        # 3. æ‰§è¡ŒåŠ æƒèåˆ
        fused_pred = fusion_weights * kriging_pred + (1 - fusion_weights) * pinn_pred
        
        if self.config.verbose:
            kriging_trusted_count = np.sum(fusion_weights)
            total_count = len(fusion_weights)
            trust_ratio = kriging_trusted_count / total_count * 100
            print("       - èåˆæƒé‡ç»Ÿè®¡ (ç­–ç•¥ä¸€: ç¡¬åˆ‡æ¢):")
            print(f"         - Krigingæ–¹å·®é˜ˆå€¼: {threshold:.4e}")
            print(f"         - ä¿¡ä»»Krigingçš„ç‚¹æ•°: {int(kriging_trusted_count)} / {total_count} ({trust_ratio:.2f}%)")

        return fused_pred, fusion_weights

# ==================== æ¨¡å‹é€‚é…å™¨ (Model Adapters) ====================
class KrigingAdapter:
    """
    Krigingæ¨¡å—çš„æ ‡å‡†åŒ–æ¥å£é€‚é…å™¨
    Standardized interface adapter for Kriging module
    """
    
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
        self.model = None
        self.is_fitted = False
        
    def fit(self, X: np.ndarray, y: np.ndarray, **kwargs) -> 'KrigingAdapter':
        """
        æ ‡å‡†åŒ–çš„fitæ¥å£
        Standardized fit interface
        
        Args:
            X: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            y: è®­ç»ƒç‚¹æ•°å€¼ (N,)
            **kwargs: é¢å¤–çš„krigingå‚æ•°
            
        Returns:
            self
        """
        if not KRIGING_AVAILABLE:
            raise RuntimeError("Krigingæ¨¡å—ä¸å¯ç”¨")
            
        # å°†numpyæ•°ç»„è½¬æ¢ä¸ºDataFrameæ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        df = pd.DataFrame({
            'x': X[:, 0],
            'y': X[:, 1], 
            'z': X[:, 2],
            'target': y
        })
        
        # ä½¿ç”¨ç°æœ‰çš„trainingå‡½æ•°
        variogram_model = kwargs.get('variogram_model', self.config.kriging_variogram_model)
        self.model = kriging_training(
            df=df,
            variogram_model=variogram_model,
            nlags=kwargs.get('nlags', 8),
            enable_plotting=kwargs.get('enable_plotting', False),
            weight=kwargs.get('weight', False),
            uk=kwargs.get('uk', False),
            cpu_on=not self.config.gpu_enabled
        )
        
        self.is_fitted = True
        return self
    
    def predict(self, X: np.ndarray, return_std: bool = False, **kwargs) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
        """
        æ ‡å‡†åŒ–çš„predictæ¥å£
        Standardized predict interface
        
        Args:
            X: é¢„æµ‹ç‚¹åæ ‡ (N, 3)
            return_std: æ˜¯å¦è¿”å›æ ‡å‡†å·®ï¼ˆä¸ç¡®å®šåº¦ï¼‰
            **kwargs: é¢å¤–çš„é¢„æµ‹å‚æ•°
            
        Returns:
            predictions æˆ– (predictions, std)
        """
        if not self.is_fitted:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()")
            
        if not KRIGING_AVAILABLE:
            raise RuntimeError("Krigingæ¨¡å—ä¸å¯ç”¨")
        
        # å°†é¢„æµ‹ç‚¹è½¬æ¢ä¸ºDataFrameæ ¼å¼
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æä¾›è™šæ‹Ÿçš„targetåˆ—ï¼Œä½†ä¸ä¼šè¢«ä½¿ç”¨
        df_pred = pd.DataFrame({
            'x': X[:, 0],
            'y': X[:, 1],
            'z': X[:, 2], 
            'target': np.zeros(X.shape[0])  # è™šæ‹Ÿå€¼
        })
        
        # ä½¿ç”¨ç°æœ‰çš„testingå‡½æ•°è¿›è¡Œé¢„æµ‹
        predictions, _ = kriging_testing(
            df=df_pred,
            model=self.model,
            block_size=kwargs.get('block_size', self.config.kriging_block_size),
            cpu_on=not self.config.gpu_enabled,
            style=kwargs.get('style', "gpu_b"),
            multi_process=kwargs.get('multi_process', False),
            print_time=kwargs.get('print_time', False),
            torch_ac=kwargs.get('torch_ac', False),
            compute_precision=False  # å…³é—­ç²¾åº¦è®¡ç®—é¿å…æ··æ·†
        )
        
        if return_std and self.config.kriging_enable_uncertainty:
            # æ³¨æ„ï¼šå½“å‰å®ç°å¯èƒ½ä¸å®Œå…¨æ”¯æŒå…¨å±€ÏƒÂ²è¾“å‡º
            # TODO: éœ€è¦ä¿®æ”¹ç°æœ‰Krigingä»£ç ä»¥æ­£ç¡®è¿”å›ä¸ç¡®å®šåº¦
            warnings.warn("å½“å‰Krigingå®ç°æš‚ä¸å®Œå…¨æ”¯æŒå…¨å±€ÏƒÂ²è¾“å‡ºï¼Œè¿”å›çš„ä¸ç¡®å®šåº¦å¯èƒ½ä¸å‡†ç¡®")
            
            # ä¸´æ—¶æ–¹æ¡ˆï¼šä½¿ç”¨executeæ–¹æ³•ç›´æ¥è·å–æ–¹å·®
            try:
                _, variances = self.model.execute(
                    style='points',
                    xpoints=X[:, 0],
                    ypoints=X[:, 1], 
                    zpoints=X[:, 2],
                    block_size=kwargs.get('block_size', self.config.kriging_block_size),
                    cpu_on=not self.config.gpu_enabled
                )
                std_values = np.sqrt(np.maximum(variances, 0))  # ç¡®ä¿éè´Ÿ
                return predictions, std_values
            except Exception as e:
                warnings.warn(f"è·å–ä¸ç¡®å®šåº¦å¤±è´¥: {e}ï¼Œè¿”å›é›¶ä¸ç¡®å®šåº¦")
                return predictions, np.zeros_like(predictions)
        else:
            return predictions

class PINNAdapter:
    """
    PINNæ¨¡å‹çš„æ ‡å‡†åŒ–æ¥å£é€‚é…å™¨
    Standardized interface adapter for the PINN model
    """
    
    def __init__(self, physical_params: Dict, config: ComposeConfig = None):
        """
        åˆå§‹åŒ–PINNé€‚é…å™¨
        """
        self.config = config or ComposeConfig()
        if not PINN_AVAILABLE:
            raise RuntimeError("PINNæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºPINNAdapter")
        if not physical_params:
            raise ValueError("PINNAdapteréœ€è¦ä¸€ä¸ªåŒ…å«ç‰©ç†å‚æ•°çš„å­—å…¸ 'physical_params'")
        
        self.trainer = PINNTrainer(physical_params=physical_params)
        self.dose_data = None  # ç”¨äºå­˜å‚¨åŠ è½½çš„æ•°æ®
        self.is_fitted = False

    def fit_from_memory(self,
                        train_points: np.ndarray,
                        train_values: np.ndarray,
                        dose_data: Dict, 
                        sample_weights: Optional[np.ndarray] = None,
                        **kwargs) -> 'PINNAdapter':
        """
        ä½¿ç”¨å†…å­˜ä¸­çš„è®­ç»ƒæ•°æ®ç‚¹è®­ç»ƒPINNæ¨¡å‹ã€‚
        ä¼šè‡ªåŠ¨å¤„ç†å¯¹æ•°è½¬æ¢ã€‚æ­¤æ–¹æ³•ä¸“ä¸ºè€¦åˆå·¥ä½œæµè®¾è®¡ã€‚
        
        Args:
            train_points: è®­ç»ƒç‚¹åæ ‡ (N, 3)
            train_values: è®­ç»ƒç‚¹æ•°å€¼ (N,)
            dose_data: å‰‚é‡æ•°æ®å­—å…¸
            sample_weights: æ ·æœ¬æƒé‡ (N,)ï¼Œå¯é€‰
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            self
        """
        print("INFO: å¼€å§‹æ‰§è¡Œ PINNAdapter.fit_from_memory()")
        
        # æ­¥éª¤ 1: æ•°æ®å‡†å¤‡ (è½¬æ¢ç‰©ç†å€¼ä¸ºå¯¹æ•°å€¼)
        print(f"      - æ­¥éª¤1: è½¬æ¢ {len(train_values)} ä¸ªè®­ç»ƒç‚¹çš„ç‰©ç†å€¼ä¸ºå¯¹æ•°å€¼...")
        sampled_log_doses = np.log(np.maximum(train_values, EPSILON))
        print("      - å¯¹æ•°è½¬æ¢å®Œæˆã€‚")

        # æ­¥éª¤ 2: åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        print("      - æ­¥éª¤2: åˆ›å»ºå¹¶è®­ç»ƒPINNæ¨¡å‹...")
        network_config = kwargs.get('network_config', {'layers': [3] + [32] * 4 + [1], 'activation': 'tanh'})
        include_source = kwargs.get('include_source', False)
        
        # æ£€æŸ¥æ˜¯å¦æä¾›äº†æ ·æœ¬æƒé‡
        if sample_weights is not None:
            print(f"      - æ£€æµ‹åˆ°æ ·æœ¬æƒé‡ï¼Œå°†ç”¨äºè®­ç»ƒ (æƒé‡èŒƒå›´: [{np.min(sample_weights):.4f}, {np.max(sample_weights):.4f}])")
            # ç¡®ä¿æƒé‡é•¿åº¦ä¸æ ·æœ¬æ•°é‡åŒ¹é…
            if len(sample_weights) != len(train_points):
                raise ValueError(f"æ ·æœ¬æƒé‡é•¿åº¦ ({len(sample_weights)}) ä¸è®­ç»ƒç‚¹æ•°é‡ ({len(train_points)}) ä¸åŒ¹é…")
            
            # å­˜å‚¨æ ·æœ¬æƒé‡ä¾›åç»­ä½¿ç”¨ï¼ˆå¦‚æœPINNæ¨¡å—æ”¯æŒï¼‰
            self._sample_weights = sample_weights
        else:
            print("      - æœªæä¾›æ ·æœ¬æƒé‡ï¼Œä½¿ç”¨å‡åŒ€æƒé‡")
            self._sample_weights = None
            
        self.trainer.create_pinn_model(
            dose_data=dose_data,
            sampled_points_xyz=train_points,
            sampled_log_doses_values=sampled_log_doses,
            include_source=include_source,
            network_config=network_config
        )
        
        epochs = kwargs.get('epochs', 10000)
        use_lbfgs = kwargs.get('use_lbfgs', True)
        loss_weights = kwargs.get('loss_weights', [1, 100])
        
        # å¦‚æœæœ‰æ ·æœ¬æƒé‡ï¼Œå°è¯•é€šè¿‡å…¶ä»–æ–¹å¼åº”ç”¨
        if self._sample_weights is not None:
            print("      - æ³¨æ„: å½“å‰PINNæ¨¡å—ä¸ç›´æ¥æ”¯æŒæ ·æœ¬æƒé‡ï¼Œå°†é€šè¿‡å…¶ä»–æ–¹å¼å®ç°")
            # è¿™é‡Œå¯ä»¥æ·»åŠ é€‚ç”¨äºæ‚¨PINNæ¨¡å—çš„æƒé‡å®ç°æ–¹å¼
            # ä¾‹å¦‚ï¼šé€šè¿‡ä¿®æ”¹æŸå¤±å‡½æ•°ã€é‡å¤æ•°æ®ç‚¹ç­‰
        
        self.trainer.train(
            epochs=epochs, 
            use_lbfgs=use_lbfgs, 
            loss_weights=loss_weights
        )
        
        self.is_fitted = True
        print("INFO: PINNAdapter.fit_from_memory() å®Œæˆ")
        return self

    def predict(self, prediction_points: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„PINNæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
        æ ¹æ®çº¦å®šï¼Œæ­¤æ–¹æ³•ç›´æ¥è¿”å›æœ€ç»ˆçš„ç‰©ç†å‰‚é‡å€¼(çº¿æ€§å°ºåº¦)ã€‚
        """
        if not self.is_fitted:
            raise RuntimeError("PINNæ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()")
            
        # æ ¹æ®çº¦å®šï¼Œtrainer.predict()è¿”å›çš„å°±æ˜¯æœ€ç»ˆçš„ç‰©ç†å‰‚é‡
        predicted_doses = self.trainer.predict(prediction_points)
        
        return predicted_doses.flatten()

def validate_compose_environment() -> Dict[str, bool]:
    """
    éªŒè¯è€¦åˆé¡¹ç›®çš„æ ¸å¿ƒä¾èµ–æ˜¯å¦å¯ç”¨
    Validate the core dependencies for the coupling project
    
    Returns:
        Dict of availability status for each component
    """
    status = {
        'Kriging': KRIGING_AVAILABLE,
        'CuPy': CUPY_AVAILABLE,
        'PyTorch': TORCH_AVAILABLE
    }
    
    print("\n=== ç¯å¢ƒæ£€æŸ¥ç»“æœ Environment Check ===")
    for component, available in status.items():
        status_str = "âœ… å¯ç”¨" if available else "âŒ ä¸å¯ç”¨"
        print(f"{component}: {status_str}")
    
    return status 

# ==================== æ–¹æ¡ˆ1ä¸“ç”¨åŠŸèƒ½ (Mode 1 Specific) ====================
class Mode1Fusion:
    """
    æ–¹æ¡ˆ1: åŸºäºç„¦ç‚¹åŒºåŸŸçš„ç¡¬åˆ‡æ¢èåˆ
    Mode 1: Hard-switch fusion based on focus region
    """
    def __init__(self, config: ComposeConfig = None):
        self.config = config or ComposeConfig()
    
    def fuse_predictions(self,
                         pinn_pred: np.ndarray,
                         kriging_pred: np.ndarray,
                         prediction_points: np.ndarray,
                         focus_center: np.ndarray,
                         focus_radius: float) -> Tuple[np.ndarray, np.ndarray]:
        """
        [ç­–ç•¥äºŒ] åŸºäºé¢„å®šä¹‰çš„ç„¦ç‚¹åŒºåŸŸï¼Œè¿›è¡Œç¡¬åˆ‡æ¢èåˆ.
        Final = w * Kriging + (1 - w) * PINN
        w = 1 if point is inside focus_sphere, else w = 0
        
        Args:
            pinn_pred: PINNçš„é¢„æµ‹å€¼ (N,)
            kriging_pred: Krigingçš„é¢„æµ‹å€¼ (N,)
            prediction_points: é¢„æµ‹ç‚¹çš„åæ ‡ (N, 3)
            focus_center: ç„¦ç‚¹åŒºåŸŸçš„ä¸­å¿ƒ (3,)
            focus_radius: ç„¦ç‚¹åŒºåŸŸçš„åŠå¾„
            
        Returns:
            (fused_prediction, fusion_weights): èåˆåçš„é¢„æµ‹å’Œæ‰€ä½¿ç”¨çš„èåˆæƒé‡
        """
        if focus_center is None or focus_radius is None:
            warnings.warn("æœªæä¾›ç„¦ç‚¹åŒºåŸŸå‚æ•°ï¼Œæ— æ³•æ‰§è¡Œèåˆï¼Œå°†å®Œå…¨ä½¿ç”¨PINNç»“æœã€‚")
            return pinn_pred, np.zeros_like(pinn_pred)

        # 1. è®¡ç®—æ‰€æœ‰é¢„æµ‹ç‚¹åˆ°ç„¦ç‚¹ä¸­å¿ƒçš„è·ç¦»
        distances_to_center = np.linalg.norm(prediction_points - focus_center, axis=1)
        
        # 2. æ ¹æ®è·ç¦»å’ŒåŠå¾„ç”ŸæˆäºŒå…ƒ(0æˆ–1)æƒé‡
        # æƒé‡ w(x)=1 ä»£è¡¨æˆ‘ä»¬å®Œå…¨ä¿¡ä»»Kriging, w(x)=0 ä»£è¡¨å®Œå…¨ä¿¡ä»»PINN
        fusion_weights = (distances_to_center <= focus_radius).astype(np.float32)
        
        # 3. æ‰§è¡ŒåŠ æƒèåˆ
        fused_pred = fusion_weights * kriging_pred + (1 - fusion_weights) * pinn_pred
        
        if self.config.verbose:
            kriging_trusted_count = np.sum(fusion_weights)
            total_count = len(fusion_weights)
            trust_ratio = kriging_trusted_count / total_count * 100
            print("       - èåˆæƒé‡ç»Ÿè®¡ (ç­–ç•¥äºŒ: ç„¦ç‚¹åŒºåŸŸç¡¬åˆ‡æ¢):")
            print(f"         - ç„¦ç‚¹ä¸­å¿ƒ: {focus_center}, åŠå¾„: {focus_radius}")
            print(f"         - ä¿¡ä»»Krigingçš„ç‚¹æ•°(åœ¨ç„¦ç‚¹åŒºåŸŸå†…): {int(kriging_trusted_count)} / {total_count} ({trust_ratio:.2f}%)")

        return fused_pred, fusion_weights

# ==================== ç«¯åˆ°ç«¯è€¦åˆå·¥ä½œæµ ====================
# End-to-end coupling workflows

class CouplingWorkflow:
    """
    è€¦åˆå·¥ä½œæµä¸»ç¼–æ’å™¨
    Main orchestrator for coupling workflows
    """
    def __init__(self, physical_params: Dict, config: ComposeConfig = None):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            physical_params: ç‰©ç†å‚æ•°å­—å…¸ (å¦‚rho, mu)
            config: å…¨å±€é…ç½®å¯¹è±¡
        """
        self.physical_params = physical_params
        self.config = config or ComposeConfig()
        
        if self.config.verbose:
            print("="*20 + " è€¦åˆå·¥ä½œæµåˆå§‹åŒ– " + "="*20)
            print(f"  - ä½¿ç”¨é…ç½®: {self.config}")
            print("="*20 + " åˆå§‹åŒ–å®Œæˆ " + "="*20 + "\n")

    def analyze_data_distribution(self, points: np.ndarray, dose_data: Dict) -> str:
        """
        åˆ†ææ•°æ®ç‚¹çš„ç©ºé—´åˆ†å¸ƒï¼Œä»¥å†³å®šæœ€ä¼˜çš„é¢„æµ‹æ–¹æ³•ã€‚
        ä½¿ç”¨ä¸¤é˜¶æ®µæ£€æŸ¥ï¼š
        1. å…¨å±€åˆ†å¸ƒï¼šæ¯”è¾ƒæ•°æ®åŒ…å›´ç›’ä½“ç§¯ä¸æ€»ç©ºé—´ä½“ç§¯çš„æ¯”ä¾‹ã€‚
        2. å±€éƒ¨å‡åŒ€æ€§ï¼šè‹¥å…¨å±€åˆ†å¸ƒé€šè¿‡ï¼Œåˆ™ä½¿ç”¨æœ€è¿‘é‚»è·ç¦»çš„å˜å¼‚ç³»æ•°(CV)ã€‚

        Args:
            points: è®­ç»ƒæ•°æ®ç‚¹åæ ‡ (N, D)
            dose_data: åŒ…å«ä¸–ç•Œè¾¹ç•Œå’Œå°ºå¯¸ä¿¡æ¯çš„å­—å…¸ã€‚

        Returns:
            'kriging' å¦‚æœæ•°æ®åˆ†å¸ƒå‡åŒ€ã€‚
            'pinn' å¦‚æœæ•°æ®åˆ†å¸ƒä¸å‡æˆ–å‘ˆèšé›†çŠ¶æ€ã€‚
        """
        print("\n--- æ­¥éª¤ 1/3: åˆ†ææ•°æ®ç©ºé—´åˆ†å¸ƒ ---")

        # --- å…¨å±€åˆ†å¸ƒæ£€æŸ¥ ---
        total_volume = np.prod(dose_data['space_dims'])
        data_min = np.min(points, axis=0)
        data_max = np.max(points, axis=0)
        data_volume = np.prod(data_max - data_min)
        volume_ratio = data_volume / total_volume if total_volume > 0 else 0

        print(f"   - å…¨å±€åˆ†å¸ƒæ£€æŸ¥:")
        print(f"     - æ•°æ®åŒ…å›´ç›’ä½“ç§¯: {data_volume:.2f} m^3")
        print(f"     - æ€»ç©ºé—´ä½“ç§¯: {total_volume:.2f} m^3")
        print(f"     - ä½“ç§¯å æ¯”: {volume_ratio:.2%}")

        # å‡è®¾ä½“ç§¯å æ¯”å°äº30%å³ä¸ºæ˜¾è‘—èšé›†
        if volume_ratio < 0.3:
            print("   - ç»“è®º: æ•°æ®ç‚¹æ˜¾è‘—èšé›†åœ¨éƒ¨åˆ†ç©ºé—´ã€‚æ¨èä½¿ç”¨ PINN è¿›è¡Œå…¨å±€æ³›åŒ–ã€‚")
            return 'pinn'
        
        print("   - å…¨å±€åˆ†å¸ƒé€šè¿‡ï¼Œå¼€å§‹è¿›è¡Œå±€éƒ¨å‡åŒ€æ€§æ£€æŸ¥...")

        # --- å±€éƒ¨å‡åŒ€æ€§æ£€æŸ¥ ---
        # 1. æ£€æŸ¥æ•°æ®ç‚¹æ•°é‡
        if len(points) < 100: # ç‚¹å¤ªå°‘ï¼ŒKrigingçš„å˜å¼‚å‡½æ•°ä¼°è®¡ä¸å¯é 
            print(f"   - æ•°æ®ç‚¹æ•°é‡: {len(points)} (< 100)")
            print("   - ç»“è®º: æ•°æ®ç‚¹è¿‡å°‘ï¼ŒKrigingæ¨¡å‹å¯èƒ½ä¸ç¨³å®šã€‚æ¨èä½¿ç”¨ PINNã€‚")
            return 'pinn'

        # 2. è®¡ç®—æ¯ä¸ªç‚¹åˆ°å…¶æœ€è¿‘é‚»çš„è·ç¦»
        nn = NearestNeighbors(n_neighbors=2, algorithm='kd_tree').fit(points)
        distances, _ = nn.kneighbors(points)
        
        # distances[:, 0] æ˜¯åˆ°è‡ªèº«çš„è·ç¦»(0), distances[:, 1] æ˜¯åˆ°æœ€è¿‘é‚»çš„è·ç¦»
        nearest_distances = distances[:, 1]
        
        # 3. è®¡ç®—è·ç¦»çš„ç»Ÿè®¡é‡
        mean_dist = np.mean(nearest_distances)
        std_dist = np.std(nearest_distances)
        cv = std_dist / mean_dist if mean_dist > EPSILON else float('inf')
        
        threshold = self.config.uniformity_cv_threshold
        
        # 4. æ‰“å°åˆ†ææŠ¥å‘Šå¹¶åšå‡ºå†³ç­–
        print(f"   - å±€éƒ¨å‡åŒ€æ€§æ£€æŸ¥:")
        print(f"     - è®­ç»ƒç‚¹æ•°é‡: {len(points)}")
        print(f"     - æœ€è¿‘é‚»å¹³å‡è·ç¦»: {mean_dist:.4f}")
        print(f"     - æœ€è¿‘é‚»è·ç¦»æ ‡å‡†å·®: {std_dist:.4f}")
        print(f"     - å˜å¼‚ç³»æ•° (CV): {cv:.4f} (å€¼è¶Šä½è¶Šå‡åŒ€)")
        print(f"     - å†³ç­–é˜ˆå€¼ (CV): {threshold}")
        
        if cv < threshold:
            decision = 'kriging'
            print(f"   - ç»“è®º: æ•°æ®åœ¨å…¨å±€åˆ†å¸ƒåˆç†ä¸”å±€éƒ¨å‡åŒ€ (CV < {threshold})ã€‚æ¨èä½¿ç”¨ Krigingã€‚")
        else:
            decision = 'pinn'
            print(f"   - ç»“è®º: æ•°æ®è™½å…¨å±€åˆ†å¸ƒï¼Œä½†å±€éƒ¨å­˜åœ¨èšé›†æˆ–ç©ºæ´ (CV >= {threshold})ã€‚æ¨èä½¿ç”¨ PINNã€‚")
            
        return decision

    def run_auto_selection_pipeline(self,
                          train_points: np.ndarray,
                          train_values: np.ndarray,
                          prediction_points: np.ndarray,
                          dose_data: Optional[Dict] = None,
                          **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªåŠ¨é€‰æ‹©å·¥ä½œæµï¼š
        1. åˆ†æè®­ç»ƒæ•°æ®çš„ç©ºé—´åˆ†å¸ƒå‡åŒ€æ€§ã€‚
        2. è‹¥åˆ†å¸ƒå‡åŒ€ï¼Œåˆ™ä½¿ç”¨Krigingè¿›è¡Œå…¨å±€é¢„æµ‹ã€‚
        3. è‹¥åˆ†å¸ƒä¸å‡ï¼Œåˆ™ä½¿ç”¨PINNè¿›è¡Œå…¨å±€é¢„æµ‹ã€‚
        """
        start_time = time.time()
        results = {}

        # æ­¥éª¤ 1: åˆ†ææ•°æ®åˆ†å¸ƒå¹¶å†³å®šä½¿ç”¨å“ªç§æ–¹æ³•
        method_to_use = self.analyze_data_distribution(train_points, dose_data)
        results['method_used'] = method_to_use

        if method_to_use == 'kriging':
            # --- æ‰§è¡Œ Kriging å·¥ä½œæµ ---
            print("\n" + "-"*20 + " æ‰§è¡Œ Kriging å…¨å±€é¢„æµ‹ " + "-"*20)
            
            # æ­¥éª¤ 2: æ•°æ®æ¸…æ´—ä¸Krigingæ¨¡å‹è®­ç»ƒ
            print("\n--- æ­¥éª¤ 2/3: æ¸…æ´—æ•°æ®å¹¶è®­ç»ƒKrigingæ¨¡å‹ ---")
            mean_val = np.mean(train_values)
            std_val = np.std(train_values)
            threshold = 2 * std_val
            valid_mask = np.abs(train_values - mean_val) < threshold
            kr_train_points = train_points[valid_mask]
            kr_train_values = train_values[valid_mask]
            
            print(f"   - åŸå§‹è®­ç»ƒç‚¹æ•°: {len(train_values)}")
            print(f"   - å‰”é™¤å¼‚å¸¸å€¼é˜ˆå€¼ (mean + 2*std): {threshold:.4e}")
            print(f"   - æ¸…æ´—åç”¨äºKrigingçš„è®­ç»ƒç‚¹æ•°: {len(kr_train_values)}")

            kriging_adapter = KrigingAdapter(self.config)
            kriging_adapter.fit(kr_train_points, kr_train_values)
            print("   âœ… Krigingæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

            # æ­¥éª¤ 3: è·å–Krigingçš„é¢„æµ‹ç»“æœ
            print("\n--- æ­¥éª¤ 3/3: è·å–Krigingåœ¨å…¨åœºçš„ç‹¬ç«‹é¢„æµ‹ ---")
            kriging_predictions, kriging_std = kriging_adapter.predict(
                prediction_points, return_std=True
            )
            results['final_predictions'] = kriging_predictions
            results['kriging_uncertainty_std'] = kriging_std
            print(f"   - å·²ç”Ÿæˆ {len(kriging_predictions)} ä¸ªKrigingé¢„æµ‹ã€‚")

        elif method_to_use == 'pinn':
            # --- æ‰§è¡Œ PINN å·¥ä½œæµ ---
            print("\n" + "-"*20 + " æ‰§è¡Œ PINN å…¨å±€é¢„æµ‹ " + "-"*20)
            
            # æ­¥éª¤ 2: è®­ç»ƒPINNæ¨¡å‹
            print("\n--- æ­¥éª¤ 2/3: ä½¿ç”¨å…¨éƒ¨ç¨€ç–æ•°æ®è®­ç»ƒPINNæ¨¡å‹ ---")
            pinn_adapter = PINNAdapter(self.physical_params, self.config)
            pinn_adapter.fit_from_memory(
                train_points=train_points, 
                train_values=train_values, 
                dose_data=dose_data, 
                **kwargs
            )
            print("   âœ… PINNæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

            # æ­¥éª¤ 3: è·å–PINNçš„é¢„æµ‹ç»“æœ
            print("\n--- æ­¥éª¤ 3/3: è·å–PINNåœ¨å…¨åœºçš„ç‹¬ç«‹é¢„æµ‹ ---")
            pinn_predictions = pinn_adapter.predict(prediction_points)
            results['final_predictions'] = pinn_predictions
            print(f"   - å·²ç”Ÿæˆ {len(pinn_predictions)} ä¸ªPINNé¢„æµ‹ã€‚")

        end_time = time.time()
        results['total_time'] = end_time - start_time
        print(f"\næ–¹æ³• '{method_to_use}' pipeline æ‰§è¡Œå®Œæ¯•ï¼Œæ€»è€—æ—¶: {results['total_time']:.2f} ç§’ã€‚")
        print("-" * 60)
        
        return results

def print_compose_banner():
    """æ‰“å°é¡¹ç›®æ¨ªå¹…"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         GPU Block-Kriging & PINN è‡ªåŠ¨é€‰æ‹©é‡å»ºæ¨¡å—            â•‘  
    â•‘      Auto-Selector for GPU-Accelerated Kriging & PINN        â•‘
    â•‘                                                              â•‘
    â•‘  ğŸš€ ç­–ç•¥: æ®æ•°æ®åˆ†å¸ƒå‡åŒ€æ€§ï¼Œè‡ªåŠ¨æ‹©ä¼˜ (Kriging / PINN)        â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ’¡ æ”¯æŒGPUåŠ é€Ÿ | ğŸ”¬ ç‰©ç†çº¦æŸ | ğŸ“Š ç©ºé—´ç»Ÿè®¡å†³ç­–              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

if __name__ == "__main__":
    print_compose_banner()
    validate_compose_environment() 