{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n"
     ]
    }
   ],
   "source": [
    "# GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n",
    "# æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ - ä½¿ç”¨çœŸå®çš„PINN/DATA.xlsxæ•°æ®\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
      "============================================================\n",
      "âœ… ComposeToolså¯¼å…¥æˆåŠŸ\n",
      "âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\n",
      "\n",
      "ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å¯¼å…¥ä¸»è¦æ¨¡å—\n",
    "try:\n",
    "    from ComposeTools import *\n",
    "    print(\"âœ… ComposeToolså¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ComposeToolså¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# æ·»åŠ PINNè·¯å¾„å¹¶å¯¼å…¥\n",
    "pinn_dir = Path.cwd().parent / \"PINN\"\n",
    "sys.path.insert(0, str(pinn_dir))\n",
    "\n",
    "try:\n",
    "    from dataAnalysis import get_data\n",
    "    from tools import (\n",
    "        DataLoader, RadiationDataProcessor, \n",
    "        PINNTrainer, setup_deepxde_backend\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PINNæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# è®¾ç½®DeepXDEåç«¯\n",
    "try:\n",
    "    setup_deepxde_backend()\n",
    "    print(\"âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ DeepXDEåç«¯è®¾ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
      "============================================================\n",
      "æ•°æ®æ–‡ä»¶è·¯å¾„: /home/linghuankong/Projects/PythonProjects/è€¦åˆé¡¹ç›®/PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n",
      "  - æ•°æ®æ–¹å·®: 3.8956e+06\n",
      "  - æœ€å¤§å€¼: 1.5743e+06\n",
      "  - æœ€å°å€¼(éé›¶): 2.6277e+01\n",
      "  - æ•°æ®å±‚æ•°: 72\n",
      "  - æ¯å±‚å½¢çŠ¶: (112, 136)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŠ è½½DATA.xlsxæ•°æ®\n",
    "data_file_path = pinn_dir / \"DATA.xlsx\"\n",
    "print(f\"æ•°æ®æ–‡ä»¶è·¯å¾„: {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨dataAnalysisä¸­çš„get_dataå‡½æ•°\n",
    "    data_dict = get_data(str(data_file_path))\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« {len(data_dict)} ä¸ªzå±‚\")\n",
    "    \n",
    "    # åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
    "    all_targets = [data_dict[i].iloc[j, k] for i in range(len(data_dict.keys())) \n",
    "                   for j in range(len(data_dict[0])) for k in range(len(data_dict[0].columns))]\n",
    "    \n",
    "    variance = np.var(all_targets)\n",
    "    minValue = np.min([i for i in all_targets if i != 0])\n",
    "    maxValue = np.max(all_targets)\n",
    "    \n",
    "    print(f\"æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"  - æ•°æ®æ–¹å·®: {variance:.4e}\")\n",
    "    print(f\"  - æœ€å¤§å€¼: {maxValue:.4e}\")\n",
    "    print(f\"  - æœ€å°å€¼(éé›¶): {minValue:.4e}\")\n",
    "    print(f\"  - æ•°æ®å±‚æ•°: {len(data_dict)}\")\n",
    "    print(f\"  - æ¯å±‚å½¢çŠ¶: {data_dict[0].shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 2.87e+01 to 4.49e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.26e+01 to 2.38e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [2.87e+01, 4.49e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.26e+01, 2.38e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
      "============================================================\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "  - ç©ºé—´ç»´åº¦: [20. 10. 10.] m\n",
      "  - ä½“ç´ å°ºå¯¸: [0.14705882 0.08928571 0.13888889] m\n",
      "  - ä¸–ç•Œè¾¹ç•Œ: [-10.  -5.  -5.] åˆ° [10.  5.  5.]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.05e+01 to 1.11e+04\n",
      "\n",
      "è®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\n",
      "  - è®­ç»ƒç‚¹æ•°: 300\n",
      "  - å‰‚é‡å€¼èŒƒå›´: 3.0459e+01 - 1.1138e+04 Gy\n",
      "  - logå‰‚é‡å€¼èŒƒå›´: 3.42 - 9.32\n",
      "  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 4500\n",
      "  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: (20, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨DataLoaderå¤„ç†æ•°æ®\n",
    "    dose_data = DataLoader.load_dose_from_dict(\n",
    "        data_dict=data_dict,\n",
    "        space_dims=[20.0, 10.0, 10.0]  # æ ¹æ®å®é™…ç‰©ç†å°ºå¯¸è°ƒæ•´\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… æ•°æ®å¤„ç†å®Œæˆ:\")\n",
    "    print(f\"  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: {dose_data['grid_shape']}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {dose_data['space_dims']} m\")\n",
    "    print(f\"  - ä½“ç´ å°ºå¯¸: {dose_data['voxel_size']} m\")\n",
    "    print(f\"  - ä¸–ç•Œè¾¹ç•Œ: {dose_data['world_min']} åˆ° {dose_data['world_max']}\")\n",
    "    \n",
    "    # é‡‡æ ·è®­ç»ƒæ•°æ®\n",
    "    sampled_points_xyz, sampled_doses_values, sampled_log_doses_values = DataLoader.sample_training_points(\n",
    "        dose_data, \n",
    "        num_samples=300, \n",
    "        sampling_strategy='positive_only'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nè®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹æ•°: {len(sampled_points_xyz)}\")\n",
    "    print(f\"  - å‰‚é‡å€¼èŒƒå›´: {np.min(sampled_doses_values):.4e} - {np.max(sampled_doses_values):.4e} Gy\")\n",
    "    print(f\"  - logå‰‚é‡å€¼èŒƒå›´: {np.min(sampled_log_doses_values):.2f} - {np.max(sampled_log_doses_values):.2f}\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ç½‘æ ¼\n",
    "    test_grid_shape = (20, 15, 15)\n",
    "    x_test = np.linspace(dose_data['world_min'][0], dose_data['world_max'][0], test_grid_shape[0])\n",
    "    y_test = np.linspace(dose_data['world_min'][1], dose_data['world_max'][1], test_grid_shape[1])\n",
    "    z_test = np.linspace(dose_data['world_min'][2], dose_data['world_max'][2], test_grid_shape[2])\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(x_test, y_test, z_test, indexing='ij')\n",
    "    test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(test_points)}\")\n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: {test_grid_shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.01e+01 to 5.84e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.67e+01 to 1.59e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.01e+01, 5.84e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.67e+01, 1.59e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
      "\n",
      "1. æ•°æ®æºä¿®æ”¹:\n",
      "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
      "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
      "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
      "\n",
      "2. ä»£ç ä¿®å¤:\n",
      "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
      "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
      "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
      "\n",
      "3. æµ‹è¯•ç”¨ä¾‹:\n",
      "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
      "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
      "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
      "\n",
      "4. ä½¿ç”¨æ–¹æ³•:\n",
      "   \n",
      "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
      "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
      "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
      "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
      "   \n",
      "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
      "   jupyter notebook test.ipynb\n",
      "   \n",
      "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
      "   python test_simple.py\n",
      "\n",
      "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
      "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
      "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
      "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
      "\n",
      "6. æ€§èƒ½ä¼˜åŒ–:\n",
      "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
      "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
      "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
      "\n",
      "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
      "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
      "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
      "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# æ€»ç»“å’Œä½¿ç”¨è¯´æ˜\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
    "\n",
    "1. æ•°æ®æºä¿®æ”¹:\n",
    "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
    "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
    "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
    "\n",
    "2. ä»£ç ä¿®å¤:\n",
    "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
    "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
    "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
    "\n",
    "3. æµ‹è¯•ç”¨ä¾‹:\n",
    "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
    "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
    "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "\n",
    "4. ä½¿ç”¨æ–¹æ³•:\n",
    "   \n",
    "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
    "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
    "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
    "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
    "   \n",
    "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
    "   jupyter notebook test.ipynb\n",
    "   \n",
    "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
    "   python test_simple.py\n",
    "\n",
    "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
    "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
    "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
    "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
    "\n",
    "6. æ€§èƒ½ä¼˜åŒ–:\n",
    "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
    "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
    "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
    "\n",
    "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
    "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
    "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
    "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.47e+01 to 9.60e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.19e+01 to 3.18e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.47e+01, 9.60e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.19e+01, 3.18e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\n",
      "============================================================\n",
      "âœ… PINNè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ\n",
      "ğŸ”¥ åˆ›å»ºPINNæ¨¡å‹...\n",
      "å®šä¹‰å¹¶è®­ç»ƒPINN...\n",
      "âœ… PINNæ¨¡å‹åˆ›å»ºæˆåŠŸ\n",
      "ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•...\n",
      "å¼€å§‹Adamè®­ç»ƒ...\n",
      "Compiling model...\n",
      "'compile' took 0.000222 s\n",
      "\n",
      "=== åˆå§‹å‚æ•°å€¼ ===\n",
      "k_pinn: 0.002291\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 1/4: ç¬¬ 1 åˆ° 2500 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "0         [9.12e-03, 2.31e+02]    [9.12e-03, 2.31e+02]    []  \n",
      "100       [1.18e-01, 1.37e+02]    [1.18e-01, 1.37e+02]    []  \n",
      "200       [8.06e-02, 2.49e+00]    [8.06e-02, 2.49e+00]    []  \n",
      "300       [5.70e-02, 7.28e-01]    [5.70e-02, 7.28e-01]    []  \n",
      "400       [4.39e-02, 4.38e-01]    [4.39e-02, 4.38e-01]    []  \n",
      "500       [3.60e-02, 2.96e-01]    [3.60e-02, 2.96e-01]    []  \n",
      "600       [3.18e-02, 2.09e-01]    [3.18e-02, 2.09e-01]    []  \n",
      "700       [3.00e-02, 1.49e-01]    [3.00e-02, 1.49e-01]    []  \n",
      "800       [2.92e-02, 1.08e-01]    [2.92e-02, 1.08e-01]    []  \n",
      "900       [2.89e-02, 8.23e-02]    [2.89e-02, 8.23e-02]    []  \n",
      "1000      [2.86e-02, 6.57e-02]    [2.86e-02, 6.57e-02]    []  \n",
      "1100      [2.83e-02, 5.45e-02]    [2.83e-02, 5.45e-02]    []  \n",
      "1200      [2.79e-02, 4.66e-02]    [2.79e-02, 4.66e-02]    []  \n",
      "1300      [2.73e-02, 4.06e-02]    [2.73e-02, 4.06e-02]    []  \n",
      "1400      [2.68e-02, 3.60e-02]    [2.68e-02, 3.60e-02]    []  \n",
      "1500      [2.62e-02, 3.22e-02]    [2.62e-02, 3.22e-02]    []  \n",
      "1600      [2.56e-02, 2.91e-02]    [2.56e-02, 2.91e-02]    []  \n",
      "1700      [2.51e-02, 2.64e-02]    [2.51e-02, 2.64e-02]    []  \n",
      "1800      [2.46e-02, 2.41e-02]    [2.46e-02, 2.41e-02]    []  \n",
      "1900      [2.41e-02, 2.22e-02]    [2.41e-02, 2.22e-02]    []  \n",
      "2000      [2.37e-02, 2.05e-02]    [2.37e-02, 2.05e-02]    []  \n",
      "2100      [2.33e-02, 1.90e-02]    [2.33e-02, 1.90e-02]    []  \n",
      "2200      [2.30e-02, 1.76e-02]    [2.30e-02, 1.76e-02]    []  \n",
      "2300      [2.28e-02, 1.65e-02]    [2.28e-02, 1.65e-02]    []  \n",
      "2400      [2.25e-02, 1.54e-02]    [2.25e-02, 1.54e-02]    []  \n",
      "2500      [2.23e-02, 1.45e-02]    [2.23e-02, 1.45e-02]    []  \n",
      "\n",
      "Best model at step 2500:\n",
      "  train loss: 3.68e-02\n",
      "  test loss: 3.68e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.847672 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 2500 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.187357\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 2/4: ç¬¬ 2501 åˆ° 5000 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "2500      [2.23e-02, 1.45e-02]    [2.23e-02, 1.45e-02]    []  \n",
      "2600      [2.21e-02, 1.36e-02]    [2.21e-02, 1.36e-02]    []  \n",
      "2700      [2.20e-02, 1.29e-02]    [2.20e-02, 1.29e-02]    []  \n",
      "2800      [2.18e-02, 1.22e-02]    [2.18e-02, 1.22e-02]    []  \n",
      "2900      [2.16e-02, 1.15e-02]    [2.16e-02, 1.15e-02]    []  \n",
      "3000      [2.15e-02, 1.09e-02]    [2.15e-02, 1.09e-02]    []  \n",
      "3100      [2.14e-02, 1.04e-02]    [2.14e-02, 1.04e-02]    []  \n",
      "3200      [2.12e-02, 9.85e-03]    [2.12e-02, 9.85e-03]    []  \n",
      "3300      [2.11e-02, 9.36e-03]    [2.11e-02, 9.36e-03]    []  \n",
      "3400      [2.10e-02, 8.89e-03]    [2.10e-02, 8.89e-03]    []  \n",
      "3500      [2.09e-02, 8.46e-03]    [2.09e-02, 8.46e-03]    []  \n",
      "3600      [2.07e-02, 8.04e-03]    [2.07e-02, 8.04e-03]    []  \n",
      "3700      [2.06e-02, 7.65e-03]    [2.06e-02, 7.65e-03]    []  \n",
      "3800      [2.05e-02, 7.28e-03]    [2.05e-02, 7.28e-03]    []  \n",
      "3900      [2.04e-02, 6.93e-03]    [2.04e-02, 6.93e-03]    []  \n",
      "4000      [2.02e-02, 6.60e-03]    [2.02e-02, 6.60e-03]    []  \n",
      "4100      [2.01e-02, 6.29e-03]    [2.01e-02, 6.29e-03]    []  \n",
      "4200      [2.00e-02, 5.99e-03]    [2.00e-02, 5.99e-03]    []  \n",
      "4300      [1.99e-02, 5.71e-03]    [1.99e-02, 5.71e-03]    []  \n",
      "4400      [1.98e-02, 5.45e-03]    [1.98e-02, 5.45e-03]    []  \n",
      "4500      [1.96e-02, 5.20e-03]    [1.96e-02, 5.20e-03]    []  \n",
      "4600      [1.95e-02, 4.96e-03]    [1.95e-02, 4.96e-03]    []  \n",
      "4700      [1.94e-02, 4.99e-03]    [1.94e-02, 4.99e-03]    []  \n",
      "4800      [1.93e-02, 4.52e-03]    [1.93e-02, 4.52e-03]    []  \n",
      "4900      [1.92e-02, 4.31e-03]    [1.92e-02, 4.31e-03]    []  \n",
      "5000      [1.91e-02, 4.11e-03]    [1.91e-02, 4.11e-03]    []  \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 2.32e-02\n",
      "  test loss: 2.32e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.102112 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 5000 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.178546\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 3/4: ç¬¬ 5001 åˆ° 7500 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "5000      [1.91e-02, 4.11e-03]    [1.91e-02, 4.11e-03]    []  \n",
      "5100      [1.90e-02, 3.92e-03]    [1.90e-02, 3.92e-03]    []  \n",
      "5200      [1.89e-02, 3.73e-03]    [1.89e-02, 3.73e-03]    []  \n",
      "5300      [1.88e-02, 3.55e-03]    [1.88e-02, 3.55e-03]    []  \n",
      "5400      [1.87e-02, 3.38e-03]    [1.87e-02, 3.38e-03]    []  \n",
      "5500      [1.86e-02, 3.20e-03]    [1.86e-02, 3.20e-03]    []  \n",
      "5600      [1.84e-02, 3.20e-03]    [1.84e-02, 3.20e-03]    []  \n",
      "5700      [1.83e-02, 2.89e-03]    [1.83e-02, 2.89e-03]    []  \n",
      "5800      [1.82e-02, 2.76e-03]    [1.82e-02, 2.76e-03]    []  \n",
      "5900      [1.81e-02, 2.61e-03]    [1.81e-02, 2.61e-03]    []  \n",
      "6000      [1.80e-02, 2.48e-03]    [1.80e-02, 2.48e-03]    []  \n",
      "6100      [1.79e-02, 2.47e-03]    [1.79e-02, 2.47e-03]    []  \n",
      "6200      [1.78e-02, 2.25e-03]    [1.78e-02, 2.25e-03]    []  \n",
      "6300      [1.78e-02, 2.15e-03]    [1.78e-02, 2.15e-03]    []  \n",
      "6400      [1.77e-02, 2.06e-03]    [1.77e-02, 2.06e-03]    []  \n",
      "6500      [1.76e-02, 1.98e-03]    [1.76e-02, 1.98e-03]    []  \n",
      "6600      [1.75e-02, 3.06e-03]    [1.75e-02, 3.06e-03]    []  \n",
      "6700      [1.74e-02, 1.84e-03]    [1.74e-02, 1.84e-03]    []  \n",
      "6800      [1.74e-02, 1.78e-03]    [1.74e-02, 1.78e-03]    []  \n",
      "6900      [1.73e-02, 1.73e-03]    [1.73e-02, 1.73e-03]    []  \n",
      "7000      [1.72e-02, 1.68e-03]    [1.72e-02, 1.68e-03]    []  \n",
      "7100      [1.72e-02, 1.72e-03]    [1.72e-02, 1.72e-03]    []  \n",
      "7200      [1.71e-02, 1.60e-03]    [1.71e-02, 1.60e-03]    []  \n",
      "7300      [1.70e-02, 1.57e-03]    [1.70e-02, 1.57e-03]    []  \n",
      "7400      [1.70e-02, 1.75e-03]    [1.70e-02, 1.75e-03]    []  \n",
      "7500      [1.69e-02, 1.51e-03]    [1.69e-02, 1.51e-03]    []  \n",
      "\n",
      "Best model at step 7500:\n",
      "  train loss: 1.85e-02\n",
      "  test loss: 1.85e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.644301 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 7500 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.167373\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 4/4: ç¬¬ 7501 åˆ° 10000 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "7500      [1.69e-02, 1.51e-03]    [1.69e-02, 1.51e-03]    []  \n",
      "7600      [1.69e-02, 1.49e-03]    [1.69e-02, 1.49e-03]    []  \n",
      "7700      [1.69e-02, 1.47e-03]    [1.69e-02, 1.47e-03]    []  \n",
      "7800      [1.68e-02, 1.45e-03]    [1.68e-02, 1.45e-03]    []  \n",
      "7900      [1.68e-02, 1.75e-03]    [1.68e-02, 1.75e-03]    []  \n",
      "8000      [1.67e-02, 1.41e-03]    [1.67e-02, 1.41e-03]    []  \n",
      "8100      [1.67e-02, 1.40e-03]    [1.67e-02, 1.40e-03]    []  \n",
      "8200      [1.67e-02, 1.43e-03]    [1.67e-02, 1.43e-03]    []  \n",
      "8300      [1.66e-02, 1.37e-03]    [1.66e-02, 1.37e-03]    []  \n",
      "8400      [1.66e-02, 1.36e-03]    [1.66e-02, 1.36e-03]    []  \n",
      "8500      [1.66e-02, 1.35e-03]    [1.66e-02, 1.35e-03]    []  \n",
      "8600      [1.66e-02, 1.34e-03]    [1.66e-02, 1.34e-03]    []  \n",
      "8700      [1.65e-02, 1.42e-03]    [1.65e-02, 1.42e-03]    []  \n",
      "8800      [1.65e-02, 1.32e-03]    [1.65e-02, 1.32e-03]    []  \n",
      "8900      [1.65e-02, 1.31e-03]    [1.65e-02, 1.31e-03]    []  \n",
      "9000      [1.65e-02, 1.90e-03]    [1.65e-02, 1.90e-03]    []  \n",
      "9100      [1.64e-02, 1.29e-03]    [1.64e-02, 1.29e-03]    []  \n",
      "9200      [1.64e-02, 1.28e-03]    [1.64e-02, 1.28e-03]    []  \n",
      "9300      [1.64e-02, 1.37e-03]    [1.64e-02, 1.37e-03]    []  \n",
      "9400      [1.64e-02, 1.27e-03]    [1.64e-02, 1.27e-03]    []  \n",
      "9500      [1.64e-02, 1.26e-03]    [1.64e-02, 1.26e-03]    []  \n",
      "9600      [1.63e-02, 1.25e-03]    [1.63e-02, 1.25e-03]    []  \n",
      "9700      [1.63e-02, 1.25e-03]    [1.63e-02, 1.25e-03]    []  \n",
      "9800      [1.63e-02, 1.48e-03]    [1.63e-02, 1.48e-03]    []  \n",
      "9900      [1.63e-02, 1.23e-03]    [1.63e-02, 1.23e-03]    []  \n",
      "10000     [1.63e-02, 1.23e-03]    [1.63e-02, 1.23e-03]    []  \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 1.75e-02\n",
      "  test loss: 1.75e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 20.913358 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 10000 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.158916\n",
      "\n",
      "=== è®­ç»ƒå®Œæˆ ===\n",
      "æ€»è€—æ—¶: 89.70 ç§’\n",
      "\n",
      "=== æœ€ç»ˆå­¦ä¹ å‚æ•° ===\n",
      "k_pinn: 0.158916\n",
      "âœ… è®­ç»ƒå®Œæˆ:\n",
      "  - å­¦ä¹ åˆ°çš„kå€¼: 0.158916 (1/m)\n",
      "  - ç†è®ºkå€¼: 0.002291 (1/m)\n",
      "ğŸ”® è¿›è¡Œé¢„æµ‹æµ‹è¯•...\n",
      "âœ… é¢„æµ‹å®Œæˆ:\n",
      "  - é¢„æµ‹ç‚¹æ•°: 4500\n",
      "  - é¢„æµ‹å€¼èŒƒå›´: 2.5148e+01 - 1.1286e+03\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ç‰©ç†å‚æ•°\n",
    "    physical_params = {\n",
    "        'rho_material': 1.205,  # ç©ºæ°”å¯†åº¦ kg/mÂ³\n",
    "        'mass_energy_abs_coeff': 0.001901  # è´¨é‡èƒ½é‡å¸æ”¶ç³»æ•° mÂ²/kg\n",
    "    }\n",
    "    \n",
    "    # åˆ›å»ºPINNè®­ç»ƒå™¨\n",
    "    trainer = PINNTrainer(physical_params=physical_params)\n",
    "    print(\"âœ… PINNè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„PINNæ¨¡å‹ï¼ˆè¾ƒå°‘çš„å±‚æ•°ä»¥é¿å…ç»´åº¦é—®é¢˜ï¼‰\n",
    "    print(\"ğŸ”¥ åˆ›å»ºPINNæ¨¡å‹...\")\n",
    "    model = trainer.create_pinn_model(\n",
    "        dose_data=dose_data,\n",
    "        sampled_points_xyz=sampled_points_xyz[:100],  # ä½¿ç”¨å°‘é‡è®­ç»ƒç‚¹\n",
    "        sampled_log_doses_values=sampled_log_doses_values[:100], \n",
    "        include_source=False,\n",
    "        network_config={'layers': [3] + [20] * 2 + [1], 'activation': 'tanh'}  # æ›´å°çš„ç½‘ç»œ\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•\n",
    "    print(\"ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•...\")\n",
    "    trainer.train(epochs=10000, use_lbfgs=False, loss_weights=[1, 10])\n",
    "    \n",
    "    # è·å–å­¦ä¹ åˆ°çš„å‚æ•°\n",
    "    learned_k = trainer.get_learned_parameters()\n",
    "    print(f\"âœ… è®­ç»ƒå®Œæˆ:\")\n",
    "    print(f\"  - å­¦ä¹ åˆ°çš„kå€¼: {learned_k[0]:.6f} (1/m)\")\n",
    "    print(f\"  - ç†è®ºkå€¼: {physical_params['mass_energy_abs_coeff'] * physical_params['rho_material']:.6f} (1/m)\")\n",
    "    \n",
    "    # ç®€å•é¢„æµ‹æµ‹è¯•\n",
    "    print(\"ğŸ”® è¿›è¡Œé¢„æµ‹æµ‹è¯•...\")\n",
    "    test_subset = test_points[:100000]  \n",
    "    predictions = trainer.predict(test_subset)\n",
    "    print(f\"âœ… é¢„æµ‹å®Œæˆ:\")\n",
    "    print(f\"  - é¢„æµ‹ç‚¹æ•°: {len(predictions)}\")\n",
    "    print(f\"  - é¢„æµ‹å€¼èŒƒå›´: {np.min(predictions):.4e} - {np.max(predictions):.4e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PINNæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINNENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
