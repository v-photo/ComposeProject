{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n"
     ]
    }
   ],
   "source": [
    "# GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n",
    "# æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ - ä½¿ç”¨çœŸå®çš„PINN/DATA.xlsxæ•°æ®\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Krigingæ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "âœ… ComposeToolså¯¼å…¥æˆåŠŸ\n",
      "âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\n",
      "\n",
      "ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å¯¼å…¥ä¸»è¦æ¨¡å—\n",
    "try:\n",
    "    from ComposeTools import *\n",
    "    print(\"âœ… ComposeToolså¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ComposeToolså¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# æ·»åŠ PINNè·¯å¾„å¹¶å¯¼å…¥\n",
    "pinn_dir = Path.cwd().parent / \"PINN\"\n",
    "sys.path.insert(0, str(pinn_dir))\n",
    "\n",
    "try:\n",
    "    from dataAnalysis import get_data\n",
    "    from tools import (\n",
    "        DataLoader, RadiationDataProcessor, \n",
    "        PINNTrainer, setup_deepxde_backend\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PINNæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# è®¾ç½®DeepXDEåç«¯\n",
    "try:\n",
    "    setup_deepxde_backend()\n",
    "    print(\"âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ DeepXDEåç«¯è®¾ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
      "============================================================\n",
      "æ•°æ®æ–‡ä»¶è·¯å¾„: /home/linghuankong/Projects/PythonProjects/è€¦åˆé¡¹ç›®/PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n",
      "  - æ•°æ®æ–¹å·®: 3.8956e+06\n",
      "  - æœ€å¤§å€¼: 1.5743e+06\n",
      "  - æœ€å°å€¼(éé›¶): 2.6277e+01\n",
      "  - æ•°æ®å±‚æ•°: 72\n",
      "  - æ¯å±‚å½¢çŠ¶: (112, 136)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŠ è½½DATA.xlsxæ•°æ®\n",
    "data_file_path = pinn_dir / \"DATA.xlsx\"\n",
    "print(f\"æ•°æ®æ–‡ä»¶è·¯å¾„: {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨dataAnalysisä¸­çš„get_dataå‡½æ•°\n",
    "    data_dict = get_data(str(data_file_path))\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« {len(data_dict)} ä¸ªzå±‚\")\n",
    "    \n",
    "    # åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
    "    all_targets = [data_dict[i].iloc[j, k] for i in range(len(data_dict.keys())) \n",
    "                   for j in range(len(data_dict[0])) for k in range(len(data_dict[0].columns))]\n",
    "    \n",
    "    variance = np.var(all_targets)\n",
    "    minValue = np.min([i for i in all_targets if i != 0])\n",
    "    maxValue = np.max(all_targets)\n",
    "    \n",
    "    print(f\"æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"  - æ•°æ®æ–¹å·®: {variance:.4e}\")\n",
    "    print(f\"  - æœ€å¤§å€¼: {maxValue:.4e}\")\n",
    "    print(f\"  - æœ€å°å€¼(éé›¶): {minValue:.4e}\")\n",
    "    print(f\"  - æ•°æ®å±‚æ•°: {len(data_dict)}\")\n",
    "    print(f\"  - æ¯å±‚å½¢çŠ¶: {data_dict[0].shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•3: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
      "============================================================\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "  - ç©ºé—´ç»´åº¦: [20. 10. 10.] m\n",
      "  - ä½“ç´ å°ºå¯¸: [0.14705882 0.08928571 0.13888889] m\n",
      "  - ä¸–ç•Œè¾¹ç•Œ: [-10.  -5.  -5.] åˆ° [10.  5.  5.]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.13e+01 to 6.35e+03\n",
      "\n",
      "è®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\n",
      "  - è®­ç»ƒç‚¹æ•°: 300\n",
      "  - å‰‚é‡å€¼èŒƒå›´: 3.1274e+01 - 6.3501e+03 Gy\n",
      "  - logå‰‚é‡å€¼èŒƒå›´: 3.44 - 8.76\n",
      "  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 4500\n",
      "  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: (20, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•3: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•3: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨DataLoaderå¤„ç†æ•°æ®\n",
    "    dose_data = DataLoader.load_dose_from_dict(\n",
    "        data_dict=data_dict,\n",
    "        space_dims=[20.0, 10.0, 10.0]  # æ ¹æ®å®é™…ç‰©ç†å°ºå¯¸è°ƒæ•´\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… æ•°æ®å¤„ç†å®Œæˆ:\")\n",
    "    print(f\"  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: {dose_data['grid_shape']}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {dose_data['space_dims']} m\")\n",
    "    print(f\"  - ä½“ç´ å°ºå¯¸: {dose_data['voxel_size']} m\")\n",
    "    print(f\"  - ä¸–ç•Œè¾¹ç•Œ: {dose_data['world_min']} åˆ° {dose_data['world_max']}\")\n",
    "    \n",
    "    # é‡‡æ ·è®­ç»ƒæ•°æ®\n",
    "    sampled_points_xyz, sampled_doses_values, sampled_log_doses_values = DataLoader.sample_training_points(\n",
    "        dose_data, \n",
    "        num_samples=300, \n",
    "        sampling_strategy='positive_only'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nè®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹æ•°: {len(sampled_points_xyz)}\")\n",
    "    print(f\"  - å‰‚é‡å€¼èŒƒå›´: {np.min(sampled_doses_values):.4e} - {np.max(sampled_doses_values):.4e} Gy\")\n",
    "    print(f\"  - logå‰‚é‡å€¼èŒƒå›´: {np.min(sampled_log_doses_values):.2f} - {np.max(sampled_log_doses_values):.2f}\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ç½‘æ ¼\n",
    "    test_grid_shape = (20, 15, 15)\n",
    "    x_test = np.linspace(dose_data['world_min'][0], dose_data['world_max'][0], test_grid_shape[0])\n",
    "    y_test = np.linspace(dose_data['world_min'][1], dose_data['world_max'][1], test_grid_shape[1])\n",
    "    z_test = np.linspace(dose_data['world_min'][2], dose_data['world_max'][2], test_grid_shape[2])\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(x_test, y_test, z_test, indexing='ij')\n",
    "    test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(test_points)}\")\n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: {test_grid_shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.31e+01 to 5.25e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.44e+01 to 7.54e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.31e+01, 5.25e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.44e+01, 7.54e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
      "\n",
      "1. æ•°æ®æºä¿®æ”¹:\n",
      "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
      "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
      "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
      "\n",
      "2. ä»£ç ä¿®å¤:\n",
      "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
      "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
      "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
      "\n",
      "3. æµ‹è¯•ç”¨ä¾‹:\n",
      "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
      "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
      "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
      "\n",
      "4. ä½¿ç”¨æ–¹æ³•:\n",
      "   \n",
      "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
      "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
      "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
      "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
      "   \n",
      "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
      "   jupyter notebook test.ipynb\n",
      "   \n",
      "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
      "   python test_simple.py\n",
      "\n",
      "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
      "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
      "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
      "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
      "\n",
      "6. æ€§èƒ½ä¼˜åŒ–:\n",
      "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
      "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
      "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
      "\n",
      "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
      "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
      "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
      "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# æ€»ç»“å’Œä½¿ç”¨è¯´æ˜\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
    "\n",
    "1. æ•°æ®æºä¿®æ”¹:\n",
    "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
    "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
    "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
    "\n",
    "2. ä»£ç ä¿®å¤:\n",
    "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
    "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
    "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
    "\n",
    "3. æµ‹è¯•ç”¨ä¾‹:\n",
    "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
    "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
    "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "\n",
    "4. ä½¿ç”¨æ–¹æ³•:\n",
    "   \n",
    "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
    "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
    "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
    "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
    "   \n",
    "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
    "   jupyter notebook test.ipynb\n",
    "   \n",
    "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
    "   python test_simple.py\n",
    "\n",
    "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
    "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
    "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
    "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
    "\n",
    "6. æ€§èƒ½ä¼˜åŒ–:\n",
    "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
    "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
    "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
    "\n",
    "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
    "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
    "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
    "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•4: KrigingåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
      "============================================================\n",
      "å¼€å§‹Krigingæµ‹è¯•:\n",
      "  - è®­ç»ƒç‚¹æ•°: 100\n",
      "  - æµ‹è¯•ç‚¹æ•°: 200\n",
      "initæ¶ˆè€—æ—¶é—´ä¸º0.01\n",
      "\n",
      "é¢„æµ‹çŸ©é˜µä¸­æœ‰ 200 ä¸ª0\n",
      "_get_kriging_matrixæ¶ˆè€—æ—¶é—´ä¸º0.00\n",
      "\n",
      "executeæ¶ˆè€—æ—¶é—´ä¸º1.67\n",
      "\n",
      "âŒ Krigingæµ‹è¯•å¤±è´¥: too many values to unpack (expected 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29671/2229405641.py\", line 32, in <module>\n",
      "    predictions, variances = kriging_adapter.predict(test_subset)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•4: KrigingåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: KrigingåŸºç¡€åŠŸèƒ½æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # å¯¼å…¥ComposeTools\n",
    "    from ComposeTools import KrigingAdapter, ComposeConfig\n",
    "    \n",
    "    # é…ç½®\n",
    "    config = ComposeConfig(gpu_enabled=True, verbose=True)\n",
    "    kriging_adapter = KrigingAdapter(config)\n",
    "    \n",
    "    # ä½¿ç”¨å‰100ä¸ªè®­ç»ƒç‚¹è¿›è¡Œæµ‹è¯•ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰\n",
    "    train_subset = sampled_points_xyz[:100]\n",
    "    values_subset = sampled_doses_values[:100]\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ç‚¹\n",
    "    test_subset = test_points[:200]  # è¾ƒå°‘çš„æµ‹è¯•ç‚¹\n",
    "    \n",
    "    print(f\"å¼€å§‹Krigingæµ‹è¯•:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹æ•°: {len(train_subset)}\")\n",
    "    print(f\"  - æµ‹è¯•ç‚¹æ•°: {len(test_subset)}\")\n",
    "    \n",
    "    # è®­ç»ƒKriging\n",
    "    start_time = time.time()\n",
    "    kriging_adapter.fit(train_subset, values_subset)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    start_time = time.time()\n",
    "    predictions, variances = kriging_adapter.predict(test_subset)\n",
    "    pred_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Krigingæµ‹è¯•å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒæ—¶é—´: {fit_time:.2f} ç§’\")\n",
    "    print(f\"  - é¢„æµ‹æ—¶é—´: {pred_time:.2f} ç§’\")\n",
    "    print(f\"  - é¢„æµ‹å€¼èŒƒå›´: {np.min(predictions):.4e} - {np.max(predictions):.4e}\")\n",
    "    print(f\"  - æ–¹å·®èŒƒå›´: {np.min(variances):.4e} - {np.max(variances):.4e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Krigingæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•4: KrigingåŸºç¡€æµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: KrigingåŸºç¡€æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # æµ‹è¯•Krigingé€‚é…å™¨\n",
    "    config = ComposeConfig(gpu_enabled=True, verbose=True)\n",
    "    kriging_adapter = KrigingAdapter(config)\n",
    "    \n",
    "    # ä½¿ç”¨å‰300ä¸ªè®­ç»ƒç‚¹è¿›è¡Œæµ‹è¯•\n",
    "    train_subset = sampled_points_xyz[:300]\n",
    "    values_subset = sampled_doses_values[:300]\n",
    "    test_subset = test_points[:500]  # è¾ƒå°‘çš„æµ‹è¯•ç‚¹\n",
    "    \n",
    "    print(f\"å¼€å§‹Krigingæµ‹è¯•:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹æ•°: {len(train_subset)}\")\n",
    "    print(f\"  - æµ‹è¯•ç‚¹æ•°: {len(test_subset)}\")\n",
    "    \n",
    "    # è®­ç»ƒKriging\n",
    "    start_time = time.time()\n",
    "    kriging_adapter.fit(train_subset, values_subset)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    start_time = time.time()\n",
    "    predictions, variances = kriging_adapter.predict(test_subset)\n",
    "    pred_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Krigingæµ‹è¯•å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒæ—¶é—´: {fit_time:.2f} ç§’\")\n",
    "    print(f\"  - é¢„æµ‹æ—¶é—´: {pred_time:.2f} ç§’\")\n",
    "    print(f\"  - é¢„æµ‹å€¼èŒƒå›´: {np.min(predictions):.4e} - {np.max(predictions):.4e}\")\n",
    "    print(f\"  - æ–¹å·®èŒƒå›´: {np.min(variances):.4e} - {np.max(variances):.4e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Krigingæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•4: åŸºç¡€PINNæ¨¡å‹æµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: åŸºç¡€PINNæ¨¡å‹æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ç‰©ç†å‚æ•°\n",
    "    physical_params = {\n",
    "        'rho_material': 1.205,  # ç©ºæ°”å¯†åº¦ kg/mÂ³\n",
    "        'mass_energy_abs_coeff': 0.001901  # è´¨é‡èƒ½é‡å¸æ”¶ç³»æ•° mÂ²/kg\n",
    "    }\n",
    "    \n",
    "    # åˆ›å»ºPINNè®­ç»ƒå™¨\n",
    "    trainer = PINNTrainer(physical_params=physical_params)\n",
    "    print(\"âœ… PINNè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„PINNæ¨¡å‹ï¼ˆè¾ƒå°‘çš„å±‚æ•°ä»¥é¿å…ç»´åº¦é—®é¢˜ï¼‰\n",
    "    print(\"ğŸ”¥ åˆ›å»ºPINNæ¨¡å‹...\")\n",
    "    model = trainer.create_pinn_model(\n",
    "        dose_data=dose_data,\n",
    "        sampled_points_xyz=sampled_points_xyz[:100],  # ä½¿ç”¨å°‘é‡è®­ç»ƒç‚¹\n",
    "        sampled_log_doses_values=sampled_log_doses_values[:100], \n",
    "        include_source=False,\n",
    "        network_config={'layers': [3] + [20] * 2 + [1], 'activation': 'tanh'}  # æ›´å°çš„ç½‘ç»œ\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•\n",
    "    print(\"ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•...\")\n",
    "    trainer.train(epochs=100, use_lbfgs=False, loss_weights=[1, 10])\n",
    "    \n",
    "    # è·å–å­¦ä¹ åˆ°çš„å‚æ•°\n",
    "    learned_k = trainer.get_learned_parameters()\n",
    "    print(f\"âœ… è®­ç»ƒå®Œæˆ:\")\n",
    "    print(f\"  - å­¦ä¹ åˆ°çš„kå€¼: {learned_k[0]:.6f} (1/m)\")\n",
    "    print(f\"  - ç†è®ºkå€¼: {physical_params['mass_energy_abs_coeff'] * physical_params['rho_material']:.6f} (1/m)\")\n",
    "    \n",
    "    # ç®€å•é¢„æµ‹æµ‹è¯•\n",
    "    print(\"ğŸ”® è¿›è¡Œé¢„æµ‹æµ‹è¯•...\")\n",
    "    test_subset = test_points[:100]  # ä½¿ç”¨å°‘é‡æµ‹è¯•ç‚¹\n",
    "    predictions = trainer.predict(test_subset)\n",
    "    print(f\"âœ… é¢„æµ‹å®Œæˆ:\")\n",
    "    print(f\"  - é¢„æµ‹ç‚¹æ•°: {len(predictions)}\")\n",
    "    print(f\"  - é¢„æµ‹å€¼èŒƒå›´: {np.min(predictions):.4e} - {np.max(predictions):.4e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PINNæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINNENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
