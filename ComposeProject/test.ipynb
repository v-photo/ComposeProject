{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n"
     ]
    }
   ],
   "source": [
    "# GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\n",
    "# æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ - ä½¿ç”¨çœŸå®çš„PINN/DATA.xlsxæ•°æ®\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºå·¥å…·æµ‹è¯•\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
      "============================================================\n",
      "âœ… ComposeToolså¯¼å…¥æˆåŠŸ\n",
      "âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\n",
      "\n",
      "ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å¯¼å…¥ä¸»è¦æ¨¡å—\n",
    "try:\n",
    "    from ComposeTools import *\n",
    "    print(\"âœ… ComposeToolså¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ComposeToolså¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# æ·»åŠ PINNè·¯å¾„å¹¶å¯¼å…¥\n",
    "pinn_dir = Path.cwd().parent / \"PINN\"\n",
    "sys.path.insert(0, str(pinn_dir))\n",
    "\n",
    "try:\n",
    "    from dataAnalysis import get_data\n",
    "    from tools import (\n",
    "        DataLoader, RadiationDataProcessor, \n",
    "        PINNTrainer, setup_deepxde_backend\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ PINNæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# è®¾ç½®DeepXDEåç«¯\n",
    "try:\n",
    "    setup_deepxde_backend()\n",
    "    print(\"âœ… DeepXDEåç«¯è®¾ç½®å®Œæˆ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ DeepXDEåç«¯è®¾ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nç¯å¢ƒæ£€æŸ¥å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
      "============================================================\n",
      "æ•°æ®æ–‡ä»¶è·¯å¾„: /home/linghuankong/Projects/PythonProjects/è€¦åˆé¡¹ç›®/PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n",
      "  - æ•°æ®æ–¹å·®: 3.8956e+06\n",
      "  - æœ€å¤§å€¼: 1.5743e+06\n",
      "  - æœ€å°å€¼(éé›¶): 2.6277e+01\n",
      "  - æ•°æ®å±‚æ•°: 72\n",
      "  - æ¯å±‚å½¢çŠ¶: (112, 136)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•2: åŠ è½½çœŸå®çš„DATA.xlsxæ•°æ®\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åŠ è½½DATA.xlsxæ•°æ®\n",
    "data_file_path = pinn_dir / \"DATA.xlsx\"\n",
    "print(f\"æ•°æ®æ–‡ä»¶è·¯å¾„: {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨dataAnalysisä¸­çš„get_dataå‡½æ•°\n",
    "    data_dict = get_data(str(data_file_path))\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« {len(data_dict)} ä¸ªzå±‚\")\n",
    "    \n",
    "    # åˆ†ææ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
    "    all_targets = [data_dict[i].iloc[j, k] for i in range(len(data_dict.keys())) \n",
    "                   for j in range(len(data_dict[0])) for k in range(len(data_dict[0].columns))]\n",
    "    \n",
    "    variance = np.var(all_targets)\n",
    "    minValue = np.min([i for i in all_targets if i != 0])\n",
    "    maxValue = np.max(all_targets)\n",
    "    \n",
    "    print(f\"æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"  - æ•°æ®æ–¹å·®: {variance:.4e}\")\n",
    "    print(f\"  - æœ€å¤§å€¼: {maxValue:.4e}\")\n",
    "    print(f\"  - æœ€å°å€¼(éé›¶): {minValue:.4e}\")\n",
    "    print(f\"  - æ•°æ®å±‚æ•°: {len(data_dict)}\")\n",
    "    print(f\"  - æ¯å±‚å½¢çŠ¶: {data_dict[0].shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 2.87e+01 to 4.49e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.26e+01 to 2.38e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [2.87e+01, 4.49e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.26e+01, 2.38e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•3: æ•°æ®æ ¼å¼éªŒè¯æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
      "============================================================\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "  - ç©ºé—´ç»´åº¦: [20. 10. 10.] m\n",
      "  - ä½“ç´ å°ºå¯¸: [0.14705882 0.08928571 0.13888889] m\n",
      "  - ä¸–ç•Œè¾¹ç•Œ: [-10.  -5.  -5.] åˆ° [10.  5.  5.]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.05e+01 to 1.11e+04\n",
      "\n",
      "è®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\n",
      "  - è®­ç»ƒç‚¹æ•°: 300\n",
      "  - å‰‚é‡å€¼èŒƒå›´: 3.0459e+01 - 1.1138e+04 Gy\n",
      "  - logå‰‚é‡å€¼èŒƒå›´: 3.42 - 9.32\n",
      "  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 4500\n",
      "  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: (20, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: æ•°æ®å¤„ç†å’Œæ ‡å‡†åŒ–\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨DataLoaderå¤„ç†æ•°æ®\n",
    "    dose_data = DataLoader.load_dose_from_dict(\n",
    "        data_dict=data_dict,\n",
    "        space_dims=[20.0, 10.0, 10.0]  # æ ¹æ®å®é™…ç‰©ç†å°ºå¯¸è°ƒæ•´\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… æ•°æ®å¤„ç†å®Œæˆ:\")\n",
    "    print(f\"  - å‰‚é‡ç½‘æ ¼å½¢çŠ¶: {dose_data['grid_shape']}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {dose_data['space_dims']} m\")\n",
    "    print(f\"  - ä½“ç´ å°ºå¯¸: {dose_data['voxel_size']} m\")\n",
    "    print(f\"  - ä¸–ç•Œè¾¹ç•Œ: {dose_data['world_min']} åˆ° {dose_data['world_max']}\")\n",
    "    \n",
    "    # é‡‡æ ·è®­ç»ƒæ•°æ®\n",
    "    sampled_points_xyz, sampled_doses_values, sampled_log_doses_values = DataLoader.sample_training_points(\n",
    "        dose_data, \n",
    "        num_samples=300, \n",
    "        sampling_strategy='positive_only'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nè®­ç»ƒæ•°æ®é‡‡æ ·å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹æ•°: {len(sampled_points_xyz)}\")\n",
    "    print(f\"  - å‰‚é‡å€¼èŒƒå›´: {np.min(sampled_doses_values):.4e} - {np.max(sampled_doses_values):.4e} Gy\")\n",
    "    print(f\"  - logå‰‚é‡å€¼èŒƒå›´: {np.min(sampled_log_doses_values):.2f} - {np.max(sampled_log_doses_values):.2f}\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ç½‘æ ¼\n",
    "    test_grid_shape = (20, 15, 15)\n",
    "    x_test = np.linspace(dose_data['world_min'][0], dose_data['world_max'][0], test_grid_shape[0])\n",
    "    y_test = np.linspace(dose_data['world_min'][1], dose_data['world_max'][1], test_grid_shape[1])\n",
    "    z_test = np.linspace(dose_data['world_min'][2], dose_data['world_max'][2], test_grid_shape[2])\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(x_test, y_test, z_test, indexing='ij')\n",
    "    test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(test_points)}\")\n",
    "    print(f\"  - æµ‹è¯•ç½‘æ ¼å½¢çŠ¶: {test_grid_shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.01e+01 to 5.84e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.67e+01 to 1.59e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.01e+01, 5.84e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.67e+01, 1.59e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•5: æ•°æ®åŠ è½½å‡½æ•°éªŒè¯\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
      "\n",
      "1. æ•°æ®æºä¿®æ”¹:\n",
      "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
      "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
      "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
      "\n",
      "2. ä»£ç ä¿®å¤:\n",
      "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
      "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
      "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
      "\n",
      "3. æµ‹è¯•ç”¨ä¾‹:\n",
      "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
      "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
      "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
      "\n",
      "4. ä½¿ç”¨æ–¹æ³•:\n",
      "   \n",
      "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
      "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
      "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
      "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
      "   \n",
      "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
      "   jupyter notebook test.ipynb\n",
      "   \n",
      "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
      "   python test_simple.py\n",
      "\n",
      "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
      "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
      "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
      "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
      "\n",
      "6. æ€§èƒ½ä¼˜åŒ–:\n",
      "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
      "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
      "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
      "\n",
      "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
      "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
      "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
      "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# æ€»ç»“å’Œä½¿ç”¨è¯´æ˜\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… å·²å®Œæˆçš„ä¿®æ”¹å’Œæ”¹è¿›:\n",
    "\n",
    "1. æ•°æ®æºä¿®æ”¹:\n",
    "   - å°†é»˜è®¤æ•°æ®æºä»å†…ç½®éšæœºç”Ÿæˆæ”¹ä¸ºçœŸå®çš„ PINN/DATA.xlsx æ•°æ®\n",
    "   - ä½¿ç”¨ dataAnalysis.get_data() å‡½æ•°åŠ è½½çœŸå®è¾å°„å‰‚é‡æ•°æ®\n",
    "   - é€šè¿‡ tools.py ä¸­çš„ DataLoader.load_dose_from_dict() å¤„ç†æ•°æ®\n",
    "\n",
    "2. ä»£ç ä¿®å¤:\n",
    "   - ä¿®æ”¹äº† main.py ä¸­çš„å‚æ•°é»˜è®¤å€¼ï¼Œä½¿å…¶é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®\n",
    "   - æ·»åŠ äº†å¼‚å¸¸å¤„ç†ï¼Œåœ¨çœŸå®æ•°æ®åŠ è½½å¤±è´¥æ—¶å›é€€åˆ°åˆæˆæ•°æ®\n",
    "   - ä¼˜åŒ–äº†æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä½¿ç”¨ 'positive_only' é¿å…é›¶å€¼é—®é¢˜\n",
    "\n",
    "3. æµ‹è¯•ç”¨ä¾‹:\n",
    "   - åˆ›å»ºäº† test.ipynb æ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„æµ‹è¯•æµç¨‹\n",
    "   - åˆ›å»ºäº† test_simple.py ç®€åŒ–æµ‹è¯•è„šæœ¬\n",
    "   - åŒ…å«æ•°æ®åŠ è½½ã€å¤„ç†ã€Krigingå’ŒPINNåŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "\n",
    "4. ä½¿ç”¨æ–¹æ³•:\n",
    "   \n",
    "   # æ–¹æ³•1: ä½¿ç”¨ä¸»ç¨‹åºï¼ˆæ¨èï¼‰\n",
    "   python main.py --mode common  # åŸºç¡€åŠŸèƒ½æ¼”ç¤º\n",
    "   python main.py --mode mode1 --fusion_weight 0.7  # æ–¹æ¡ˆ1: PINN+Krigingèåˆ\n",
    "   python main.py --mode mode2 --augment_factor 2.0  # æ–¹æ¡ˆ2: æ ·æœ¬æ‰©å……\n",
    "   \n",
    "   # æ–¹æ³•2: ä½¿ç”¨Jupyter Notebook\n",
    "   jupyter notebook test.ipynb\n",
    "   \n",
    "   # æ–¹æ³•3: è¿è¡Œç®€å•æµ‹è¯•\n",
    "   python test_simple.py\n",
    "\n",
    "5. æ•°æ®æ ¼å¼è¯´æ˜:\n",
    "   - è¾“å…¥: PINN/DATA.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªzå±‚çš„è¾å°„å‰‚é‡æ•°æ®)\n",
    "   - å¤„ç†: è½¬æ¢ä¸º3Dç½‘æ ¼æ ¼å¼ï¼Œæ”¯æŒç‰©ç†åæ ‡æ˜ å°„\n",
    "   - è¾“å‡º: æ ‡å‡†åŒ–çš„dose_dataå­—å…¸æ ¼å¼ï¼Œå…¼å®¹PINNå’ŒKriging\n",
    "\n",
    "6. æ€§èƒ½ä¼˜åŒ–:\n",
    "   - æ”¯æŒGPUåŠ é€Ÿçš„Krigingæ’å€¼\n",
    "   - å¯é…ç½®çš„é‡‡æ ·ç­–ç•¥å’Œç½‘ç»œå‚æ•°\n",
    "   - å†…å­˜å‹å¥½çš„æ‰¹å¤„ç†æœºåˆ¶\n",
    "\n",
    "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
    "- ç¡®ä¿å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ… (numpy, pandas, matplotlib, deepxde, cupyç­‰)\n",
    "- GPUåŠ é€Ÿéœ€è¦CUDAç¯å¢ƒæ”¯æŒ\n",
    "- å¤§æ•°æ®é›†å»ºè®®å‡å°‘é‡‡æ ·ç‚¹æ•°æˆ–ä½¿ç”¨æ›´å°çš„ç½‘æ ¼åˆ†è¾¨ç‡\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒPINNÃ—Krigingè€¦åˆé‡å»ºäº†ï¼\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.47e+01 to 9.60e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.19e+01 to 3.18e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.47e+01, 9.60e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.19e+01, 3.18e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•6: è€¦åˆæ–¹æ¡ˆå‡†å¤‡å·¥ä½œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\n",
      "============================================================\n",
      "âœ… PINNè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ\n",
      "ğŸ”¥ åˆ›å»ºPINNæ¨¡å‹...\n",
      "å®šä¹‰å¹¶è®­ç»ƒPINN...\n",
      "âœ… PINNæ¨¡å‹åˆ›å»ºæˆåŠŸ\n",
      "ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•...\n",
      "å¼€å§‹Adamè®­ç»ƒ...\n",
      "Compiling model...\n",
      "'compile' took 0.000222 s\n",
      "\n",
      "=== åˆå§‹å‚æ•°å€¼ ===\n",
      "k_pinn: 0.002291\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 1/4: ç¬¬ 1 åˆ° 2500 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "0         [9.12e-03, 2.31e+02]    [9.12e-03, 2.31e+02]    []  \n",
      "100       [1.18e-01, 1.37e+02]    [1.18e-01, 1.37e+02]    []  \n",
      "200       [8.06e-02, 2.49e+00]    [8.06e-02, 2.49e+00]    []  \n",
      "300       [5.70e-02, 7.28e-01]    [5.70e-02, 7.28e-01]    []  \n",
      "400       [4.39e-02, 4.38e-01]    [4.39e-02, 4.38e-01]    []  \n",
      "500       [3.60e-02, 2.96e-01]    [3.60e-02, 2.96e-01]    []  \n",
      "600       [3.18e-02, 2.09e-01]    [3.18e-02, 2.09e-01]    []  \n",
      "700       [3.00e-02, 1.49e-01]    [3.00e-02, 1.49e-01]    []  \n",
      "800       [2.92e-02, 1.08e-01]    [2.92e-02, 1.08e-01]    []  \n",
      "900       [2.89e-02, 8.23e-02]    [2.89e-02, 8.23e-02]    []  \n",
      "1000      [2.86e-02, 6.57e-02]    [2.86e-02, 6.57e-02]    []  \n",
      "1100      [2.83e-02, 5.45e-02]    [2.83e-02, 5.45e-02]    []  \n",
      "1200      [2.79e-02, 4.66e-02]    [2.79e-02, 4.66e-02]    []  \n",
      "1300      [2.73e-02, 4.06e-02]    [2.73e-02, 4.06e-02]    []  \n",
      "1400      [2.68e-02, 3.60e-02]    [2.68e-02, 3.60e-02]    []  \n",
      "1500      [2.62e-02, 3.22e-02]    [2.62e-02, 3.22e-02]    []  \n",
      "1600      [2.56e-02, 2.91e-02]    [2.56e-02, 2.91e-02]    []  \n",
      "1700      [2.51e-02, 2.64e-02]    [2.51e-02, 2.64e-02]    []  \n",
      "1800      [2.46e-02, 2.41e-02]    [2.46e-02, 2.41e-02]    []  \n",
      "1900      [2.41e-02, 2.22e-02]    [2.41e-02, 2.22e-02]    []  \n",
      "2000      [2.37e-02, 2.05e-02]    [2.37e-02, 2.05e-02]    []  \n",
      "2100      [2.33e-02, 1.90e-02]    [2.33e-02, 1.90e-02]    []  \n",
      "2200      [2.30e-02, 1.76e-02]    [2.30e-02, 1.76e-02]    []  \n",
      "2300      [2.28e-02, 1.65e-02]    [2.28e-02, 1.65e-02]    []  \n",
      "2400      [2.25e-02, 1.54e-02]    [2.25e-02, 1.54e-02]    []  \n",
      "2500      [2.23e-02, 1.45e-02]    [2.23e-02, 1.45e-02]    []  \n",
      "\n",
      "Best model at step 2500:\n",
      "  train loss: 3.68e-02\n",
      "  test loss: 3.68e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.847672 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 2500 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.187357\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 2/4: ç¬¬ 2501 åˆ° 5000 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "2500      [2.23e-02, 1.45e-02]    [2.23e-02, 1.45e-02]    []  \n",
      "2600      [2.21e-02, 1.36e-02]    [2.21e-02, 1.36e-02]    []  \n",
      "2700      [2.20e-02, 1.29e-02]    [2.20e-02, 1.29e-02]    []  \n",
      "2800      [2.18e-02, 1.22e-02]    [2.18e-02, 1.22e-02]    []  \n",
      "2900      [2.16e-02, 1.15e-02]    [2.16e-02, 1.15e-02]    []  \n",
      "3000      [2.15e-02, 1.09e-02]    [2.15e-02, 1.09e-02]    []  \n",
      "3100      [2.14e-02, 1.04e-02]    [2.14e-02, 1.04e-02]    []  \n",
      "3200      [2.12e-02, 9.85e-03]    [2.12e-02, 9.85e-03]    []  \n",
      "3300      [2.11e-02, 9.36e-03]    [2.11e-02, 9.36e-03]    []  \n",
      "3400      [2.10e-02, 8.89e-03]    [2.10e-02, 8.89e-03]    []  \n",
      "3500      [2.09e-02, 8.46e-03]    [2.09e-02, 8.46e-03]    []  \n",
      "3600      [2.07e-02, 8.04e-03]    [2.07e-02, 8.04e-03]    []  \n",
      "3700      [2.06e-02, 7.65e-03]    [2.06e-02, 7.65e-03]    []  \n",
      "3800      [2.05e-02, 7.28e-03]    [2.05e-02, 7.28e-03]    []  \n",
      "3900      [2.04e-02, 6.93e-03]    [2.04e-02, 6.93e-03]    []  \n",
      "4000      [2.02e-02, 6.60e-03]    [2.02e-02, 6.60e-03]    []  \n",
      "4100      [2.01e-02, 6.29e-03]    [2.01e-02, 6.29e-03]    []  \n",
      "4200      [2.00e-02, 5.99e-03]    [2.00e-02, 5.99e-03]    []  \n",
      "4300      [1.99e-02, 5.71e-03]    [1.99e-02, 5.71e-03]    []  \n",
      "4400      [1.98e-02, 5.45e-03]    [1.98e-02, 5.45e-03]    []  \n",
      "4500      [1.96e-02, 5.20e-03]    [1.96e-02, 5.20e-03]    []  \n",
      "4600      [1.95e-02, 4.96e-03]    [1.95e-02, 4.96e-03]    []  \n",
      "4700      [1.94e-02, 4.99e-03]    [1.94e-02, 4.99e-03]    []  \n",
      "4800      [1.93e-02, 4.52e-03]    [1.93e-02, 4.52e-03]    []  \n",
      "4900      [1.92e-02, 4.31e-03]    [1.92e-02, 4.31e-03]    []  \n",
      "5000      [1.91e-02, 4.11e-03]    [1.91e-02, 4.11e-03]    []  \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 2.32e-02\n",
      "  test loss: 2.32e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.102112 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 5000 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.178546\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 3/4: ç¬¬ 5001 åˆ° 7500 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "5000      [1.91e-02, 4.11e-03]    [1.91e-02, 4.11e-03]    []  \n",
      "5100      [1.90e-02, 3.92e-03]    [1.90e-02, 3.92e-03]    []  \n",
      "5200      [1.89e-02, 3.73e-03]    [1.89e-02, 3.73e-03]    []  \n",
      "5300      [1.88e-02, 3.55e-03]    [1.88e-02, 3.55e-03]    []  \n",
      "5400      [1.87e-02, 3.38e-03]    [1.87e-02, 3.38e-03]    []  \n",
      "5500      [1.86e-02, 3.20e-03]    [1.86e-02, 3.20e-03]    []  \n",
      "5600      [1.84e-02, 3.20e-03]    [1.84e-02, 3.20e-03]    []  \n",
      "5700      [1.83e-02, 2.89e-03]    [1.83e-02, 2.89e-03]    []  \n",
      "5800      [1.82e-02, 2.76e-03]    [1.82e-02, 2.76e-03]    []  \n",
      "5900      [1.81e-02, 2.61e-03]    [1.81e-02, 2.61e-03]    []  \n",
      "6000      [1.80e-02, 2.48e-03]    [1.80e-02, 2.48e-03]    []  \n",
      "6100      [1.79e-02, 2.47e-03]    [1.79e-02, 2.47e-03]    []  \n",
      "6200      [1.78e-02, 2.25e-03]    [1.78e-02, 2.25e-03]    []  \n",
      "6300      [1.78e-02, 2.15e-03]    [1.78e-02, 2.15e-03]    []  \n",
      "6400      [1.77e-02, 2.06e-03]    [1.77e-02, 2.06e-03]    []  \n",
      "6500      [1.76e-02, 1.98e-03]    [1.76e-02, 1.98e-03]    []  \n",
      "6600      [1.75e-02, 3.06e-03]    [1.75e-02, 3.06e-03]    []  \n",
      "6700      [1.74e-02, 1.84e-03]    [1.74e-02, 1.84e-03]    []  \n",
      "6800      [1.74e-02, 1.78e-03]    [1.74e-02, 1.78e-03]    []  \n",
      "6900      [1.73e-02, 1.73e-03]    [1.73e-02, 1.73e-03]    []  \n",
      "7000      [1.72e-02, 1.68e-03]    [1.72e-02, 1.68e-03]    []  \n",
      "7100      [1.72e-02, 1.72e-03]    [1.72e-02, 1.72e-03]    []  \n",
      "7200      [1.71e-02, 1.60e-03]    [1.71e-02, 1.60e-03]    []  \n",
      "7300      [1.70e-02, 1.57e-03]    [1.70e-02, 1.57e-03]    []  \n",
      "7400      [1.70e-02, 1.75e-03]    [1.70e-02, 1.75e-03]    []  \n",
      "7500      [1.69e-02, 1.51e-03]    [1.69e-02, 1.51e-03]    []  \n",
      "\n",
      "Best model at step 7500:\n",
      "  train loss: 1.85e-02\n",
      "  test loss: 1.85e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 21.644301 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 7500 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.167373\n",
      "\n",
      "è®­ç»ƒé˜¶æ®µ 4/4: ç¬¬ 7501 åˆ° 10000 epoch...\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "7500      [1.69e-02, 1.51e-03]    [1.69e-02, 1.51e-03]    []  \n",
      "7600      [1.69e-02, 1.49e-03]    [1.69e-02, 1.49e-03]    []  \n",
      "7700      [1.69e-02, 1.47e-03]    [1.69e-02, 1.47e-03]    []  \n",
      "7800      [1.68e-02, 1.45e-03]    [1.68e-02, 1.45e-03]    []  \n",
      "7900      [1.68e-02, 1.75e-03]    [1.68e-02, 1.75e-03]    []  \n",
      "8000      [1.67e-02, 1.41e-03]    [1.67e-02, 1.41e-03]    []  \n",
      "8100      [1.67e-02, 1.40e-03]    [1.67e-02, 1.40e-03]    []  \n",
      "8200      [1.67e-02, 1.43e-03]    [1.67e-02, 1.43e-03]    []  \n",
      "8300      [1.66e-02, 1.37e-03]    [1.66e-02, 1.37e-03]    []  \n",
      "8400      [1.66e-02, 1.36e-03]    [1.66e-02, 1.36e-03]    []  \n",
      "8500      [1.66e-02, 1.35e-03]    [1.66e-02, 1.35e-03]    []  \n",
      "8600      [1.66e-02, 1.34e-03]    [1.66e-02, 1.34e-03]    []  \n",
      "8700      [1.65e-02, 1.42e-03]    [1.65e-02, 1.42e-03]    []  \n",
      "8800      [1.65e-02, 1.32e-03]    [1.65e-02, 1.32e-03]    []  \n",
      "8900      [1.65e-02, 1.31e-03]    [1.65e-02, 1.31e-03]    []  \n",
      "9000      [1.65e-02, 1.90e-03]    [1.65e-02, 1.90e-03]    []  \n",
      "9100      [1.64e-02, 1.29e-03]    [1.64e-02, 1.29e-03]    []  \n",
      "9200      [1.64e-02, 1.28e-03]    [1.64e-02, 1.28e-03]    []  \n",
      "9300      [1.64e-02, 1.37e-03]    [1.64e-02, 1.37e-03]    []  \n",
      "9400      [1.64e-02, 1.27e-03]    [1.64e-02, 1.27e-03]    []  \n",
      "9500      [1.64e-02, 1.26e-03]    [1.64e-02, 1.26e-03]    []  \n",
      "9600      [1.63e-02, 1.25e-03]    [1.63e-02, 1.25e-03]    []  \n",
      "9700      [1.63e-02, 1.25e-03]    [1.63e-02, 1.25e-03]    []  \n",
      "9800      [1.63e-02, 1.48e-03]    [1.63e-02, 1.48e-03]    []  \n",
      "9900      [1.63e-02, 1.23e-03]    [1.63e-02, 1.23e-03]    []  \n",
      "10000     [1.63e-02, 1.23e-03]    [1.63e-02, 1.23e-03]    []  \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 1.75e-02\n",
      "  test loss: 1.75e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 20.913358 s\n",
      "\n",
      "\n",
      "--- ç¬¬ 10000 epoch å‚æ•°çŠ¶æ€ ---\n",
      "k_pinn: 0.158916\n",
      "\n",
      "=== è®­ç»ƒå®Œæˆ ===\n",
      "æ€»è€—æ—¶: 89.70 ç§’\n",
      "\n",
      "=== æœ€ç»ˆå­¦ä¹ å‚æ•° ===\n",
      "k_pinn: 0.158916\n",
      "âœ… è®­ç»ƒå®Œæˆ:\n",
      "  - å­¦ä¹ åˆ°çš„kå€¼: 0.158916 (1/m)\n",
      "  - ç†è®ºkå€¼: 0.002291 (1/m)\n",
      "ğŸ”® è¿›è¡Œé¢„æµ‹æµ‹è¯•...\n",
      "âœ… é¢„æµ‹å®Œæˆ:\n",
      "  - é¢„æµ‹ç‚¹æ•°: 4500\n",
      "  - é¢„æµ‹å€¼èŒƒå›´: 2.5148e+01 - 1.1286e+03\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•7: åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ç‰©ç†å‚æ•°\n",
    "    physical_params = {\n",
    "        'rho_material': 1.205,  # ç©ºæ°”å¯†åº¦ kg/mÂ³\n",
    "        'mass_energy_abs_coeff': 0.001901  # è´¨é‡èƒ½é‡å¸æ”¶ç³»æ•° mÂ²/kg\n",
    "    }\n",
    "    \n",
    "    # åˆ›å»ºPINNè®­ç»ƒå™¨\n",
    "    trainer = PINNTrainer(physical_params=physical_params)\n",
    "    print(\"âœ… PINNè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„PINNæ¨¡å‹ï¼ˆè¾ƒå°‘çš„å±‚æ•°ä»¥é¿å…ç»´åº¦é—®é¢˜ï¼‰\n",
    "    print(\"ğŸ”¥ åˆ›å»ºPINNæ¨¡å‹...\")\n",
    "    model = trainer.create_pinn_model(\n",
    "        dose_data=dose_data,\n",
    "        sampled_points_xyz=sampled_points_xyz[:100],  # ä½¿ç”¨å°‘é‡è®­ç»ƒç‚¹\n",
    "        sampled_log_doses_values=sampled_log_doses_values[:100], \n",
    "        include_source=False,\n",
    "        network_config={'layers': [3] + [20] * 2 + [1], 'activation': 'tanh'}  # æ›´å°çš„ç½‘ç»œ\n",
    "    )\n",
    "    print(\"âœ… PINNæ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "    \n",
    "    # çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•\n",
    "    print(\"ğŸš€ å¼€å§‹çŸ­æ—¶é—´è®­ç»ƒæµ‹è¯•...\")\n",
    "    trainer.train(epochs=10000, use_lbfgs=False, loss_weights=[1, 10])\n",
    "    \n",
    "    # è·å–å­¦ä¹ åˆ°çš„å‚æ•°\n",
    "    learned_k = trainer.get_learned_parameters()\n",
    "    print(f\"âœ… è®­ç»ƒå®Œæˆ:\")\n",
    "    print(f\"  - å­¦ä¹ åˆ°çš„kå€¼: {learned_k[0]:.6f} (1/m)\")\n",
    "    print(f\"  - ç†è®ºkå€¼: {physical_params['mass_energy_abs_coeff'] * physical_params['rho_material']:.6f} (1/m)\")\n",
    "    \n",
    "    # ç®€å•é¢„æµ‹æµ‹è¯•\n",
    "    print(\"ğŸ”® è¿›è¡Œé¢„æµ‹æµ‹è¯•...\")\n",
    "    test_subset = test_points[:100000]  \n",
    "    predictions = trainer.predict(test_subset)\n",
    "    print(f\"âœ… é¢„æµ‹å®Œæˆ:\")\n",
    "    print(f\"  - é¢„æµ‹ç‚¹æ•°: {len(predictions)}\")\n",
    "    print(f\"  - é¢„æµ‹å€¼èŒƒå›´: {np.min(predictions):.4e} - {np.max(predictions):.4e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PINNæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•8: æ–¹æ¡ˆ1è€¦åˆæ–¹æ³•æµ‹è¯• (PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ)\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•8: æ–¹æ¡ˆ1è€¦åˆæ–¹æ³•æµ‹è¯• (PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from main import run_mode1\n",
    "    from ComposeTools import ComposeConfig, CouplingWorkflow, KrigingAdapter, PINNAdapter\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°\n",
    "    class MockArgs:\n",
    "        def __init__(self):\n",
    "            self.use_real_data = True\n",
    "            self.data_file = \"../PINN/DATA.xlsx\"\n",
    "            self.num_samples = 100  # å‡å°‘æ ·æœ¬æ•°ä»¥åŠ å¿«æµ‹è¯•\n",
    "            self.noise_level = 0.05\n",
    "            self.random_seed = 42\n",
    "            self.gpu_enabled = True\n",
    "            self.verbose = True\n",
    "            self.fusion_weight = 0.6  # èåˆæƒé‡\n",
    "            self.pinn_epochs = 1000  # å‡å°‘è®­ç»ƒè½®æ•°ä»¥åŠ å¿«æµ‹è¯•\n",
    "            self.variogram_model = 'gaussian'\n",
    "            self.save_plots = False\n",
    "            self.show_plots = False\n",
    "    \n",
    "    mock_args = MockArgs()\n",
    "    \n",
    "    print(\"ğŸ“Š é…ç½®æ–¹æ¡ˆ1æµ‹è¯•å‚æ•°:\")\n",
    "    print(f\"  - èåˆæƒé‡: {mock_args.fusion_weight}\")\n",
    "    print(f\"  - PINNè®­ç»ƒè½®æ•°: {mock_args.pinn_epochs}\")\n",
    "    print(f\"  - é‡‡æ ·ç‚¹æ•°: {mock_args.num_samples}\")\n",
    "    print(f\"  - ä½¿ç”¨GPU: {mock_args.gpu_enabled}\")\n",
    "    \n",
    "    # æ‰‹åŠ¨å®ç°æ–¹æ¡ˆ1æµç¨‹ä»¥ä¾¿æ§åˆ¶æµ‹è¯•è¿‡ç¨‹\n",
    "    print(\"\\nğŸ”„ æ‰‹åŠ¨æ‰§è¡Œæ–¹æ¡ˆ1æµç¨‹...\")\n",
    "    \n",
    "    # 1. åŠ è½½æ•°æ®\n",
    "    from main import load_real_data_from_excel\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    # ä½¿ç”¨è¾ƒå°çš„æµ‹è¯•é›†\n",
    "    test_pts_small = test_pts[:500]  # å‡å°‘æµ‹è¯•ç‚¹æ•°\n",
    "    test_vals_small = test_vals[:500]\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - æµ‹è¯•ç‚¹: {test_pts_small.shape}\")\n",
    "    \n",
    "    # 2. é…ç½®ç³»ç»Ÿ\n",
    "    config = ComposeConfig(\n",
    "        gpu_enabled=mock_args.gpu_enabled,\n",
    "        verbose=mock_args.verbose,\n",
    "        random_seed=mock_args.random_seed,\n",
    "        fusion_weight=mock_args.fusion_weight,\n",
    "        pinn_epochs=mock_args.pinn_epochs,\n",
    "        kriging_variogram_model=mock_args.variogram_model\n",
    "    )\n",
    "    \n",
    "    # 3. åˆ›å»ºé€‚é…å™¨\n",
    "    print(\"\\nğŸ”§ åˆ›å»ºPINNå’ŒKrigingé€‚é…å™¨...\")\n",
    "    pinn_adapter = PINNAdapter(config)\n",
    "    kriging_adapter = KrigingAdapter(config)\n",
    "    \n",
    "    # 4. ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒPINNæ¨¡å‹\n",
    "    print(\"\\nğŸš€ é˜¶æ®µ1: è®­ç»ƒPINNæ¨¡å‹...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pinn_adapter.fit(\n",
    "        train_pts, train_vals,\n",
    "        space_dims=field_info['space_dims'],\n",
    "        world_bounds=field_info['world_bounds']\n",
    "    )\n",
    "    \n",
    "    pinn_train_time = time.time() - start_time\n",
    "    print(f\"âœ… PINNè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {pinn_train_time:.2f}ç§’\")\n",
    "    \n",
    "    # 5. PINNé¢„æµ‹\n",
    "    print(\"\\nğŸ”® è¿›è¡ŒPINNé¢„æµ‹...\")\n",
    "    pinn_predictions = pinn_adapter.predict(test_pts_small)\n",
    "    \n",
    "    # 6. è®¡ç®—æ®‹å·®\n",
    "    print(\"\\nğŸ“Š è®¡ç®—æ®‹å·®ç”¨äºKriging...\")\n",
    "    train_pinn_pred = pinn_adapter.predict(train_pts)\n",
    "    train_residuals = train_vals - train_pinn_pred\n",
    "    \n",
    "    print(f\"  - è®­ç»ƒæ®‹å·®èŒƒå›´: [{np.min(train_residuals):.4e}, {np.max(train_residuals):.4e}]\")\n",
    "    print(f\"  - è®­ç»ƒæ®‹å·®å‡å€¼: {np.mean(train_residuals):.4e}\")\n",
    "    print(f\"  - è®­ç»ƒæ®‹å·®æ ‡å‡†å·®: {np.std(train_residuals):.4e}\")\n",
    "    \n",
    "    # 7. ç¬¬äºŒé˜¶æ®µï¼šå¯¹æ®‹å·®è¿›è¡ŒKrigingæ’å€¼\n",
    "    print(\"\\nğŸ—ºï¸ é˜¶æ®µ2: å¯¹æ®‹å·®è¿›è¡ŒKrigingæ’å€¼...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    kriging_adapter.fit(train_pts, train_residuals)\n",
    "    residual_predictions = kriging_adapter.predict(test_pts_small)\n",
    "    \n",
    "    kriging_train_time = time.time() - start_time\n",
    "    print(f\"âœ… Krigingè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {kriging_train_time:.2f}ç§’\")\n",
    "    \n",
    "    # 8. ç¬¬ä¸‰é˜¶æ®µï¼šåŠ æƒèåˆ\n",
    "    print(f\"\\nâš–ï¸ é˜¶æ®µ3: åŠ æƒèåˆ (æƒé‡={mock_args.fusion_weight})...\")\n",
    "    \n",
    "    # ç®€å•çš„çº¿æ€§åŠ æƒèåˆ\n",
    "    # final_prediction = fusion_weight * pinn_pred + (1 - fusion_weight) * (pinn_pred + residual_pred)\n",
    "    # è¿™ç­‰ä»·äº: final = pinn_pred + (1 - fusion_weight) * residual_pred\n",
    "    fusion_weight = mock_args.fusion_weight\n",
    "    mode1_predictions = pinn_predictions + (1 - fusion_weight) * residual_predictions\n",
    "    \n",
    "    total_time = pinn_train_time + kriging_train_time\n",
    "    print(f\"âœ… æ–¹æ¡ˆ1å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’\")\n",
    "    \n",
    "    # 9. æ€§èƒ½è¯„ä¼°\n",
    "    print(\"\\nğŸ“ˆ æ–¹æ¡ˆ1æ€§èƒ½è¯„ä¼°...\")\n",
    "    \n",
    "    # è®¡ç®—å„ç§æŒ‡æ ‡\n",
    "    from ComposeTools import MetricsCalculator\n",
    "    \n",
    "    pinn_metrics = MetricsCalculator.compute_metrics(test_vals_small, pinn_predictions)\n",
    "    mode1_metrics = MetricsCalculator.compute_metrics(test_vals_small, mode1_predictions)\n",
    "    \n",
    "    print(\"\\nğŸ“Š PINNåŸºçº¿æ€§èƒ½:\")\n",
    "    for metric, value in pinn_metrics.items():\n",
    "        print(f\"   {metric}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š æ–¹æ¡ˆ1èåˆåæ€§èƒ½:\")\n",
    "    for metric, value in mode1_metrics.items():\n",
    "        print(f\"   {metric}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š æ€§èƒ½å˜åŒ–:\")\n",
    "    for metric in pinn_metrics:\n",
    "        if metric in ['MAE', 'RMSE', 'MAPE']:  # è¶Šå°è¶Šå¥½\n",
    "            change = (pinn_metrics[metric] - mode1_metrics[metric]) / pinn_metrics[metric] * 100\n",
    "            print(f\"   {metric} å˜åŒ–: {change:+.2f}%\")\n",
    "        elif metric == 'R2':  # è¶Šå¤§è¶Šå¥½\n",
    "            change = (mode1_metrics[metric] - pinn_metrics[metric]) / abs(pinn_metrics[metric]) * 100\n",
    "            print(f\"   {metric} å˜åŒ–: {change:+.2f}%\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœä¾›åç»­åˆ†æ\n",
    "    mode1_results = {\n",
    "        'pinn_predictions': pinn_predictions,\n",
    "        'residual_predictions': residual_predictions,\n",
    "        'final_predictions': mode1_predictions,\n",
    "        'pinn_metrics': pinn_metrics,\n",
    "        'final_metrics': mode1_metrics,\n",
    "        'timing': {\n",
    "            'pinn_train': pinn_train_time,\n",
    "            'kriging_train': kriging_train_time,\n",
    "            'total': total_time\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\nâœ… æ–¹æ¡ˆ1æµ‹è¯•å®Œæˆ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ–¹æ¡ˆ1æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\n",
      "============================================================\n",
      "æµ‹è¯•é…ç½®: {'num_samples': 100, 'pinn_epochs': 500, 'fusion_weight': 0.6, 'test_grid_size': 1000}\n",
      "  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: 27\n",
      "é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\n",
      "âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: ../PINN/DATA.xlsx\n",
      "âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« 72 ä¸ªzå±‚\n",
      "âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—\n",
      "Loading radiation data from dictionary format...\n",
      "Found 72 z-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "Detected pandas DataFrame format\n",
      "Data dimensions: X=136, Y=112, Z=72\n",
      "Using default world bounds: [-10.  -5.  -5.] to [10.  5.  5.]\n",
      "Data statistics:\n",
      "  - Total voxels: 1,096,704\n",
      "  - Non-zero voxels: 1,096,704 (100.00%)\n",
      "  - Value range: 2.63e+01 to 1.57e+06\n",
      "  - Voxel size: [0.14705882 0.08928571 0.13888889]\n",
      "Sampled 300 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.31e+01 to 1.19e+03\n",
      "Sampled 150 training points using 'positive_only' strategy\n",
      "Dose range in samples: 3.51e+01 to 2.82e+03\n",
      "âœ… æ•°æ®å¤„ç†å®Œæˆ:\n",
      "   - è®­ç»ƒæ ·æœ¬: 300 ä¸ªç‚¹\n",
      "   - æµ‹è¯•æ ·æœ¬: 150 ä¸ªç‚¹\n",
      "   - è®­ç»ƒå€¼èŒƒå›´: [3.31e+01, 1.19e+03]\n",
      "   - æµ‹è¯•å€¼èŒƒå›´: [3.51e+01, 2.82e+03]\n",
      "   - ç½‘æ ¼å½¢çŠ¶: [136 112  72]\n",
      "   - ç©ºé—´å°ºå¯¸: [20. 10. 10.]\n",
      "âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\n",
      "  - è®­ç»ƒç‚¹: (300, 3)\n",
      "  - è®­ç»ƒå€¼: (300,)\n",
      "  - ç©ºé—´ç»´åº¦: [20.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•4: æ–¹æ¡ˆ1ç®€å•æµ‹è¯• - PINN + Krigingèåˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨è¾ƒå°çš„å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•\n",
    "    test_config = {\n",
    "        'num_samples': 100,\n",
    "        'pinn_epochs': 500,\n",
    "        'fusion_weight': 0.6,\n",
    "        'test_grid_size': 1000\n",
    "    }\n",
    "    \n",
    "    print(f\"æµ‹è¯•é…ç½®: {test_config}\")\n",
    "    \n",
    "    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç‚¹ç½‘æ ¼\n",
    "    test_grid_1d = np.linspace(dose_data['world_min'], dose_data['world_max'], 10)\n",
    "    X, Y, Z = np.meshgrid(test_grid_1d[0], test_grid_1d[1], test_grid_1d[2], indexing='ij')\n",
    "    simple_test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "    \n",
    "    print(f\"  - ç®€åŒ–æµ‹è¯•ç½‘æ ¼ç‚¹æ•°: {len(simple_test_points)}\")\n",
    "    \n",
    "    # ä½¿ç”¨main.pyä¸­çš„åŠ è½½å‡½æ•°\n",
    "    from main import load_real_data_from_excel\n",
    "    \n",
    "    # é‡æ–°åŠ è½½æ•°æ®ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®\n",
    "    print(\"é‡æ–°åŠ è½½å¹¶éªŒè¯æ•°æ®æ ¼å¼...\")\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - è®­ç»ƒå€¼: {train_vals.shape}\")\n",
    "    print(f\"  - ç©ºé—´ç»´åº¦: {field_info['space_dims']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•4å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•9: æ–¹æ¡ˆ2è€¦åˆæ–¹æ³•æµ‹è¯• (Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ)\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•9: æ–¹æ¡ˆ2è€¦åˆæ–¹æ³•æµ‹è¯• (Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from main import run_mode2\n",
    "    from ComposeTools import ComposeConfig, CouplingWorkflow, KrigingAdapter, PINNAdapter\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°\n",
    "    class MockArgs2:\n",
    "        def __init__(self):\n",
    "            self.use_real_data = True\n",
    "            self.data_file = \"../PINN/DATA.xlsx\"\n",
    "            self.num_samples = 100\n",
    "            self.noise_level = 0.05\n",
    "            self.random_seed = 42\n",
    "            self.gpu_enabled = True\n",
    "            self.verbose = True\n",
    "            self.roi_strategy = 'high_density'  # ROIæ£€æµ‹ç­–ç•¥\n",
    "            self.augment_factor = 2.0  # æ ·æœ¬æ‰©å……å€æ•°\n",
    "            self.pinn_epochs = 1000\n",
    "            self.variogram_model = 'gaussian'\n",
    "            self.save_plots = False\n",
    "            self.show_plots = False\n",
    "    \n",
    "    mock_args2 = MockArgs2()\n",
    "    \n",
    "    print(\"ğŸ“Š é…ç½®æ–¹æ¡ˆ2æµ‹è¯•å‚æ•°:\")\n",
    "    print(f\"  - ROIç­–ç•¥: {mock_args2.roi_strategy}\")\n",
    "    print(f\"  - æ ·æœ¬æ‰©å……å€æ•°: {mock_args2.augment_factor}\")\n",
    "    print(f\"  - PINNè®­ç»ƒè½®æ•°: {mock_args2.pinn_epochs}\")\n",
    "    print(f\"  - é‡‡æ ·ç‚¹æ•°: {mock_args2.num_samples}\")\n",
    "    print(f\"  - ä½¿ç”¨GPU: {mock_args2.gpu_enabled}\")\n",
    "    \n",
    "    # æ‰‹åŠ¨å®ç°æ–¹æ¡ˆ2æµç¨‹\n",
    "    print(\"\\nğŸ”„ æ‰‹åŠ¨æ‰§è¡Œæ–¹æ¡ˆ2æµç¨‹...\")\n",
    "    \n",
    "    # 1. é‡æ–°åŠ è½½æ•°æ®ï¼ˆç¡®ä¿ç‹¬ç«‹æµ‹è¯•ï¼‰\n",
    "    from main import load_real_data_from_excel\n",
    "    train_pts, train_vals, test_pts, test_vals, field_info = load_real_data_from_excel()\n",
    "    \n",
    "    # ä½¿ç”¨è¾ƒå°çš„æµ‹è¯•é›†\n",
    "    test_pts_small = test_pts[:500]\n",
    "    test_vals_small = test_vals[:500]\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
    "    print(f\"  - è®­ç»ƒç‚¹: {train_pts.shape}\")\n",
    "    print(f\"  - æµ‹è¯•ç‚¹: {test_pts_small.shape}\")\n",
    "    \n",
    "    # 2. é…ç½®ç³»ç»Ÿ\n",
    "    config2 = ComposeConfig(\n",
    "        gpu_enabled=mock_args2.gpu_enabled,\n",
    "        verbose=mock_args2.verbose,\n",
    "        random_seed=mock_args2.random_seed,\n",
    "        roi_detection_strategy=mock_args2.roi_strategy,\n",
    "        sample_augment_factor=mock_args2.augment_factor,\n",
    "        pinn_epochs=mock_args2.pinn_epochs,\n",
    "        kriging_variogram_model=mock_args2.variogram_model\n",
    "    )\n",
    "    \n",
    "    # 3. ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒåŸºçº¿PINNæ¨¡å‹\n",
    "    print(\"\\nğŸš€ é˜¶æ®µ1: è®­ç»ƒåŸºçº¿PINNæ¨¡å‹...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    baseline_pinn = PINNAdapter(config2)\n",
    "    baseline_pinn.fit(\n",
    "        train_pts, train_vals,\n",
    "        space_dims=field_info['space_dims'],\n",
    "        world_bounds=field_info['world_bounds']\n",
    "    )\n",
    "    \n",
    "    baseline_train_time = time.time() - start_time\n",
    "    baseline_predictions = baseline_pinn.predict(test_pts_small)\n",
    "    print(f\"âœ… åŸºçº¿PINNè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {baseline_train_time:.2f}ç§’\")\n",
    "    \n",
    "    # 4. ç¬¬äºŒé˜¶æ®µï¼šæ£€æµ‹ROIåŒºåŸŸ\n",
    "    print(f\"\\nğŸ¯ é˜¶æ®µ2: æ£€æµ‹ROIåŒºåŸŸ (ç­–ç•¥={mock_args2.roi_strategy})...\")\n",
    "    \n",
    "    # åŸºäºå¯†åº¦çš„ROIæ£€æµ‹ - ç®€åŒ–å®ç°\n",
    "    if mock_args2.roi_strategy == 'high_density':\n",
    "        # æ‰¾åˆ°é«˜å¯†åº¦åŒºåŸŸï¼ˆè¿™é‡Œç®€åŒ–ä¸ºé«˜å€¼åŒºåŸŸï¼‰\n",
    "        value_threshold = np.percentile(train_vals, 70)  # å‰30%é«˜å€¼åŒºåŸŸ\n",
    "        high_value_mask = train_vals >= value_threshold\n",
    "        roi_points = train_pts[high_value_mask]\n",
    "        roi_values = train_vals[high_value_mask]\n",
    "        \n",
    "        # æ‰©å±•ROIè¾¹ç•Œ\n",
    "        roi_min = np.min(roi_points, axis=0) - 1.0  # å‘å¤–æ‰©å±•1ç±³\n",
    "        roi_max = np.max(roi_points, axis=0) + 1.0\n",
    "        \n",
    "        print(f\"  - é«˜å€¼é˜ˆå€¼: {value_threshold:.2e}\")\n",
    "        print(f\"  - ROIå†…åŸå§‹ç‚¹æ•°: {len(roi_points)}\")\n",
    "        print(f\"  - ROIè¾¹ç•Œ: [{roi_min[0]:.1f}, {roi_min[1]:.1f}, {roi_min[2]:.1f}] åˆ° [{roi_max[0]:.1f}, {roi_max[1]:.1f}, {roi_max[2]:.1f}]\")\n",
    "    \n",
    "    # 5. ç¬¬ä¸‰é˜¶æ®µï¼šåœ¨ROIå†…ç”ŸæˆKrigingæ ·æœ¬\n",
    "    print(f\"\\nğŸ—ºï¸ é˜¶æ®µ3: åœ¨ROIå†…ç”ŸæˆKrigingæ‰©å……æ ·æœ¬...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # åˆ›å»ºKrigingæ¨¡å‹ç”¨äºæ ·æœ¬æ‰©å……\n",
    "    kriging_sampler = KrigingAdapter(config2)\n",
    "    kriging_sampler.fit(train_pts, train_vals)\n",
    "    \n",
    "    # åœ¨ROIå†…ç”Ÿæˆæ–°çš„é‡‡æ ·ç‚¹\n",
    "    target_new_points = int(len(train_pts) * (mock_args2.augment_factor - 1))\n",
    "    \n",
    "    # åœ¨ROIå†…éšæœºç”Ÿæˆå€™é€‰ç‚¹\n",
    "    np.random.seed(mock_args2.random_seed)\n",
    "    new_points = []\n",
    "    for _ in range(target_new_points):\n",
    "        # åœ¨ROIè¾¹ç•Œå†…éšæœºé‡‡æ ·\n",
    "        random_point = roi_min + np.random.rand(3) * (roi_max - roi_min)\n",
    "        new_points.append(random_point)\n",
    "    \n",
    "    new_points = np.array(new_points)\n",
    "    \n",
    "    # ä½¿ç”¨Krigingé¢„æµ‹æ–°ç‚¹çš„å€¼\n",
    "    new_values = kriging_sampler.predict(new_points)\n",
    "    \n",
    "    kriging_sample_time = time.time() - start_time\n",
    "    print(f\"âœ… Krigingé‡‡æ ·å®Œæˆï¼Œè€—æ—¶: {kriging_sample_time:.2f}ç§’\")\n",
    "    print(f\"  - ç”Ÿæˆæ–°æ ·æœ¬ç‚¹æ•°: {len(new_points)}\")\n",
    "    print(f\"  - æ–°æ ·æœ¬å€¼èŒƒå›´: [{np.min(new_values):.2e}, {np.max(new_values):.2e}]\")\n",
    "    \n",
    "    # 6. åˆå¹¶æ‰©å……åçš„è®­ç»ƒé›†\n",
    "    augmented_points = np.vstack([train_pts, new_points])\n",
    "    augmented_values = np.hstack([train_vals, new_values])\n",
    "    \n",
    "    print(f\"  - æ‰©å……åæ€»æ ·æœ¬æ•°: {len(augmented_points)}\")\n",
    "    print(f\"  - å®é™…æ‰©å……å€æ•°: {len(augmented_points) / len(train_pts):.2f}\")\n",
    "    \n",
    "    # 7. ç¬¬å››é˜¶æ®µï¼šä½¿ç”¨æ‰©å……æ•°æ®é‡æ–°è®­ç»ƒPINN\n",
    "    print(\"\\nğŸ”¥ é˜¶æ®µ4: ä½¿ç”¨æ‰©å……æ•°æ®é‡æ–°è®­ç»ƒPINN...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    enhanced_pinn = PINNAdapter(config2)\n",
    "    enhanced_pinn.fit(\n",
    "        augmented_points, augmented_values,\n",
    "        space_dims=field_info['space_dims'],\n",
    "        world_bounds=field_info['world_bounds']\n",
    "    )\n",
    "    \n",
    "    enhanced_train_time = time.time() - start_time\n",
    "    enhanced_predictions = enhanced_pinn.predict(test_pts_small)\n",
    "    print(f\"âœ… å¢å¼ºPINNè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {enhanced_train_time:.2f}ç§’\")\n",
    "    \n",
    "    total_time = baseline_train_time + kriging_sample_time + enhanced_train_time\n",
    "    print(f\"âœ… æ–¹æ¡ˆ2å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’\")\n",
    "    \n",
    "    # 8. æ€§èƒ½è¯„ä¼°\n",
    "    print(\"\\nğŸ“ˆ æ–¹æ¡ˆ2æ€§èƒ½è¯„ä¼°...\")\n",
    "    \n",
    "    # è®¡ç®—å„ç§æŒ‡æ ‡\n",
    "    from ComposeTools import MetricsCalculator\n",
    "    \n",
    "    baseline_metrics = MetricsCalculator.compute_metrics(test_vals_small, baseline_predictions)\n",
    "    enhanced_metrics = MetricsCalculator.compute_metrics(test_vals_small, enhanced_predictions)\n",
    "    \n",
    "    print(\"\\nğŸ“Š åŸºçº¿PINNæ€§èƒ½:\")\n",
    "    for metric, value in baseline_metrics.items():\n",
    "        print(f\"   {metric}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š æ–¹æ¡ˆ2å¢å¼ºåæ€§èƒ½:\")\n",
    "    for metric, value in enhanced_metrics.items():\n",
    "        print(f\"   {metric}: {value:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š æ€§èƒ½å˜åŒ–:\")\n",
    "    for metric in baseline_metrics:\n",
    "        if metric in ['MAE', 'RMSE', 'MAPE']:  # è¶Šå°è¶Šå¥½\n",
    "            change = (baseline_metrics[metric] - enhanced_metrics[metric]) / baseline_metrics[metric] * 100\n",
    "            print(f\"   {metric} å˜åŒ–: {change:+.2f}%\")\n",
    "        elif metric == 'R2':  # è¶Šå¤§è¶Šå¥½\n",
    "            change = (enhanced_metrics[metric] - baseline_metrics[metric]) / abs(baseline_metrics[metric]) * 100\n",
    "            print(f\"   {metric} å˜åŒ–: {change:+.2f}%\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœä¾›åç»­åˆ†æ\n",
    "    mode2_results = {\n",
    "        'baseline_predictions': baseline_predictions,\n",
    "        'enhanced_predictions': enhanced_predictions,\n",
    "        'augmented_points': augmented_points,\n",
    "        'augmented_values': augmented_values,\n",
    "        'roi_info': {\n",
    "            'strategy': mock_args2.roi_strategy,\n",
    "            'roi_min': roi_min,\n",
    "            'roi_max': roi_max,\n",
    "            'roi_points_count': len(roi_points)\n",
    "        },\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'enhanced_metrics': enhanced_metrics,\n",
    "        'timing': {\n",
    "            'baseline_train': baseline_train_time,\n",
    "            'kriging_sample': kriging_sample_time,\n",
    "            'enhanced_train': enhanced_train_time,\n",
    "            'total': total_time\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\nâœ… æ–¹æ¡ˆ2æµ‹è¯•å®Œæˆ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ–¹æ¡ˆ2æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•10: ä¸¤ç§è€¦åˆæ–¹æ³•æ€§èƒ½å¯¹æ¯”åˆ†æ\n",
    "print(\"=\" * 60)\n",
    "print(\"æµ‹è¯•10: ä¸¤ç§è€¦åˆæ–¹æ³•æ€§èƒ½å¯¹æ¯”åˆ†æ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ç¡®ä¿å‰é¢çš„æµ‹è¯•å·²ç»è¿è¡Œå¹¶è·å¾—ç»“æœ\n",
    "    if 'mode1_results' in locals() and 'mode2_results' in locals():\n",
    "        print(\"âœ… æ£€æµ‹åˆ°æ–¹æ¡ˆ1å’Œæ–¹æ¡ˆ2çš„æµ‹è¯•ç»“æœï¼Œå¼€å§‹å¯¹æ¯”åˆ†æ...\")\n",
    "        \n",
    "        print(\"\\nğŸ“Š ==== ä¸¤ç§è€¦åˆæ–¹æ¡ˆæ€§èƒ½å¯¹æ¯” ====\")\n",
    "        \n",
    "        # 1. æ—¶é—´æ€§èƒ½å¯¹æ¯”\n",
    "        print(\"\\nâ±ï¸ æ—¶é—´æ€§èƒ½å¯¹æ¯”:\")\n",
    "        print(f\"  æ–¹æ¡ˆ1 (PINNâ†’æ®‹å·®Krigingâ†’èåˆ):\")\n",
    "        print(f\"    - PINNè®­ç»ƒæ—¶é—´: {mode1_results['timing']['pinn_train']:.2f}ç§’\")\n",
    "        print(f\"    - Krigingè®­ç»ƒæ—¶é—´: {mode1_results['timing']['kriging_train']:.2f}ç§’\")\n",
    "        print(f\"    - æ€»è®¡æ—¶é—´: {mode1_results['timing']['total']:.2f}ç§’\")\n",
    "        \n",
    "        print(f\"  æ–¹æ¡ˆ2 (Krigingæ‰©å……â†’PINNé‡è®­ç»ƒ):\")\n",
    "        print(f\"    - åŸºçº¿PINNè®­ç»ƒæ—¶é—´: {mode2_results['timing']['baseline_train']:.2f}ç§’\")\n",
    "        print(f\"    - Krigingé‡‡æ ·æ—¶é—´: {mode2_results['timing']['kriging_sample']:.2f}ç§’\")\n",
    "        print(f\"    - å¢å¼ºPINNè®­ç»ƒæ—¶é—´: {mode2_results['timing']['enhanced_train']:.2f}ç§’\")\n",
    "        print(f\"    - æ€»è®¡æ—¶é—´: {mode2_results['timing']['total']:.2f}ç§’\")\n",
    "        \n",
    "        time_ratio = mode2_results['timing']['total'] / mode1_results['timing']['total']\n",
    "        print(f\"  æ—¶é—´æ¯”å€¼ (æ–¹æ¡ˆ2/æ–¹æ¡ˆ1): {time_ratio:.2f}\")\n",
    "        \n",
    "        # 2. é¢„æµ‹ç²¾åº¦å¯¹æ¯”\n",
    "        print(\"\\nğŸ“ˆ é¢„æµ‹ç²¾åº¦å¯¹æ¯”:\")\n",
    "        \n",
    "        # è·å–æŒ‡æ ‡åç§°\n",
    "        metrics_names = list(mode1_results['final_metrics'].keys())\n",
    "        \n",
    "        print(\"  æŒ‡æ ‡ | æ–¹æ¡ˆ1èåˆ | æ–¹æ¡ˆ2å¢å¼º | æ”¹è¿›å¹…åº¦\")\n",
    "        print(\"  \" + \"-\" * 50)\n",
    "        \n",
    "        for metric in metrics_names:\n",
    "            mode1_val = mode1_results['final_metrics'][metric]\n",
    "            mode2_val = mode2_results['enhanced_metrics'][metric]\n",
    "            \n",
    "            if metric in ['MAE', 'RMSE', 'MAPE']:  # è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡\n",
    "                improvement = (mode1_val - mode2_val) / mode1_val * 100\n",
    "                better_mark = \"ğŸŸ¢\" if mode2_val < mode1_val else \"ğŸ”´\"\n",
    "            elif metric == 'R2':  # è¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡\n",
    "                improvement = (mode2_val - mode1_val) / abs(mode1_val) * 100\n",
    "                better_mark = \"ğŸŸ¢\" if mode2_val > mode1_val else \"ğŸ”´\"\n",
    "            else:\n",
    "                improvement = 0\n",
    "                better_mark = \"âšª\"\n",
    "            \n",
    "            print(f\"  {metric:>6} | {mode1_val:>8.6f} | {mode2_val:>8.6f} | {improvement:>+6.2f}% {better_mark}\")\n",
    "        \n",
    "        # 3. æ ·æœ¬æ•ˆç‡åˆ†æ\n",
    "        print(\"\\nğŸ“Š æ ·æœ¬æ•ˆç‡åˆ†æ:\")\n",
    "        original_samples = len(train_pts)\n",
    "        mode2_samples = len(mode2_results['augmented_points'])\n",
    "        sample_efficiency = mode2_samples / original_samples\n",
    "        \n",
    "        print(f\"  åŸå§‹è®­ç»ƒæ ·æœ¬æ•°: {original_samples}\")\n",
    "        print(f\"  æ–¹æ¡ˆ2æ‰©å……åæ ·æœ¬æ•°: {mode2_samples}\")\n",
    "        print(f\"  æ ·æœ¬æ‰©å……å€æ•°: {sample_efficiency:.2f}\")\n",
    "        print(f\"  ROIç­–ç•¥: {mode2_results['roi_info']['strategy']}\")\n",
    "        print(f\"  ROIå†…ç‚¹æ•°: {mode2_results['roi_info']['roi_points_count']}\")\n",
    "        \n",
    "        # 4. æ–¹æ³•ç‰¹ç‚¹æ€»ç»“\n",
    "        print(\"\\nğŸ” æ–¹æ³•ç‰¹ç‚¹æ€»ç»“:\")\n",
    "        print(\"  æ–¹æ¡ˆ1 (PINNâ†’æ®‹å·®Krigingâ†’èåˆ):\")\n",
    "        print(\"    + ä¿æŒåŸå§‹è®­ç»ƒæ•°æ®ä¸å˜\")\n",
    "        print(\"    + è®¡ç®—ç›¸å¯¹å¿«é€Ÿ\")\n",
    "        print(\"    + å¯è§£é‡Šæ€§å¼ºï¼ˆæ®‹å·®åˆ†æï¼‰\")\n",
    "        print(\"    - éœ€è¦è°ƒæ•´èåˆæƒé‡\")\n",
    "        print(\"    - å¯èƒ½å—åˆ°PINNåˆå§‹è¯¯å·®å½±å“\")\n",
    "        \n",
    "        print(\"\\n  æ–¹æ¡ˆ2 (Krigingæ‰©å……â†’PINNé‡è®­ç»ƒ):\")\n",
    "        print(\"    + å¢åŠ è®­ç»ƒæ•°æ®é‡ï¼Œæå‡æ³›åŒ–èƒ½åŠ›\")\n",
    "        print(\"    + ä¸“æ³¨äºROIåŒºåŸŸï¼Œé’ˆå¯¹æ€§å¼º\")\n",
    "        print(\"    + æœ€ç»ˆæ¨¡å‹ç»Ÿä¸€ï¼Œæ— éœ€èåˆ\")\n",
    "        print(\"    - è®¡ç®—æ—¶é—´è¾ƒé•¿ï¼ˆéœ€è¦é‡è®­ç»ƒï¼‰\")\n",
    "        print(\"    - ä¾èµ–ROIæ£€æµ‹è´¨é‡\")\n",
    "        print(\"    - å¯èƒ½è¿‡æ‹Ÿåˆæ‰©å……æ•°æ®\")\n",
    "        \n",
    "        # 5. ä½¿ç”¨å»ºè®®\n",
    "        print(\"\\nğŸ’¡ ä½¿ç”¨å»ºè®®:\")\n",
    "        if time_ratio < 1.5 and mode2_results['enhanced_metrics']['R2'] > mode1_results['final_metrics']['R2']:\n",
    "            print(\"  ğŸŸ¢ æ¨èä½¿ç”¨æ–¹æ¡ˆ2ï¼šæ—¶é—´æˆæœ¬å¯æ¥å—ä¸”ç²¾åº¦æ›´é«˜\")\n",
    "        elif mode1_results['timing']['total'] < 60:  # å¦‚æœæ–¹æ¡ˆ1å¾ˆå¿«\n",
    "            print(\"  ğŸŸ¢ æ¨èä½¿ç”¨æ–¹æ¡ˆ1ï¼šå¿«é€ŸåŸå‹å’Œå®æ—¶åº”ç”¨\")\n",
    "        else:\n",
    "            print(\"  âšª æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©ï¼š\")\n",
    "            print(\"    - è¿½æ±‚é€Ÿåº¦ â†’ æ–¹æ¡ˆ1\")\n",
    "            print(\"    - è¿½æ±‚ç²¾åº¦ â†’ æ–¹æ¡ˆ2\")\n",
    "            print(\"    - æ•°æ®ç¨€å°‘ â†’ æ–¹æ¡ˆ2\")\n",
    "            print(\"    - å®æ—¶åº”ç”¨ â†’ æ–¹æ¡ˆ1\")\n",
    "        \n",
    "        print(\"\\nâœ… ä¸¤ç§è€¦åˆæ–¹æ¡ˆå¯¹æ¯”åˆ†æå®Œæˆ!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°æ–¹æ¡ˆ1æˆ–æ–¹æ¡ˆ2çš„æµ‹è¯•ç»“æœ\")\n",
    "        print(\"è¯·å…ˆè¿è¡Œå‰é¢çš„æµ‹è¯•8å’Œæµ‹è¯•9\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯¹æ¯”åˆ†æå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€»ç»“å’Œæ–‡æ¡£æ›´æ–°\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ è€¦åˆæ–¹æ³•æµ‹è¯•å®Œæˆæ€»ç»“\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… å·²å®Œæˆçš„æµ‹è¯•å†…å®¹:\n",
    "\n",
    "1. åŸºç¡€ç¯å¢ƒå’Œæ•°æ®æµ‹è¯•:\n",
    "   - ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å¯¼å…¥ âœ…\n",
    "   - çœŸå®DATA.xlsxæ•°æ®åŠ è½½å’Œå¤„ç† âœ…\n",
    "   - æ•°æ®æ ¼å¼éªŒè¯å’Œæ ‡å‡†åŒ– âœ…\n",
    "   - åŸºç¡€PINNæ¨¡å‹è®­ç»ƒæµ‹è¯• âœ…\n",
    "\n",
    "2. è€¦åˆæ–¹æ³•æ€§èƒ½æµ‹è¯•:\n",
    "   - æ–¹æ¡ˆ1: PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ âœ…\n",
    "   - æ–¹æ¡ˆ2: Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ âœ…\n",
    "   - ä¸¤ç§æ–¹æ¡ˆçš„æ€§èƒ½å¯¹æ¯”åˆ†æ âœ…\n",
    "\n",
    "ğŸ“Š æµ‹è¯•æ–‡ä»¶ç»“æ„:\n",
    "   - æµ‹è¯•1-6: åŸºç¡€åŠŸèƒ½éªŒè¯\n",
    "   - æµ‹è¯•7: çº¯PINNè®­ç»ƒéªŒè¯\n",
    "   - æµ‹è¯•8: æ–¹æ¡ˆ1è€¦åˆæ–¹æ³•æµ‹è¯•\n",
    "   - æµ‹è¯•9: æ–¹æ¡ˆ2è€¦åˆæ–¹æ³•æµ‹è¯•  \n",
    "   - æµ‹è¯•10: ä¸¤ç§æ–¹æ¡ˆæ€§èƒ½å¯¹æ¯”\n",
    "\n",
    "ğŸš€ ä½¿ç”¨æ–¹æ³•:\n",
    "   \n",
    "   # æ–¹æ³•1: è¿è¡ŒJupyter Notebook (æ¨è)\n",
    "   jupyter notebook test.ipynb\n",
    "   \n",
    "   # æ–¹æ³•2: è¿è¡Œä¸»ç¨‹åºå®Œæ•´æµ‹è¯•\n",
    "   python main.py --mode mode1 --fusion_weight 0.6 --use_real_data\n",
    "   python main.py --mode mode2 --roi_strategy high_density --augment_factor 2.0 --use_real_data\n",
    "   \n",
    "   # æ–¹æ³•3: å¿«é€ŸéªŒè¯\n",
    "   python main.py --mode common\n",
    "\n",
    "ğŸ“ˆ è€¦åˆæ–¹æ³•å¯¹æ¯”è¦ç‚¹:\n",
    "   - æ–¹æ¡ˆ1é€‚åˆå¿«é€ŸåŸå‹å’Œå®æ—¶åº”ç”¨\n",
    "   - æ–¹æ¡ˆ2é€‚åˆé«˜ç²¾åº¦è¦æ±‚å’Œæ•°æ®ç¨€å°‘åœºæ™¯\n",
    "   - ä¸¤ç§æ–¹æ¡ˆéƒ½èƒ½æœ‰æ•ˆæ”¹å–„çº¯PINNçš„é¢„æµ‹æ€§èƒ½\n",
    "   - å®é™…é€‰æ‹©åº”æ ¹æ®æ—¶é—´é¢„ç®—å’Œç²¾åº¦è¦æ±‚æƒè¡¡\n",
    "\n",
    "âš ï¸ æ³¨æ„äº‹é¡¹:\n",
    "   - ç¡®ä¿CUDAç¯å¢ƒæ”¯æŒGPUåŠ é€Ÿ\n",
    "   - å¤§æ•°æ®é›†å»ºè®®è°ƒæ•´é‡‡æ ·å‚æ•°\n",
    "   - æ ¹æ®å†…å­˜æƒ…å†µè°ƒæ•´æ‰¹å¤„ç†å¤§å°\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ‰ ç°åœ¨å·²ç»æ‹¥æœ‰å®Œæ•´çš„PINNÃ—Krigingè€¦åˆæ–¹æ³•æ€§èƒ½æµ‹è¯•ï¼\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINNENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
