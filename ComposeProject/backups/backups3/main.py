import sys
print("--- SCRIPT START ---")
import os
import argparse
import numpy as np
from pathlib import Path
# import matplotlib
# matplotlib.use('Agg') # <--- åœ¨å¯¼å…¥pyplotä¹‹å‰è®¾ç½®åç«¯
# import matplotlib.pyplot as plt

# --- è·¯å¾„è®¾ç½® ---
try:
    current_dir = Path(__file__).parent.resolve()
    project_root = current_dir.parent
except NameError:
    project_root = Path('.').resolve()

sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'PINN'))
sys.path.insert(0, str(project_root / 'ComposeProject'))

# --- æ¨¡å—å¯¼å…¥ ---
try:
    from ComposeTools import (
        ComposeConfig,
        CouplingWorkflow,
        print_compose_banner,
        validate_compose_environment,
        MetricsCalculator,
        VisualizationTools
    )
    from PINN.data_processing import DataLoader
    from PINN.dataAnalysis import get_data
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸã€‚")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def main(args):
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    
    # ==================== 1. åˆå§‹åŒ–å’Œç¯å¢ƒæ£€æŸ¥ ====================
    print_compose_banner()
    if not all(validate_compose_environment().values()):
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–é¡¹ã€‚ç¨‹åºé€€å‡ºã€‚")
        return

    config = ComposeConfig(random_seed=args.seed)
    
    # PINN ç‰©ç†å‚æ•° (åº”ä»æ›´å¯é çš„æ¥æºè·å–ï¼Œæ­¤å¤„ä¸ºç¤ºä¾‹)
    physical_params = {
        'rho_material': 1.205,
        'mass_energy_abs_coeff': 1.0
    }

    # ==================== 2. æ•°æ®åŠ è½½å’Œå‡†å¤‡ ====================
    print(f"\n" + "="*25 + " æ­¥éª¤1: æ•°æ®åŠ è½½ " + "="*25)
    if not os.path.exists(args.data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_path}")
        return
        
    raw_data = get_data(args.data_path)
    dose_data = DataLoader.load_dose_from_dict(
        data_dict=raw_data,
        space_dims=np.array([20.0, 10.0, 10.0]) # ç¤ºä¾‹ç»´åº¦
    )
    
    # é‡‡æ ·è®­ç»ƒç‚¹ (ç”¨äºä¸¤ä¸ªæ–¹æ¡ˆçš„åˆå§‹è®­ç»ƒ)
    print(f"é‡‡æ · {args.num_samples} ä¸ªè®­ç»ƒç‚¹...")
    train_points, train_values, _ = DataLoader.sample_training_points(
        dose_data, 
        num_samples=args.num_samples,
        sampling_strategy='positive_only' # ä½¿ç”¨ 'positive_only' ç­–ç•¥
    )
    print(f"âœ… æˆåŠŸé‡‡æ · {len(train_points)} ä¸ªè®­ç»ƒç‚¹ã€‚")

    # å‡†å¤‡å…¨åœºé¢„æµ‹ç‚¹
    original_grid_shape = np.array(dose_data['dose_grid'].shape)
    if args.downsample > 1:
        print(f"âš ï¸ è­¦å‘Š: é¢„æµ‹ç½‘æ ¼å°†é€šè¿‡ç³»æ•° {args.downsample} è¿›è¡Œé™é‡‡æ ·ä»¥åŠ é€Ÿè°ƒè¯•ã€‚")
        step = int(args.downsample)
        pred_x_indices = np.arange(0, original_grid_shape[0], step)
        pred_y_indices = np.arange(0, original_grid_shape[1], step)
        pred_z_indices = np.arange(0, original_grid_shape[2], step)
        grid_shape = (len(pred_x_indices), len(pred_y_indices), len(pred_z_indices))
    else:
        pred_x_indices = np.arange(original_grid_shape[0])
        pred_y_indices = np.arange(original_grid_shape[1])
        pred_z_indices = np.arange(original_grid_shape[2])
        grid_shape = original_grid_shape

    pred_x = dose_data['world_min'][0] + (pred_x_indices + 0.5) * dose_data['voxel_size'][0]
    pred_y = dose_data['world_min'][1] + (pred_y_indices + 0.5) * dose_data['voxel_size'][1]
    pred_z = dose_data['world_min'][2] + (pred_z_indices + 0.5) * dose_data['voxel_size'][2]
    XX, YY, ZZ = np.meshgrid(pred_x, pred_y, pred_z, indexing='ij')
    prediction_points = np.vstack([XX.ravel(), YY.ravel(), ZZ.ravel()]).T

    # ==================== 3. åˆå§‹åŒ–å¹¶æ‰§è¡Œå·¥ä½œæµ ====================
    print(f"\n" + "="*25 + f" æ­¥éª¤2: æ‰§è¡Œæ–¹æ¡ˆ {args.mode} " + "="*25)
    workflow = CouplingWorkflow(physical_params=physical_params, config=config)
    
    results = {}
    pinn_params = {
        'epochs': args.pinn_epochs,
        'use_lbfgs': args.use_lbfgs,
        'loss_weights': [1, 100]
    }

    if args.mode == 1:
        results = workflow.run_mode1_pipeline(
            train_points=train_points,
            train_values=train_values,
            prediction_points=prediction_points,
            dose_data=dose_data,
            **pinn_params
        )
    elif args.mode == 2:
        results = workflow.run_mode2_pipeline(
            train_points=train_points,
            train_values=train_values,
            prediction_points=prediction_points,
            dose_data=dose_data,
            roi_strategy=args.roi_strategy,
            augment_factor=args.augment_factor,
            **pinn_params
        )
    else:
        print(f"âŒ æœªçŸ¥çš„æ¨¡å¼: {args.mode}")
        return
        
    print(f"âœ… æ–¹æ¡ˆ {args.mode} æ‰§è¡Œå®Œæ¯•ã€‚")
    
    # ==================== 4. è¯„ä¼°å’Œå¯è§†åŒ– ====================
    print(f"\n" + "="*25 + " æ­¥éª¤3: ç»“æœè¯„ä¼° " + "="*25)
    
    # å‡†å¤‡ç”¨äºè¯„ä¼°çš„çœŸå€¼
    if args.downsample > 1:
        true_field_for_eval = dose_data['dose_grid'][np.ix_(pred_x_indices, pred_y_indices, pred_z_indices)]
        test_values = true_field_for_eval.flatten()
    else:
        test_values = dose_data['dose_grid'].flatten()

    # ==================== DEBUG: PINNåŸºçº¿ vs èåˆç»“æœæ€§èƒ½å¯¹æ¯” ====================
    print("\n" + "#"*20 + " DEBUG: æ€§èƒ½å¯¹æ¯”æµ‹è¯• " + "#"*20)
    
    pinn_predictions = results.get('pinn_predictions')
    final_predictions = results.get('final_predictions')

    if pinn_predictions is not None and final_predictions is not None:
        print(f"è¯„ä¼°ç‚¹æ•°: {len(test_values)}")

        # 1. è®¡ç®—PINNåŸºçº¿æ€§èƒ½
        pinn_metrics = MetricsCalculator.compute_metrics(test_values, pinn_predictions)
        print("\n--- PINNåŸºçº¿æ€§èƒ½ (æ— æ®‹å·®ä¿®æ­£) ---")
        for name, value in pinn_metrics.items():
            print(f"  - {name}: {value:.6f}")

        # 2. è®¡ç®—æœ€ç»ˆèåˆåæ€§èƒ½
        final_metrics = MetricsCalculator.compute_metrics(test_values, final_predictions)
        
        # æ ¹æ®æ¨¡å¼ç¡®å®šæ ‡é¢˜
        if args.mode == 1:
            print("\n--- èåˆåæ€§èƒ½ (PINN + Krigingæ®‹å·®ä¿®æ­£) ---")
        elif args.mode == 2:
            print("\n--- å¢å¼ºåæ€§èƒ½ (PINNé‡è®­ç»ƒå) ---")
        else:
            print("\n--- æœ€ç»ˆæ€§èƒ½ ---")
            
        for name, value in final_metrics.items():
            print(f"  - {name}: {value:.6f}")

        # 3. è®¡ç®—æ€§èƒ½æå‡
        print("\n--- æ€§èƒ½æå‡åˆ†æ ---")
        for metric in pinn_metrics:
            if metric in final_metrics:
                pinn_val = pinn_metrics[metric]
                final_val = final_metrics[metric]
                
                # å¯¹äºè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ (MAE, RMSE, MAPE)
                if 'MAE' in metric or 'RMSE' in metric or 'MAPE' in metric:
                    if abs(pinn_val) > 1e-9:
                        improvement = (pinn_val - final_val) / pinn_val * 100
                        print(f"  - {metric} æå‡: {improvement:+.2f}% (è¶Šä½è¶Šå¥½)")
                # å¯¹äºè¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡ (R2)
                elif 'R2' in metric:
                    if abs(pinn_val) > 1e-9:
                        improvement = (final_val - pinn_val) / abs(pinn_val) * 100
                        print(f"  - {metric} æå‡: {improvement:+.2f}% (è¶Šé«˜è¶Šå¥½)")
    else:
        print("âš ï¸ æœªèƒ½è·å–PINNæˆ–æœ€ç»ˆé¢„æµ‹ç»“æœï¼Œæ— æ³•è¿›è¡Œæ€§èƒ½å¯¹æ¯”ã€‚")

    print("#"*20 + " DEBUG: æ€§èƒ½å¯¹æ¯”ç»“æŸ " + "#"*20 + "\n")
    # =======================================================================
        
    print("\nğŸ‰ æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¿è¡Œ Kriging-PINN è€¦åˆå·¥ä½œæµ")
    parser.add_argument('--mode', type=int, choices=[1, 2], default=1,
                        help="é€‰æ‹©è¦è¿è¡Œçš„è€¦åˆæ–¹æ¡ˆ (1æˆ–2)")
    parser.add_argument('--data_path', type=str, default="PINN/DATA.xlsx",
                        help="è¾“å…¥æ•°æ®æ–‡ä»¶çš„è·¯å¾„ (Excelæ ¼å¼)")
    parser.add_argument('--num_samples', type=int, default=300,
                        help="ç”¨äºåˆå§‹è®­ç»ƒçš„é‡‡æ ·ç‚¹æ•°é‡")
    parser.add_argument('--pinn_epochs', type=int, default=5000,
                        help="PINNè®­ç»ƒçš„å‘¨æœŸæ•°")
    parser.add_argument('--downsample', type=int, default=1,
                        help="å…¨åœºé¢„æµ‹ç½‘æ ¼çš„é™é‡‡æ ·ç³»æ•°(>1)ï¼Œç”¨äºåŠ é€Ÿè°ƒè¯•ã€‚")
    parser.add_argument('--seed', type=int, default=42,
                        help="éšæœºç§å­ï¼Œä»¥ç¡®ä¿ç»“æœå¯å¤ç°")
    # ä¸ºæ¨¡å¼2æ·»åŠ æ–°çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument('--roi_strategy', type=str, default='high_density',
                        choices=['high_density', 'high_value', 'bounding_box'],
                        help="[æ¨¡å¼2ä¸“ç”¨] ROIæ£€æµ‹ç­–ç•¥")
    parser.add_argument('--augment_factor', type=float, default=2.0,
                        help="[æ¨¡å¼2ä¸“ç”¨] Krigingæ•°æ®å¢å¼ºçš„æ ·æœ¬æ‰©å……å€æ•°")
    parser.add_argument('--use_lbfgs', action='store_true',
                        help="åœ¨PINNè®­ç»ƒä¸­ä½¿ç”¨L-BFGSè¿›è¡Œç²¾ç»†è°ƒä¼˜")
    
    args = parser.parse_args()
    
    try:
        main(args)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()