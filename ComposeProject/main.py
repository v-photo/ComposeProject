#!/usr/bin/env python3
"""
PINN-Kriging è€¦åˆç³»ç»Ÿä¸»å…¥å£è„šæœ¬
Main entry script for PINN-Kriging coupling system

ç”¨æ³•ç¤ºä¾‹ï¼š
1. ä½¿ç”¨é»˜è®¤é…ç½®ï¼špython main.py
2. ä½¿ç”¨é¢„è®¾é…ç½®ï¼špython main.py --preset kriging_only
3. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶ï¼špython main.py --config my_config.py
4. å¿«é€Ÿæµ‹è¯•ï¼špython main.py --preset quick_test
"""

import argparse
import sys
import numpy as np
from pathlib import Path
import time
import json

# å°†é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
# è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç»å¯¹å¯¼å…¥ï¼Œå¦‚ from src.workflows.auto_selection import ...
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir.parent)) # PINN_ts ç›®å½•
sys.path.insert(0, str(current_dir / 'src')) # ComposeProject/src ç›®å½•
sys.path.insert(0, str(current_dir)) # ComposeProject ç›®å½•

# ä»æˆ‘ä»¬é‡æ„çš„æ¨¡å—ä¸­å¯¼å…¥
from config import load_config_dict
from src.data.loader import load_3d_data_from_sheets, process_grid_to_dose_data, sample_training_points, create_prediction_grid
from src.models.pinn import PINNModel
from src.analysis.plotting import plot_training_comparison
from src.utils.display import print_compose_banner
from src.utils.environment import validate_compose_environment

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¨¡å—åŒ–çš„PINNè€¦åˆç³»ç»Ÿ")
    parser.add_argument('--preset', type=str, default='default', help='æŒ‡å®šè¦ä½¿ç”¨çš„config.pyä¸­çš„é¢„è®¾é…ç½®')
    args = parser.parse_args()

    print_compose_banner()
    
    # 1. éªŒè¯ä¾èµ–
    dep_status = validate_compose_environment()
    print("\n--- ğŸ“¦ ä¾èµ–çŠ¶æ€æ£€æŸ¥ ---")
    for dep, status in dep_status.items():
        print(f"  - {dep}: {'âœ… å¯ç”¨' if status else 'âŒ ä¸å¯ç”¨'}")
    
    # 2. åŠ è½½é…ç½®
    print(f"\n--- âš™ï¸ æ­£åœ¨åŠ è½½é…ç½® (é¢„è®¾: {args.preset}) ---")
    config = load_config_dict(args.preset)
    np.random.seed(config.get('system', {}).get('random_seed', 42))
    
    # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„é…ç½®å­—å…¸
    print("--- è°ƒè¯•ä¿¡æ¯ï¼šå½“å‰ä½¿ç”¨çš„å®Œæ•´é…ç½® ---")
    print(json.dumps(config, indent=2))
    print("------------------------------------")
    
    # 3. æ•°æ®åŠ è½½ã€å¤„ç†å’Œé‡‡æ ·
    data_cfg = config.get('data', {})
    dose_grid = load_3d_data_from_sheets(
        file_path=data_cfg.get('file_path'),
        sheet_name_template=data_cfg.get('sheet_name_template'),
        use_cols=data_cfg.get('use_columns'),
        z_size=data_cfg.get('z_size'),
        y_size=data_cfg.get('y_size'),
    )
    
    dose_data = process_grid_to_dose_data(
        dose_grid=dose_grid,
        space_dims=data_cfg.get('space_dims')
    )
    
    train_points, train_values = sample_training_points(
        dose_data=dose_data,
        num_samples=data_cfg.get('num_samples')
    )
    
    prediction_points = create_prediction_grid(
        dose_data=dose_data,
        downsample_factor=data_cfg.get('downsample_factor')
    )

    # 4. åˆå§‹åŒ–å¹¶è®­ç»ƒPINNæ¨¡å‹
    print("\n--- ğŸš€ æ­£åœ¨æ‰§è¡Œ PINN å·¥ä½œæµ ---")
    start_time = time.time()
    
    pinn_config = config.get('pinn', {})
    
    # å‡†å¤‡test_dataï¼Œè¿™é‡Œçš„test_dataæ˜¯å…¨åœºçš„çœŸå€¼ç½‘æ ¼
    # PINNModelå†…éƒ¨ä¼šä½¿ç”¨å®ƒæ¥è®¡ç®—MRE
    true_field_values = dose_data['dose_grid'].flatten()
    dummy_test_data = np.hstack([prediction_points, true_field_values[:len(prediction_points)].reshape(-1, 1)])

    pinn_training_data = np.hstack([train_points, train_values])

    model = PINNModel(
        dose_data=dose_data,
        training_data=pinn_training_data,
        test_data=dummy_test_data, 
        **pinn_config.get('model_params', {})
    )
    
    # ä»é…ç½®ä¸­æå–è®­ç»ƒå‚æ•°å¹¶ç”Ÿæˆé…ç‚¹
    training_params = pinn_config.get('training_params', {})
    model_params = pinn_config.get('model_params', {})
    num_collocation = model_params.get('num_collocation_points')
    
    print(f"INFO: Generating {num_collocation} collocation points for training cycle...")
    collocation_points = np.random.uniform(
        low=dose_data['world_min'],
        high=dose_data['world_max'],
        size=(num_collocation, 3)
    )
    
    model.run_training_cycle(
        max_epochs=training_params.get('total_epochs'),
        detect_every=training_params.get('detect_every'),
        collocation_points=collocation_points,
        checkpoint_path_prefix=config.get('system', {}).get('checkpoint_path')
    )
    
    total_time = time.time() - start_time
    print(f"\n--- âœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ---")
    print(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’")

    # 5. åˆ†æå’Œä¿å­˜
    print("\n--- ğŸ“ˆ æ­£åœ¨åˆ†æä¸ä¿å­˜ç»“æœ ---")
    results_dir = Path("results")
    results_dir.mkdir(parents=True, exist_ok=True)
    exp_name = config.get('experiment', {}).get('name', 'default')

    if hasattr(model, 'mre_history') and model.epoch_history:
        history = {'é«˜çº§PINN': {'epochs': model.epoch_history, 'metrics': model.mre_history}}
        plot_training_comparison(
            history,
            title=f"PINNè®­ç»ƒå†å² ({exp_name})",
            save_path=results_dir / f"training_history_{exp_name}.png"
        )
    
    print("\nğŸ‰ æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ã€‚")

if __name__ == "__main__":
    main()