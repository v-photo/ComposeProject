#!/usr/bin/env python3
"""
GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºä¸»ç¨‹åº
GPU-Accelerated Block Kriging Ã— PINN Coupling Main Program

æ”¯æŒä¸‰ç§è¿è¡Œæ¨¡å¼:
- common: é€šç”¨å·¥å…·æ¼”ç¤ºå’Œç¯å¢ƒæ£€æŸ¥
- mode1: æ–¹æ¡ˆ1æ¼”ç¤º (PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ)
- mode2: æ–¹æ¡ˆ2æ¼”ç¤º (Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ)

ç”¨æ³•:
    python main.py --mode common
    python main.py --mode mode1 --num_samples 300 --fusion_weight 0.6
    python main.py --mode mode2 --roi_strategy high_density --augment_factor 2.5

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import argparse
import sys
import time
import warnings
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from ComposeTools import (
    ComposeConfig, FieldTensor, ProbeSet,
    DataNormalizer, MetricsCalculator, VisualizationTools,
    KrigingAdapter, PINNAdapter, CouplingWorkflow,
    validate_compose_environment, print_compose_banner
)

def generate_synthetic_3d_data(n_samples: int = 300, 
                              space_dims: list = None,
                              noise_level: float = 0.05,
                              random_seed: int = 42) -> tuple:
    """
    ç”Ÿæˆåˆæˆ3Dè¾å°„åœºæ•°æ®ç”¨äºæ¼”ç¤º
    Generate synthetic 3D radiation field data for demonstration
    
    Args:
        n_samples: é‡‡æ ·ç‚¹æ•°é‡
        space_dims: ç©ºé—´ç»´åº¦ [x, y, z]
        noise_level: å™ªå£°æ°´å¹³
        random_seed: éšæœºç§å­
        
    Returns:
        (train_points, train_values, test_points, test_values, field_info)
    """
    if space_dims is None:
        space_dims = [20.0, 10.0, 10.0]
    
    np.random.seed(random_seed)
    
    # å®šä¹‰è¾å°„æºä½ç½®å’Œå¼ºåº¦
    source_positions = np.array([
        [2.0, 0.0, 0.0],   # ä¸»æº
        [-3.0, 2.0, 1.0],  # æ¬¡æº
        [1.0, -2.5, -1.5]  # å¼±æº
    ])
    source_strengths = np.array([100.0, 50.0, 25.0])
    
    # ä¸–ç•Œåæ ‡è¾¹ç•Œ
    world_min = np.array([-10.0, -5.0, -5.0])
    world_max = np.array([10.0, 5.0, 5.0])
    
    # ç”Ÿæˆè®­ç»ƒé‡‡æ ·ç‚¹ï¼ˆéšæœºé‡‡æ ·ï¼‰
    train_points = np.random.rand(n_samples, 3)
    train_points = world_min + train_points * (world_max - world_min)
    
    # ç”Ÿæˆæµ‹è¯•ç½‘æ ¼ç‚¹ï¼ˆè§„åˆ™ç½‘æ ¼ï¼‰
    test_grid_shape = (20, 15, 15)
    x_test = np.linspace(world_min[0], world_max[0], test_grid_shape[0])
    y_test = np.linspace(world_min[1], world_max[1], test_grid_shape[1])
    z_test = np.linspace(world_min[2], world_max[2], test_grid_shape[2])
    
    X, Y, Z = np.meshgrid(x_test, y_test, z_test, indexing='ij')
    test_points = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)
    
    def compute_radiation_field(points, sources, strengths):
        """è®¡ç®—å¤šæºè¾å°„åœº (ç®€åŒ–çš„åå¹³æ–¹å¾‹æ¨¡å‹)"""
        field_values = np.zeros(len(points))
        
        for source_pos, strength in zip(sources, strengths):
            # è®¡ç®—è·ç¦»
            distances = np.linalg.norm(points - source_pos, axis=1)
            # é˜²æ­¢é™¤é›¶ï¼Œæ·»åŠ å°çš„è¡°å‡å¸¸æ•°
            distances = np.maximum(distances, 0.1)
            # åå¹³æ–¹å¾‹ + æŒ‡æ•°è¡°å‡
            field_contribution = strength / (distances**2) * np.exp(-distances / 5.0)
            field_values += field_contribution
        
        # æ·»åŠ èƒŒæ™¯å™ªå£°
        field_values += np.random.normal(0, noise_level * np.mean(field_values), len(points))
        field_values = np.maximum(field_values, 1e-6)  # ç¡®ä¿éè´Ÿ
        
        return field_values
    
    # è®¡ç®—åœºå€¼
    train_values = compute_radiation_field(train_points, source_positions, source_strengths)
    test_values = compute_radiation_field(test_points, source_positions, source_strengths)
    
    field_info = {
        'space_dims': space_dims,
        'world_bounds': {'min': world_min, 'max': world_max},
        'source_positions': source_positions,
        'source_strengths': source_strengths,
        'test_grid_shape': test_grid_shape,
        'noise_level': noise_level
    }
    
    print(f"âœ… ç”Ÿæˆåˆæˆæ•°æ®å®Œæˆ:")
    print(f"   - è®­ç»ƒæ ·æœ¬: {len(train_points)} ä¸ªç‚¹")
    print(f"   - æµ‹è¯•ç½‘æ ¼: {len(test_points)} ä¸ªç‚¹ ({test_grid_shape})")
    print(f"   - è®­ç»ƒå€¼èŒƒå›´: [{np.min(train_values):.2e}, {np.max(train_values):.2e}]")
    print(f"   - æµ‹è¯•å€¼èŒƒå›´: [{np.min(test_values):.2e}, {np.max(test_values):.2e}]")
    
    return train_points, train_values, test_points, test_values, field_info

def load_real_data_from_excel(data_file_path: str = "../PINN/DATA.xlsx") -> tuple:
    """
    åŠ è½½çœŸå®çš„è¾å°„åœºæ•°æ®ä»PINN/DATA.xlsx
    Load real radiation field data from PINN/DATA.xlsx
    
    Args:
        data_file_path: DATA.xlsxæ–‡ä»¶è·¯å¾„
        
    Returns:
        (train_points, train_values, test_points, test_values, field_info)
    """
    import sys
    from pathlib import Path
    
    # æ·»åŠ PINNç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥dataAnalysis
    pinn_dir = Path(__file__).parent.parent / "PINN"
    sys.path.insert(0, str(pinn_dir))
    
    try:
        from dataAnalysis import get_data
        print("âœ… æˆåŠŸå¯¼å…¥dataAnalysisæ¨¡å—")
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥dataAnalysisæ¨¡å—: {e}")
        raise
    
    # åŠ è½½çœŸå®æ•°æ®
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½çœŸå®æ•°æ®: {data_file_path}")
    data_file_full_path = str(pinn_dir / "DATA.xlsx")
    
    try:
        data_dict = get_data(data_file_full_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å« {len(data_dict)} ä¸ªzå±‚")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise
    
    # ä½¿ç”¨PINNçš„RadiationDataProcessorå¤„ç†æ•°æ®
    try:
        from tools import RadiationDataProcessor, DataLoader
        print("âœ… æˆåŠŸå¯¼å…¥PINN toolsæ¨¡å—")
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥PINN toolsæ¨¡å—: {e}")
        raise
    
    # å¤„ç†æ•°æ®
    dose_data = DataLoader.load_dose_from_dict(
        data_dict=data_dict,
        space_dims=[20.0, 10.0, 10.0]  # æ ¹æ®å®é™…ç‰©ç†å°ºå¯¸è°ƒæ•´
    )
    
    # é‡‡æ ·è®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨positive_onlyç­–ç•¥ï¼Œé¿å…é›¶å€¼ï¼‰
    train_points, train_values, _ = DataLoader.sample_training_points(
        dose_data, 
        num_samples=300, 
        sampling_strategy='positive_only'
    )
    
    # é‡‡æ ·æµ‹è¯•æ•°æ®ï¼ˆæ›´å°‘çš„ç‚¹ç”¨äºæµ‹è¯•ï¼‰
    test_points, test_values, _ = DataLoader.sample_training_points(
        dose_data,
        num_samples=150,
        sampling_strategy='positive_only'
    )
    
    # å­—æ®µä¿¡æ¯
    field_info = {
        'space_dims': dose_data['space_dims'].tolist(),
        'world_bounds': {
            'min': dose_data['world_min'],
            'max': dose_data['world_max']
        },
        'grid_shape': dose_data['grid_shape'],
        'dose_data': dose_data,  # ä¿å­˜å®Œæ•´çš„dose_dataä¾›åç»­ä½¿ç”¨
        'data_source': 'real_excel_data'
    }
    
    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ:")
    print(f"   - è®­ç»ƒæ ·æœ¬: {len(train_points)} ä¸ªç‚¹")
    print(f"   - æµ‹è¯•æ ·æœ¬: {len(test_points)} ä¸ªç‚¹")
    print(f"   - è®­ç»ƒå€¼èŒƒå›´: [{np.min(train_values):.2e}, {np.max(train_values):.2e}]")
    print(f"   - æµ‹è¯•å€¼èŒƒå›´: [{np.min(test_values):.2e}, {np.max(test_values):.2e}]")
    print(f"   - ç½‘æ ¼å½¢çŠ¶: {dose_data['grid_shape']}")
    print(f"   - ç©ºé—´å°ºå¯¸: {dose_data['space_dims']}")
    
    return train_points, train_values, test_points, test_values, field_info

def run_common_mode(args):
    """
    è¿è¡Œé€šç”¨æ¨¡å¼: ç¯å¢ƒæ£€æŸ¥å’Œå·¥å…·æ¼”ç¤º
    Run common mode: environment check and tools demonstration
    """
    print("\n" + "="*60)
    print("ğŸ”§ é€šç”¨æ¨¡å¼: ç¯å¢ƒæ£€æŸ¥å’Œå·¥å…·æ¼”ç¤º")
    print("="*60)
    
    # ç¯å¢ƒæ£€æŸ¥
    print("\n1ï¸âƒ£ ç¯å¢ƒå®Œæ•´æ€§æ£€æŸ¥...")
    env_status = validate_compose_environment()
    
    # åŠ è½½æ•°æ® - é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®
    print("\n2ï¸âƒ£ åŠ è½½æ•°æ®...")
    try:
        print("ä½¿ç”¨çœŸå®DATA.xlsxæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = load_real_data_from_excel(
            data_file_path=args.data_file
        )
    except Exception as e:
        print(f"âš ï¸ çœŸå®æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("å›é€€åˆ°åˆæˆæ¼”ç¤ºæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = generate_synthetic_3d_data(
            n_samples=args.num_samples,
            noise_level=args.noise_level,
            random_seed=args.random_seed
        )
    
    # æ•°æ®ç»“æ„æ¼”ç¤º
    print("\n3ï¸âƒ£ æ•°æ®ç»“æ„æ ‡å‡†åŒ–æ¼”ç¤º...")
    field_tensor = FieldTensor(
        coordinates=train_points,
        values=train_values,
        metadata={'type': 'radiation_field', 'units': 'arbitrary'}
    )
    
    probe_set = ProbeSet(
        positions=train_points,
        measurements=train_values,
        metadata={'sensor_type': 'synthetic', 'calibration': 'simulated'}
    )
    
    print(f"   âœ… FieldTensor: {field_tensor.coordinates.shape} åæ ‡, {field_tensor.values.shape} æ•°å€¼")
    print(f"   âœ… ProbeSet: {probe_set.positions.shape} ä½ç½®, {probe_set.measurements.shape} æµ‹é‡å€¼")
    
    # æ•°æ®å½’ä¸€åŒ–æ¼”ç¤º
    print("\n4ï¸âƒ£ æ•°æ®å½’ä¸€åŒ–æ¼”ç¤º...")
    normalized_values, norm_info = DataNormalizer.robust_normalize(train_values)
    print(f"   åŸå§‹å€¼èŒƒå›´: [{np.min(train_values):.2e}, {np.max(train_values):.2e}]")
    print(f"   å½’ä¸€åŒ–åèŒƒå›´: [{np.min(normalized_values):.3f}, {np.max(normalized_values):.3f}]")
    print(f"   å½’ä¸€åŒ–å‚æ•°: {norm_info}")
    
    # è¯¯å·®ç»Ÿè®¡æ¼”ç¤º
    print("\n5ï¸âƒ£ è¯¯å·®ç»Ÿè®¡æ¼”ç¤º...")
    # åˆ›å»ºæ¨¡æ‹Ÿé¢„æµ‹å€¼ï¼ˆæ·»åŠ ä¸€äº›è¯¯å·®ï¼‰
    pred_values = train_values * (1 + np.random.normal(0, 0.1, len(train_values)))
    metrics = MetricsCalculator.compute_metrics(train_values, pred_values)
    print("   é¢„æµ‹è¯¯å·®æŒ‡æ ‡:")
    for metric, value in metrics.items():
        print(f"     {metric}: {value:.4f}")
    
    # å¯è§†åŒ–æ¼”ç¤º
    print("\n6ï¸âƒ£ å¯è§†åŒ–åŠŸèƒ½æ¼”ç¤º...")
    
    # è½¬æ¢ä¸º3Dç½‘æ ¼ç”¨äºå¯è§†åŒ–
    test_grid_shape = field_info['test_grid_shape']
    true_grid = test_values.reshape(test_grid_shape)
    pred_grid = test_values.reshape(test_grid_shape) * (1 + np.random.normal(0, 0.05, test_grid_shape))
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾
    fig = VisualizationTools.plot_comparison_2d_slice(
        true_grid, pred_grid, slice_axis=2, slice_idx=test_grid_shape[2]//2,
        title_prefix="æ¼”ç¤ºæ•°æ® - "
    )
    
    if args.save_plots:
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        fig.savefig(plots_dir / "common_mode_comparison.png", dpi=300, bbox_inches='tight')
        print(f"   ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {plots_dir / 'common_mode_comparison.png'}")
    
    plt.show()
    
    # æ®‹å·®åˆ†ææ¼”ç¤º
    residuals = pred_values - train_values
    fig_residual = VisualizationTools.plot_residual_analysis(residuals, train_points)
    
    if args.save_plots:
        fig_residual.savefig(plots_dir / "common_mode_residuals.png", dpi=300, bbox_inches='tight')
        print(f"   ğŸ“Š æ®‹å·®åˆ†æå›¾å·²ä¿å­˜: {plots_dir / 'common_mode_residuals.png'}")
    
    plt.show()
    
    print("\nâœ… é€šç”¨æ¨¡å¼æ¼”ç¤ºå®Œæˆ!")
    return env_status

def run_mode1(args):
    """
    è¿è¡Œæ–¹æ¡ˆ1: PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ
    Run Mode 1: PINN â†’ Residual Kriging â†’ Weighted Fusion
    """
    print("\n" + "="*60)
    print("ğŸš€ æ–¹æ¡ˆ1: PINN â†’ æ®‹å·®Kriging â†’ åŠ æƒèåˆ")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    if args.use_real_data:
        print("ä½¿ç”¨çœŸå®DATA.xlsxæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = load_real_data_from_excel(
            data_file_path=args.data_file
        )
    else:
        print("ç”Ÿæˆåˆæˆæ¼”ç¤ºæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = generate_synthetic_3d_data(
            n_samples=args.num_samples,
            noise_level=args.noise_level,
            random_seed=args.random_seed
        )
    
    # é…ç½®è€¦åˆç³»ç»Ÿ
    config = ComposeConfig(
        gpu_enabled=args.gpu_enabled,
        verbose=args.verbose,
        random_seed=args.random_seed,
        fusion_weight=args.fusion_weight,
        pinn_epochs=args.pinn_epochs,
        kriging_variogram_model=args.variogram_model
    )
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = CouplingWorkflow(config)
    
    # æ‰§è¡Œæ–¹æ¡ˆ1æµç¨‹
    print(f"\nğŸ”„ æ‰§è¡Œæ–¹æ¡ˆ1æµç¨‹ (èåˆæƒé‡={args.fusion_weight})...")
    
    start_time = time.time()
    
    try:
        results = workflow.run_mode1_pipeline(
            train_points=train_points,
            train_values=train_values,
            prediction_points=test_points,
            fusion_weight=args.fusion_weight,
            space_dims=field_info['space_dims'],
            world_bounds=field_info['world_bounds'],
            kriging_params={'variogram_model': args.variogram_model},
            epochs=args.pinn_epochs,
            max_training_points=1000,  # é™åˆ¶æœ€å¤§è®­ç»ƒç‚¹æ•°é¿å…å†…å­˜é—®é¢˜
            network_config={'layers': [3, 32, 32, 32, 1]}  # ä½¿ç”¨å®‰å…¨çš„ç½‘ç»œé…ç½®
        )
        
        execution_time = time.time() - start_time
        print(f"\nâ±ï¸ æ–¹æ¡ˆ1æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
        
        # è¯„ä¼°ç»“æœ
        print("\nğŸ“ˆ ç»“æœè¯„ä¼°...")
        final_predictions = results['final_predictions']
        
        # è®¡ç®—å„ç§é¢„æµ‹çš„è¯¯å·®æŒ‡æ ‡
        pinn_metrics = MetricsCalculator.compute_metrics(test_values, results['pinn_predictions'])
        final_metrics = MetricsCalculator.compute_metrics(test_values, final_predictions)
        
        print("\nğŸ“Š PINNåŸºçº¿æ€§èƒ½:")
        for metric, value in pinn_metrics.items():
            print(f"   {metric}: {value:.4f}")
        
        print("\nğŸ“Š æ–¹æ¡ˆ1èåˆåæ€§èƒ½:")
        for metric, value in final_metrics.items():
            print(f"   {metric}: {value:.4f}")
        
        print("\nğŸ“Š æ€§èƒ½æå‡:")
        for metric in pinn_metrics:
            if metric in ['MAE', 'RMSE', 'MAPE']:  # è¶Šå°è¶Šå¥½
                improvement = (pinn_metrics[metric] - final_metrics[metric]) / pinn_metrics[metric] * 100
                print(f"   {metric} æ”¹å–„: {improvement:+.2f}%")
            elif metric == 'R2':  # è¶Šå¤§è¶Šå¥½
                improvement = (final_metrics[metric] - pinn_metrics[metric]) / abs(pinn_metrics[metric]) * 100
                print(f"   {metric} æ”¹å–„: {improvement:+.2f}%")
        
        # å¯è§†åŒ–ç»“æœ
        if args.save_plots or args.show_plots:
            print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
            
            test_grid_shape = field_info['test_grid_shape']
            true_grid = test_values.reshape(test_grid_shape)
            pinn_grid = results['pinn_predictions'].reshape(test_grid_shape)
            final_grid = final_predictions.reshape(test_grid_shape)
            
            # å¯¹æ¯”å›¾1: çœŸå® vs PINN
            fig1 = VisualizationTools.plot_comparison_2d_slice(
                true_grid, pinn_grid, slice_axis=2, slice_idx=test_grid_shape[2]//2,
                title_prefix="æ–¹æ¡ˆ1 - PINNåŸºçº¿ - "
            )
            
            # å¯¹æ¯”å›¾2: çœŸå® vs èåˆç»“æœ
            fig2 = VisualizationTools.plot_comparison_2d_slice(
                true_grid, final_grid, slice_axis=2, slice_idx=test_grid_shape[2]//2,
                title_prefix="æ–¹æ¡ˆ1 - èåˆç»“æœ - "
            )
            
            # æ®‹å·®åˆ†æ
            final_residuals = final_predictions - test_values
            fig3 = VisualizationTools.plot_residual_analysis(final_residuals, test_points)
            
            if args.save_plots:
                plots_dir = Path("plots")
                plots_dir.mkdir(exist_ok=True)
                fig1.savefig(plots_dir / "mode1_pinn_baseline.png", dpi=300, bbox_inches='tight')
                fig2.savefig(plots_dir / "mode1_fusion_result.png", dpi=300, bbox_inches='tight')
                fig3.savefig(plots_dir / "mode1_residual_analysis.png", dpi=300, bbox_inches='tight')
                print(f"   ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³ {plots_dir}/")
            
            if args.show_plots:
                plt.show()
        
        print("\nâœ… æ–¹æ¡ˆ1æ¼”ç¤ºå®Œæˆ!")
        return results
        
    except Exception as e:
        print(f"\nâŒ æ–¹æ¡ˆ1æ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return None

def run_mode2(args):
    """
    è¿è¡Œæ–¹æ¡ˆ2: Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ
    Run Mode 2: Kriging ROI Sample Augmentation â†’ PINN Retraining
    """
    print("\n" + "="*60)
    print("ğŸ¯ æ–¹æ¡ˆ2: Kriging ROIæ ·æœ¬æ‰©å…… â†’ PINNé‡è®­ç»ƒ")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    if args.use_real_data:
        print("ä½¿ç”¨çœŸå®DATA.xlsxæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = load_real_data_from_excel(
            data_file_path=args.data_file
        )
    else:
        print("ç”Ÿæˆåˆæˆæ¼”ç¤ºæ•°æ®")
        train_points, train_values, test_points, test_values, field_info = generate_synthetic_3d_data(
            n_samples=args.num_samples,
            noise_level=args.noise_level,
            random_seed=args.random_seed
        )
    
    # é…ç½®è€¦åˆç³»ç»Ÿ
    config = ComposeConfig(
        gpu_enabled=args.gpu_enabled,
        verbose=args.verbose,
        random_seed=args.random_seed,
        roi_detection_strategy=args.roi_strategy,
        sample_augment_factor=args.augment_factor,
        pinn_epochs=args.pinn_epochs,
        kriging_variogram_model=args.variogram_model
    )
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = CouplingWorkflow(config)
    
    # é¦–å…ˆè®­ç»ƒPINNåŸºçº¿ç”¨äºå¯¹æ¯”
    print("\nğŸ”¥ è®­ç»ƒPINNåŸºçº¿æ¨¡å‹...")
    baseline_pinn = PINNAdapter(config)
    baseline_pinn.fit(train_points, train_values, 
                     space_dims=field_info['space_dims'],
                     world_bounds=field_info['world_bounds'])
    baseline_predictions = baseline_pinn.predict(test_points)
    
    # æ‰§è¡Œæ–¹æ¡ˆ2æµç¨‹
    print(f"\nğŸ”„ æ‰§è¡Œæ–¹æ¡ˆ2æµç¨‹ (ROIç­–ç•¥={args.roi_strategy}, æ‰©å……å€æ•°={args.augment_factor})...")
    
    start_time = time.time()
    
    try:
        results = workflow.run_mode2_pipeline(
            train_points=train_points,
            train_values=train_values,
            prediction_points=test_points,
            roi_strategy=args.roi_strategy,
            augment_factor=args.augment_factor,
            space_dims=field_info['space_dims'],
            world_bounds=field_info['world_bounds'],
            roi_params={'density_percentile': 70, 'expansion_factor': 1.3},
            kriging_params={'variogram_model': args.variogram_model},
            epochs=args.pinn_epochs
        )
        
        execution_time = time.time() - start_time
        print(f"\nâ±ï¸ æ–¹æ¡ˆ2æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
        
        # è¯„ä¼°ç»“æœ
        print("\nğŸ“ˆ ç»“æœè¯„ä¼°...")
        final_predictions = results['final_predictions']
        
        # è®¡ç®—å„ç§é¢„æµ‹çš„è¯¯å·®æŒ‡æ ‡
        baseline_metrics = MetricsCalculator.compute_metrics(test_values, baseline_predictions)
        final_metrics = MetricsCalculator.compute_metrics(test_values, final_predictions)
        
        print("\nğŸ“Š PINNåŸºçº¿æ€§èƒ½:")
        for metric, value in baseline_metrics.items():
            print(f"   {metric}: {value:.4f}")
        
        print("\nğŸ“Š æ–¹æ¡ˆ2å¢å¼ºåæ€§èƒ½:")
        for metric, value in final_metrics.items():
            print(f"   {metric}: {value:.4f}")
        
        print("\nğŸ“Š æ€§èƒ½æå‡:")
        for metric in baseline_metrics:
            if metric in ['MAE', 'RMSE', 'MAPE']:  # è¶Šå°è¶Šå¥½
                improvement = (baseline_metrics[metric] - final_metrics[metric]) / baseline_metrics[metric] * 100
                print(f"   {metric} æ”¹å–„: {improvement:+.2f}%")
            elif metric == 'R2':  # è¶Šå¤§è¶Šå¥½
                improvement = (final_metrics[metric] - baseline_metrics[metric]) / abs(baseline_metrics[metric]) * 100
                print(f"   {metric} æ”¹å–„: {improvement:+.2f}%")
        
        # æ ·æœ¬æ‰©å……ç»Ÿè®¡
        original_count = len(train_points)
        augmented_count = len(results['augmented_points'])
        print(f"\nğŸ“ˆ æ ·æœ¬æ‰©å……ç»Ÿè®¡:")
        print(f"   åŸå§‹æ ·æœ¬æ•°: {original_count}")
        print(f"   æ‰©å……åæ ·æœ¬æ•°: {augmented_count}")
        print(f"   æ‰©å……å€æ•°: {augmented_count / original_count:.2f}")
        
        # ROIä¿¡æ¯
        roi_bounds = results['roi_bounds']
        print(f"\nğŸ¯ ROIæ£€æµ‹ç»“æœ:")
        print(f"   ç­–ç•¥: {args.roi_strategy}")
        print(f"   ROIè¾¹ç•Œ: {roi_bounds['min']} åˆ° {roi_bounds['max']}")
        if 'mask' in roi_bounds:
            roi_point_count = np.sum(roi_bounds['mask'])
            print(f"   ROIå†…è®­ç»ƒç‚¹æ•°: {roi_point_count}/{original_count}")
        
        # å¯è§†åŒ–ç»“æœ
        if args.save_plots or args.show_plots:
            print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
            
            test_grid_shape = field_info['test_grid_shape']
            true_grid = test_values.reshape(test_grid_shape)
            baseline_grid = baseline_predictions.reshape(test_grid_shape)
            final_grid = final_predictions.reshape(test_grid_shape)
            
            # å¯¹æ¯”å›¾1: çœŸå® vs PINNåŸºçº¿
            fig1 = VisualizationTools.plot_comparison_2d_slice(
                true_grid, baseline_grid, slice_axis=2, slice_idx=test_grid_shape[2]//2,
                title_prefix="æ–¹æ¡ˆ2 - PINNåŸºçº¿ - "
            )
            
            # å¯¹æ¯”å›¾2: çœŸå® vs å¢å¼ºç»“æœ
            fig2 = VisualizationTools.plot_comparison_2d_slice(
                true_grid, final_grid, slice_axis=2, slice_idx=test_grid_shape[2]//2,
                title_prefix="æ–¹æ¡ˆ2 - å¢å¼ºç»“æœ - "
            )
            
            # æ®‹å·®åˆ†æ
            final_residuals = final_predictions - test_values
            fig3 = VisualizationTools.plot_residual_analysis(final_residuals, test_points)
            
            if args.save_plots:
                plots_dir = Path("plots")
                plots_dir.mkdir(exist_ok=True)
                fig1.savefig(plots_dir / "mode2_pinn_baseline.png", dpi=300, bbox_inches='tight')
                fig2.savefig(plots_dir / "mode2_enhanced_result.png", dpi=300, bbox_inches='tight')
                fig3.savefig(plots_dir / "mode2_residual_analysis.png", dpi=300, bbox_inches='tight')
                print(f"   ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³ {plots_dir}/")
            
            if args.show_plots:
                plt.show()
        
        print("\nâœ… æ–¹æ¡ˆ2æ¼”ç¤ºå®Œæˆ!")
        return results
        
    except Exception as e:
        print(f"\nâŒ æ–¹æ¡ˆ2æ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return None

def create_argument_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="GPU Block-Kriging Ã— PINN è€¦åˆé‡å»ºæ¼”ç¤ºç¨‹åº",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py --mode common                          # é€šç”¨å·¥å…·æ¼”ç¤º
  python main.py --mode mode1 --fusion_weight 0.7      # æ–¹æ¡ˆ1æ¼”ç¤º
  python main.py --mode mode2 --roi_strategy high_value # æ–¹æ¡ˆ2æ¼”ç¤º
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--mode', 
        choices=['common', 'mode1', 'mode2'],
        required=True,
        help='è¿è¡Œæ¨¡å¼: common(é€šç”¨å·¥å…·) | mode1(æ®‹å·®èåˆ) | mode2(æ ·æœ¬æ‰©å……)'
    )
    
    # æ•°æ®æºé€‰æ‹©
    parser.add_argument('--use_real_data', action='store_true', default=True, 
                       help='ä½¿ç”¨çœŸå®DATA.xlsxæ•°æ®è€Œéåˆæˆæ•°æ®')
    parser.add_argument('--use_synthetic_data', action='store_true', default=False,
                       help='ä½¿ç”¨åˆæˆæ•°æ®è€ŒéçœŸå®æ•°æ®')
    parser.add_argument('--data_file', type=str, default="../PINN/DATA.xlsx",
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../PINN/DATA.xlsx)')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--num_samples', type=int, default=300, help='è®­ç»ƒæ ·æœ¬æ•°é‡ (é»˜è®¤: 300)')
    parser.add_argument('--noise_level', type=float, default=0.05, help='æ•°æ®å™ªå£°æ°´å¹³ (é»˜è®¤: 0.05)')
    parser.add_argument('--random_seed', type=int, default=42, help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--gpu_enabled', action='store_true', default=True, help='å¯ç”¨GPUåŠ é€Ÿ')
    parser.add_argument('--no_gpu', dest='gpu_enabled', action='store_false', help='ç¦ç”¨GPUåŠ é€Ÿ')
    parser.add_argument('--verbose', action='store_true', default=True, help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--quiet', dest='verbose', action='store_false', help='ç®€æ´è¾“å‡º')
    
    # PINNå‚æ•°
    parser.add_argument('--pinn_epochs', type=int, default=500, help='PINNè®­ç»ƒè½®æ•° (é»˜è®¤: 500)')
    
    # Krigingå‚æ•°
    parser.add_argument('--variogram_model', choices=['linear', 'exponential', 'gaussian'], 
                       default='linear', help='å˜å¼‚å‡½æ•°æ¨¡å‹ (é»˜è®¤: linear)')
    
    # æ–¹æ¡ˆ1ä¸“ç”¨å‚æ•°
    parser.add_argument('--fusion_weight', type=float, default=0.5, 
                       help='æ–¹æ¡ˆ1èåˆæƒé‡ Ï‰ âˆˆ (0,1) (é»˜è®¤: 0.5)')
    
    # æ–¹æ¡ˆ2ä¸“ç”¨å‚æ•°
    parser.add_argument('--roi_strategy', choices=['high_density', 'high_value', 'bounding_box'],
                       default='high_density', help='æ–¹æ¡ˆ2 ROIæ£€æµ‹ç­–ç•¥ (é»˜è®¤: high_density)')
    parser.add_argument('--augment_factor', type=float, default=2.0,
                       help='æ–¹æ¡ˆ2æ ·æœ¬æ‰©å……å€æ•° (é»˜è®¤: 2.0)')
    
    # å¯è§†åŒ–å‚æ•°
    parser.add_argument('--save_plots', action='store_true', help='ä¿å­˜å¯è§†åŒ–å›¾ç‰‡')
    parser.add_argument('--show_plots', action='store_true', help='æ˜¾ç¤ºå¯è§†åŒ–å›¾ç‰‡')
    parser.add_argument('--no_plots', dest='show_plots', action='store_false', help='ä¸æ˜¾ç¤ºå›¾ç‰‡')
    
    return parser

def main():
    """ä¸»å‡½æ•°"""
    print_compose_banner()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ› ï¸  è¿è¡Œé…ç½®")
    print("="*60)
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"æ ·æœ¬æ•°é‡: {args.num_samples}")
    print(f"GPUåŠ é€Ÿ: {'å¯ç”¨' if args.gpu_enabled else 'ç¦ç”¨'}")
    print(f"è¯¦ç»†è¾“å‡º: {'æ˜¯' if args.verbose else 'å¦'}")
    print(f"éšæœºç§å­: {args.random_seed}")
    
    if args.mode in ['mode1', 'mode2']:
        print(f"PINNè®­ç»ƒè½®æ•°: {args.pinn_epochs}")
        print(f"å˜å¼‚å‡½æ•°æ¨¡å‹: {args.variogram_model}")
    
    if args.mode == 'mode1':
        print(f"èåˆæƒé‡: {args.fusion_weight}")
    elif args.mode == 'mode2':
        print(f"ROIç­–ç•¥: {args.roi_strategy}")
        print(f"æ‰©å……å€æ•°: {args.augment_factor}")
    
    # æ‰§è¡Œç›¸åº”æ¨¡å¼
    try:
        if args.mode == 'common':
            results = run_common_mode(args)
        elif args.mode == 'mode1':
            results = run_mode1(args)
        elif args.mode == 'mode2':
            results = run_mode2(args)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„è¿è¡Œæ¨¡å¼: {args.mode}")
            return 1
        
        if results is not None:
            print(f"\nğŸ‰ {args.mode} æ¨¡å¼è¿è¡ŒæˆåŠŸ!")
        else:
            print(f"\nâš ï¸ {args.mode} æ¨¡å¼è¿è¡Œç»“æŸï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½æœªå®Œå…¨å·¥ä½œ")
            return 1
            
    except KeyboardInterrupt:
        print("\n\nâ›” ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        return 130
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 