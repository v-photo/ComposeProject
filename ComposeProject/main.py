#!/usr/bin/env python3
"""
PINN-Kriging è€¦åˆç³»ç»Ÿä¸»å…¥å£è„šæœ¬
Main entry script for PINN-Kriging coupling system

ç”¨æ³•ç¤ºä¾‹ï¼š
1. ä½¿ç”¨é»˜è®¤é…ç½®ï¼špython main.py
2. ä½¿ç”¨é¢„è®¾é…ç½®ï¼špython main.py --preset kriging_only
3. å¿«é€Ÿæµ‹è¯•ï¼špython main.py --preset quick_test
4. ä½¿ç”¨éšæœºé‡‡æ ·ï¼špython main.py --preset random_sampling
"""

import argparse
import sys
import numpy as np
from pathlib import Path
import time
import json

# å°†é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir.parent)) # PINN_ts ç›®å½•
sys.path.insert(0, str(current_dir / 'src')) # ComposeProject/src ç›®å½•
sys.path.insert(0, str(current_dir)) # ComposeProject ç›®å½•

# ä»æˆ‘ä»¬é‡æ„çš„æ¨¡å—ä¸­å¯¼å…¥
from config import load_config_dict
from src.data.loader import (
    load_3d_data_from_sheets, 
    process_grid_to_dose_data, 
    sample_training_points, 
    sample_kriging_style,
    create_prediction_grid
)
from src.models.pinn import PINNModel
from src.models.kriging_adapter import KrigingAdapter
from src.workflows.auto_selection import AutoSelectionWorkflow
from src.analysis.plotting import plot_training_comparison
from src.utils.display import print_compose_banner
from src.utils.environment import validate_compose_environment


def get_training_samples(dose_data, config):
    """
    æ ¹æ®é…ç½®è·å–è®­ç»ƒæ ·æœ¬
    
    æ”¯æŒä¸¤ç§é‡‡æ ·ç­–ç•¥ï¼š
    1. kriging_style: Krigingé£æ ¼çš„ç»“æ„åŒ–ç½‘æ ¼é‡‡æ ·
    2. å…¶ä»–ç­–ç•¥: ä½¿ç”¨ sample_training_points è¿›è¡Œéšæœºé‡‡æ ·
    
    Args:
        dose_data: å¤„ç†åçš„å‰‚é‡æ•°æ®å­—å…¸
        config: é…ç½®å­—å…¸
        
    Returns:
        (train_points, train_values): è®­ç»ƒç‚¹åæ ‡å’Œå¯¹åº”çš„å€¼
    """
    sampling_cfg = config.get('sampling', {})
    strategy = sampling_cfg.get('strategy', 'positive_only')
    
    print(f"\n--- ğŸ“Š é‡‡æ ·ç­–ç•¥: {strategy} ---")
    
    if strategy == 'kriging_style':
        # ä½¿ç”¨Krigingé£æ ¼é‡‡æ ·
        kriging_cfg = sampling_cfg.get('kriging_style', {})
        
        print(f"  - é‡‡æ ·åŒºåŸŸèµ·ç‚¹: {kriging_cfg.get('box_origin', [5, 5, 5])}")
        print(f"  - é‡‡æ ·åŒºåŸŸå»¶ä¼¸: {kriging_cfg.get('box_extent', [90, 90, 90])}")
        print(f"  - é‡‡æ ·æ­¥é•¿: {kriging_cfg.get('step_sizes', [5])}")
        
        train_points, train_values = sample_kriging_style(
            dose_data,
            box_origin=kriging_cfg.get('box_origin', [5, 5, 5]),
            box_extent=kriging_cfg.get('box_extent', [90, 90, 90]),
            step_sizes=kriging_cfg.get('step_sizes', [5]),
            source_positions=kriging_cfg.get('source_positions', None),
            source_exclusion_radius=kriging_cfg.get('source_exclusion_radius', 30.0)
        )
    else:
        # ä½¿ç”¨éšæœºé‡‡æ ·
        random_cfg = sampling_cfg.get('random_sampling', {})
        num_samples = random_cfg.get('num_samples', config.get('data', {}).get('num_samples', 300))
        
        print(f"  - é‡‡æ ·æ•°é‡: {num_samples}")
        
        train_points, train_values = sample_training_points(
            dose_data=dose_data,
            num_samples=num_samples,
            strategy=strategy if strategy != 'kriging_style' else 'positive_only'
        )
    
    print(f"  âœ… é‡‡æ ·å®Œæˆ: {len(train_points)} ä¸ªè®­ç»ƒç‚¹")
    return train_points, train_values


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¨¡å—åŒ–çš„PINNè€¦åˆç³»ç»Ÿ")
    parser.add_argument('--preset', type=str, default='default', 
                       help='æŒ‡å®šè¦ä½¿ç”¨çš„config.pyä¸­çš„é¢„è®¾é…ç½®')
    parser.add_argument('--method', type=str, choices=['auto', 'kriging', 'pinn', 'adaptive_experiment'], default=None,
                       help='é€‰æ‹©é¢„æµ‹æ–¹æ³•: auto | kriging | pinn | adaptive_experimentï¼ˆCLIä¼˜å…ˆï¼Œå…¶æ¬¡é…ç½®ï¼Œé»˜è®¤autoï¼‰')
    parser.add_argument('--verbose', action='store_true',
                       help='æ‰“å°è¯¦ç»†çš„é…ç½®ä¿¡æ¯')
    args = parser.parse_args()

    print_compose_banner()
    
    # 1. éªŒè¯ä¾èµ–
    dep_status = validate_compose_environment()
    print("\n--- ğŸ“¦ ä¾èµ–çŠ¶æ€æ£€æŸ¥ ---")
    for dep, status in dep_status.items():
        print(f"  - {dep}: {'âœ… å¯ç”¨' if status else 'âŒ ä¸å¯ç”¨'}")
    
    # 2. åŠ è½½é…ç½®
    print(f"\n--- âš™ï¸ æ­£åœ¨åŠ è½½é…ç½® (é¢„è®¾: {args.preset}) ---")
    config = load_config_dict(args.preset)
    np.random.seed(config.get('system', {}).get('random_seed', 42))
    method = args.method or config.get('system', {}).get('method', 'auto')
    
    # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„é…ç½®å­—å…¸
    if args.verbose:
        print("--- è°ƒè¯•ä¿¡æ¯ï¼šå½“å‰ä½¿ç”¨çš„å®Œæ•´é…ç½® ---")
        print(json.dumps(config, indent=2, default=str))
        print("------------------------------------")
    
    # 3. æ•°æ®åŠ è½½å’Œå¤„ç†
    print("\n--- ğŸ’¾ æ­£åœ¨åŠ è½½æ•°æ® ---")
    data_cfg = config.get('data', {})
    dose_grid = load_3d_data_from_sheets(
        file_path=data_cfg.get('file_path'),
        sheet_name_template=data_cfg.get('sheet_name_template'),
        use_cols=data_cfg.get('use_columns'),
        z_size=data_cfg.get('z_size'),
        y_size=data_cfg.get('y_size'),
    )
    
    dose_data = process_grid_to_dose_data(
        dose_grid=dose_grid,
        space_dims=data_cfg.get('space_dims')
    )
    
    # 4. ä½¿ç”¨ç»Ÿä¸€çš„é‡‡æ ·å‡½æ•°
    train_points, train_values = get_training_samples(dose_data, config)
    
    # 5. åˆ›å»ºé¢„æµ‹ç½‘æ ¼
    prediction_points = create_prediction_grid(
        dose_data=dose_data,
        downsample_factor=data_cfg.get('downsample_factor', 1)
    )

    # 6. æ ¹æ®methodæ‰§è¡Œå·¥ä½œæµ
    print(f"\n--- ğŸš¦ å·¥ä½œæµé€‰æ‹©: {method} ---")
    start_time = time.time()
    predictions = None
    history = None
    method_used = method
    adapter = None

    if method == 'adaptive_experiment':
        print("\n--- ğŸ”„ æ­£åœ¨æ‰§è¡Œè‡ªé€‚åº”å®éªŒå·¥ä½œæµ ---")
        from src.workflows.adaptive_experiment import run_adaptive_experiment
        run_adaptive_experiment(config)
        print("\nğŸ‰ è‡ªé€‚åº”å®éªŒå®Œæˆã€‚")
        return

    if method == 'auto':
        workflow = AutoSelectionWorkflow(config)
        results = workflow.run(
            train_points=train_points,
            train_values=train_values,
            prediction_points=prediction_points,
            dose_data=dose_data
        )
        predictions = results.get('predictions')
        method_used = results.get('method_used', 'auto')
        adapter = results.get('adapter')
        total_time = results.get('total_time', time.time() - start_time)

    elif method == 'kriging':
        print("\n--- âš™ï¸ æ­£åœ¨æ‰§è¡Œ Kriging å·¥ä½œæµ ---")
        kriging_adapter = KrigingAdapter(
            kriging_config=config.get('kriging', {}),
            use_gpu=config.get('system',{}).get('use_gpu', True)
        )
        kriging_adapter.fit(train_points, train_values)
        predictions = kriging_adapter.predict(prediction_points)
        adapter = kriging_adapter
        total_time = time.time() - start_time

    else:  # method == 'pinn'
        print("\n--- ğŸš€ æ­£åœ¨æ‰§è¡Œ PINN å·¥ä½œæµ ---")
        pinn_config = config.get('pinn', {})
        system_cfg = config.get('system', {})
        enable_pinn_adaptive = system_cfg.get('enable_pinn_adaptive', False)
        pinn_events = []

        # å‡†å¤‡test_data
        true_field_values = dose_data['dose_grid'].flatten()
        dummy_test_data = np.hstack([prediction_points, true_field_values[:len(prediction_points)].reshape(-1, 1)])
        pinn_training_data = np.hstack([train_points, train_values])

        model = PINNModel(
            dose_data=dose_data,
            training_data=pinn_training_data,
            test_data=dummy_test_data, 
            **pinn_config.get('model_params', {})
        )
        
        training_params = pinn_config.get('training_params', {})
        model_params = pinn_config.get('model_params', {})
        num_collocation = model_params.get('num_collocation_points', 4096)
        base_epochs = training_params.get('cycle_epochs', training_params.get('total_epochs', 5000))
        
        print(f"INFO: Generating {num_collocation} collocation points for training cycle...")
        collocation_points = np.random.uniform(
            low=dose_data['world_min'],
            high=dose_data['world_max'],
            size=(num_collocation, 3)
        )
        
        cycle1 = model.run_training_cycle(
            max_epochs=base_epochs,
            detect_every=training_params.get('detect_every', 500),
            detection_threshold=training_params.get('detection_threshold', 0.1),
            collocation_points=collocation_points,
            checkpoint_path_prefix=config.get('system', {}).get('checkpoint_path', './models/pinn_checkpoint')
        )
        if getattr(model, 'epoch_history', None):
            pinn_events.append((model.epoch_history[-1], 'phase_transition', 'é¦–è½®PINNå®Œæˆ'))
        for e_step, e_type in cycle1.get('events', []):
            desc = 'æ—©åœ' if e_type == 'early_stop' else 'å›é€€åˆ°æœ€ä½³æ£€æŸ¥ç‚¹' if e_type == 'rollback' else 'è®­ç»ƒäº‹ä»¶'
            pinn_events.append((e_step, 'early_stop' if e_type == 'early_stop' else 'rollback', desc))

        if enable_pinn_adaptive:
            print("INFO: [PINN] è‡ªé€‚åº”åŠ å¯†å·²å¼€å¯ï¼Œç”Ÿæˆæ–°ä¸€è½®éšæœº collocation ç‚¹...")
            new_collocation = np.random.uniform(
                low=dose_data['world_min'],
                high=dose_data['world_max'],
                size=(num_collocation, 3)
            )
            adaptive_epochs = training_params.get('adaptive_cycle_epochs', 2000)
            cycle2 = model.run_training_cycle(
                max_epochs=adaptive_epochs,
                detect_every=training_params.get('detect_every', 500),
                detection_threshold=training_params.get('detection_threshold', 0.1),
                collocation_points=new_collocation,
                checkpoint_path_prefix=config.get('system', {}).get('checkpoint_path', './models/pinn_checkpoint')
            )
            if getattr(model, 'epoch_history', None):
                pinn_events.append((model.epoch_history[-1], 'phase_transition', 'è‡ªé€‚åº”åŠ å¯†å®Œæˆ'))
            for e_step, e_type in cycle2.get('events', []):
                desc = 'æ—©åœ' if e_type == 'early_stop' else 'å›é€€åˆ°æœ€ä½³æ£€æŸ¥ç‚¹' if e_type == 'rollback' else 'è®­ç»ƒäº‹ä»¶'
                pinn_events.append((e_step, 'early_stop' if e_type == 'early_stop' else 'rollback', desc))
        else:
            print("INFO: [PINN] è‡ªé€‚åº”åŠ å¯†å·²å…³é—­ï¼ˆenable_pinn_adaptive=Falseï¼‰ï¼Œè·³è¿‡ç¬¬äºŒé˜¶æ®µã€‚")

        predictions = model.predict(prediction_points)
        adapter = model
        total_time = time.time() - start_time

        if hasattr(model, 'mre_history') and getattr(model, 'epoch_history', None):
            history = {'é«˜çº§PINN': {'epochs': model.epoch_history, 'metrics': model.mre_history, 'events': pinn_events}}

    print(f"\n--- âœ… å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ({method_used}) ---")
    print(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"  - è®­ç»ƒç‚¹æ•°: {len(train_points)}")

    # 7. åˆ†æå’Œä¿å­˜
    print("\n--- ğŸ“ˆ æ­£åœ¨åˆ†æä¸ä¿å­˜ç»“æœ ---")
    results_dir = Path(config.get('system', {}).get('results_dir', "results"))
    results_dir.mkdir(parents=True, exist_ok=True)
    exp_name = config.get('experiment', {}).get('name', 'default')

    if predictions is not None:
        pred_path = results_dir / f"predictions_{exp_name}.npy"
        np.save(pred_path, predictions)
        print(f"  - é¢„æµ‹ç»“æœå·²ä¿å­˜: {pred_path}")

    if history:
        # æå–äº‹ä»¶
        events = None
        # å–ç¬¬ä¸€ä¸ªæ¨¡å‹çš„äº‹ä»¶
        first_key = next(iter(history.keys()))
        if 'events' in history[first_key]:
            events = history[first_key].get('events')

        plot_training_comparison(
            history,
            important_events=events,
            title=f"PINNè®­ç»ƒå†å² ({exp_name})",
            save_path=results_dir / f"training_history_{exp_name}.png"
        )
        hist_path = results_dir / f"training_history_{exp_name}.npz"
        np.savez(hist_path,
                 epochs=history[first_key]['epochs'],
                 metrics=history[first_key]['metrics'],
                 events=np.array(events, dtype=object) if events else [])
        print(f"  - è®­ç»ƒå†å²å·²ä¿å­˜: {hist_path}")

    print("\nğŸ‰ æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ã€‚")


if __name__ == "__main__":
    main()
