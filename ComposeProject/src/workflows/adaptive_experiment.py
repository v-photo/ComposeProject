import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple

import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from src.data.loader import AdaptiveDataLoader
from src.models.pinn import PINNModel
from src.training.samplers import GpuKrigingSurrogate, AdaptiveSampler
from src.utils.environment import validate_compose_environment


def _compute_exploration_ratio(cycle_number: int, initial: float, final: float, decay: float) -> float:
    """æŒ‰å‘¨æœŸé€’å‡çš„æ¢ç´¢ç‡è®¡ç®—ã€‚"""
    return max(final, initial - (cycle_number - 1) * decay)


def _format_float(value: float, precision: int = 4) -> str:
    """å®‰å…¨æ ¼å¼åŒ–æµ®ç‚¹æ•°ï¼Œä¾¿äºè¡¨æ ¼å±•ç¤ºã€‚"""
    if value is None:
        return "N/A"
    return f"{value:.{precision}f}"


def _write_comparison_markdown(
    md_path: Path,
    exp_name: str,
    suffix: str,
    adaptive_stats: Dict[str, Any],
    baseline_stats: Dict[str, Any],
):
    """å°†è€—æ—¶ä¸ç²¾åº¦çš„å¯¹æ¯”ç»“æœè½ç›˜ä¸º Markdownã€‚"""
    md_path.parent.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    rows = [
        ("è‡ªé€‚åº”PINN", adaptive_stats),
        ("åŸºçº¿PINN", baseline_stats),
    ]

    with open(md_path, "w", encoding="utf-8") as f:
        f.write(f"# PINN å¯¹æ¯”æ±‡æ€»ï¼ˆ{exp_name}ï¼‰\n\n")
        f.write(f"- ç”Ÿæˆæ—¶é—´ï¼š{timestamp}\n")
        f.write(f"- é…ç½®åç¼€ï¼š{suffix}\n\n")
        f.write("| æ¨¡å‹ | æœ€ç»ˆMRE | æœ€ä½³MRE | è®­ç»ƒè½®æ•° | è€—æ—¶(ç§’) | è€—æ—¶(åˆ†é’Ÿ) |\n")
        f.write("| --- | --- | --- | --- | --- | --- |\n")
        for name, stats in rows:
            if not stats:
                final_mre = best_mre = epochs = time_sec = time_min = "N/A"
            else:
                final_mre = _format_float(stats.get("final_mre"), 6)
                best_mre = _format_float(stats.get("best_mre"), 6)
                epochs_val = stats.get("epochs")
                epochs = epochs_val if epochs_val is not None else "N/A"
                time_sec_val = stats.get("time_seconds")
                time_sec = _format_float(time_sec_val, 2)
                time_min = _format_float(
                    time_sec_val / 60 if isinstance(time_sec_val, (int, float)) else None,
                    2,
                )
            f.write(f"| {name} | {final_mre} | {best_mre} | {epochs} | {time_sec} | {time_min} |\n")

        f.write("\n> è¯´æ˜ï¼šè€—æ—¶ç»Ÿè®¡è¦†ç›–æ¨¡å‹åˆå§‹åŒ–åçš„ä¸»è¦è®­ç»ƒè¿‡ç¨‹ã€‚\n")


def run_adaptive_experiment(config: Dict[str, Any]):
    """
    å¤åˆ» V1 çš„è‡ªé€‚åº”å¾ªç¯ï¼šPINN è®­ç»ƒ -> æ•°æ®æ³¨å…¥ -> Kriging æ®‹å·®ä¾¦å¯Ÿ + è‡ªé€‚åº”é‡‡æ · -> å¾ªç¯ã€‚
    ç»“æŸåç”¨è‡ªé€‚åº”å®é™…è®­ç»ƒç‚¹è®­ç»ƒåŸºçº¿ PINNï¼Œå¯¹æ¯”å¹¶è¾“å‡ºå›¾ã€‚
    """
    print_compose_banner = None
    try:
        from src.utils.display import print_compose_banner as _banner
        print_compose_banner = _banner
    except Exception:
        pass

    if print_compose_banner:
        print_compose_banner()

    dep_status = validate_compose_environment()
    print("\n--- ğŸ“¦ ä¾èµ–çŠ¶æ€æ£€æŸ¥ ---")
    for dep, status in dep_status.items():
        print(f"  - {dep}: {'âœ… å¯ç”¨' if status else 'âŒ ä¸å¯ç”¨'}")

    # è¯»å–é…ç½®
    exp_cfg = config.get("adaptive_experiment", {})
    data_cfg = config.get("data", {})
    pinn_cfg = config.get("pinn", {})
    kriging_cfg = config.get("kriging", {})
    system_cfg = config.get("system", {})

    total_epochs = exp_cfg.get("total_epochs", 1000)
    cycle_epochs = exp_cfg.get("adaptive_cycle_epochs", 200)
    detect_every = exp_cfg.get("detect_every", 100)
    scout_points_num = exp_cfg.get("num_residual_scout_points", 5000)
    exploration_cfg = exp_cfg.get("exploration", {})
    enable_kriging = exp_cfg.get("enable_kriging", True)
    enable_data_injection = exp_cfg.get("enable_data_injection", False)
    enable_ries = exp_cfg.get("enable_rapid_improvement_early_stop", True)
    split_ratios = exp_cfg.get("split_ratios", [0.7, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05])
    test_set_size = exp_cfg.get("test_set_size", 300)
    enable_baseline = exp_cfg.get("enable_baseline", True)
    file_suffix = exp_cfg.get("file_suffix")  # å¦‚æœªè®¾å®šï¼Œå°†æ ¹æ®å¼€å…³åŠ¨æ€ç”Ÿæˆ

    np.random.seed(system_cfg.get("random_seed", 42))

    # æ•°æ®åŠ è½½ä¸æ‹†åˆ†
    data_loader = AdaptiveDataLoader(
        data_path=data_cfg.get("file_path"),
        space_dims=np.array(data_cfg.get("space_dims", [20.0, 10.0, 10.0])),
        num_samples=data_cfg.get("num_samples", 300),
    )
    main_train, reserve_pools, test_set, dose_data = data_loader.get_training_data(
        split_ratios=split_ratios,
        test_set_size=test_set_size,
    )

    # é¢„æµ‹ç½‘æ ¼
    from src.data.loader import create_prediction_grid
    prediction_points = create_prediction_grid(
        dose_data=dose_data,
        downsample_factor=data_cfg.get("downsample_factor", 1),
    )

    # åˆå§‹åŒ– PINN
    model_params = pinn_cfg.get("model_params", {})
    training_params = pinn_cfg.get("training_params", {})
    num_collocation = model_params.get("num_collocation_points", 4096)
    detect_every = detect_every or training_params.get("detect_every", 500)

    pinn = PINNModel(
        dose_data=dose_data,
        training_data=main_train,
        test_data=test_set,
        **model_params,
    )

    # åˆå§‹ collocation
    current_collocation_points = np.random.uniform(
        low=dose_data["world_min"],
        high=dose_data["world_max"],
        size=(num_collocation, 3),
    )

    sampler = None
    surrogate = None
    if enable_kriging:
        sampler = AdaptiveSampler(
            domain_bounds=np.vstack([dose_data["world_min"], dose_data["world_max"]]),
            total_candidates=kriging_cfg.get("total_candidates", 50000),
        )
        surrogate = GpuKrigingSurrogate(
            variogram_model=kriging_cfg.get("variogram_model", "exponential"),
            nlags=kriging_cfg.get("nlags", 8),
            block_size=kriging_cfg.get("block_size", 10000),
        )

    important_events: List[Tuple[int, str, str]] = []

    total_epochs_trained = 0
    cycle_counter = 0
    history_epochs = []
    history_mre = []

    adaptive_start_time = time.time()
    while total_epochs_trained < total_epochs:
        remaining_total = total_epochs - total_epochs_trained
        cycle_max = min(cycle_epochs, remaining_total)

        print(f"\n--- ä¸»å¾ªç¯å‘¨æœŸ: ç›®æ ‡è®­ç»ƒ {total_epochs_trained} -> {total_epochs_trained + cycle_max} ---")

        epochs_before = pinn.model.train_state.step or 0
        cycle_result = pinn.run_training_cycle(
            max_epochs=cycle_max,
            detect_every=detect_every,
            detection_threshold=training_params.get("detection_threshold", 0.1),
            collocation_points=current_collocation_points,
            checkpoint_path_prefix=system_cfg.get("checkpoint_path", "./models/pinn_checkpoint"),
        )
        epochs_after = pinn.model.train_state.step or 0
        epochs_this_cycle = epochs_after - epochs_before
        total_epochs_trained += epochs_this_cycle
        cycle_counter += 1

        # è®°å½•é˜¶æ®µäº‹ä»¶ + å‘¨æœŸå†…æ—©åœ/å›é€€äº‹ä»¶
        if pinn.epoch_history:
            important_events.append((pinn.epoch_history[-1], "phase_transition", f"å‘¨æœŸ{cycle_counter}å®Œæˆ"))
        if cycle_result and cycle_result.get("events"):
            for e_step, e_type in cycle_result["events"]:
                desc = "æ—©åœ" if e_type == "early_stop" else "å›é€€" if e_type == "rollback" else "è®­ç»ƒäº‹ä»¶"
                important_events.append((e_step, e_type, desc))

        # è®°å½•è®­ç»ƒæ›²çº¿
        history_epochs = pinn.epoch_history
        history_mre = pinn.mre_history

        if total_epochs_trained >= total_epochs:
            print("INFO: æ€»è®­ç»ƒè½®æ•°å·²è¾¾ç›®æ ‡ï¼Œç»“æŸã€‚")
            break

        # æ•°æ®æ³¨å…¥
        if enable_data_injection:
            if reserve_pools:
                data_injection_epoch = pinn.model.train_state.step or 0
                data_to_inject = reserve_pools.pop(0)
                pinn.inject_new_data(data_to_inject)
                important_events.append(
                    (data_injection_epoch, "data_injection", f"å‘¨æœŸ{cycle_counter}æ•°æ®æ³¨å…¥(+{len(data_to_inject)}ç‚¹)")
                )
            else:
                print("WARNING: æ•°æ®æ³¨å…¥å·²å¯ç”¨ä½†æ— å‚¨å¤‡æ•°æ®ã€‚")

        # Kriging é‡é‡‡æ ·
        if enable_kriging and sampler and surrogate:
            print("\nPHASE: Kriging æ®‹å·®ä¾¦å¯Ÿä¸è‡ªé€‚åº”é‡‡æ ·")
            scout_points = np.random.uniform(
                low=dose_data["world_min"],
                high=dose_data["world_max"],
                size=(scout_points_num, 3),
            )
            true_residuals = pinn.compute_pde_residual(scout_points)
            surrogate.fit(scout_points, true_residuals)

            exploration_ratio = _compute_exploration_ratio(
                cycle_number=cycle_counter,
                initial=exploration_cfg.get("initial", 0.2),
                final=exploration_cfg.get("final", 0.05),
                decay=exploration_cfg.get("decay", 0.02),
            )
            current_collocation_points = sampler.generate_new_collocation_points(
                surrogate_model=surrogate,
                num_points_to_sample=num_collocation,
                exploration_ratio=exploration_ratio,
            )
            kriging_epoch = pinn.model.train_state.step or 0
            important_events.append(
                (kriging_epoch, "kriging_resampling", f"å‘¨æœŸ{cycle_counter}å…‹é‡Œé‡‘é‡‡æ ·(æ¢ç´¢ç‡={exploration_ratio:.2f})")
            )
        else:
            print("PHASE: Kriging è‡ªé€‚åº”é‡‡æ ·å·²ç¦ç”¨ï¼Œä¿æŒç°æœ‰é…ç½®ç‚¹ã€‚")

    adaptive_time = time.time() - adaptive_start_time
    print(f"\n--- âœ… è‡ªé€‚åº”è®­ç»ƒå®Œæˆï¼Œè€—æ—¶ {adaptive_time/60:.2f} åˆ† ---")

    adaptive_summary = {
        "final_mre": history_mre[-1] if history_mre else None,
        "best_mre": float(np.min(history_mre)) if history_mre else None,
        "epochs": total_epochs_trained,
        "time_seconds": adaptive_time,
    }

    # åŸºçº¿å¯¹æ¯”
    baseline_history = None
    baseline_summary = None
    baseline_time = None
    if enable_baseline:
        print("\n--- ğŸš€ è®­ç»ƒåŸºçº¿ PINN (å›ºå®šé‡‡æ ·) ---")
        baseline_start_time = time.time()
        adaptive_training_points = pinn.data.bcs[0].points
        adaptive_training_values = np.exp(pinn.data.bcs[0].values.cpu().numpy())
        full_training_data = np.hstack([adaptive_training_points, adaptive_training_values])

        baseline = PINNModel(
            dose_data=dose_data,
            training_data=full_training_data,
            test_data=test_set,
            **model_params,
        )
        baseline_collocation = np.random.uniform(
            low=dose_data["world_min"],
            high=dose_data["world_max"],
            size=(num_collocation, 3),
        )
        if baseline.model.train_state.X_train is None:
            baseline.model.train(iterations=0)
        num_bc = baseline.data.bcs[0].points.shape[0]
        start_idx = num_bc
        end_idx = len(baseline.model.train_state.X_train) - len(baseline.data.anchors)
        baseline.model.train_state.X_train[start_idx:end_idx] = baseline_collocation
        baseline.model.train(iterations=total_epochs, display_every=detect_every)

        baseline_history = {
            "Baseline PINN": {
                "epochs": baseline.epoch_history,
                "metrics": baseline.mre_history,
            }
        }
        baseline_time = time.time() - baseline_start_time
        baseline_summary = {
            "final_mre": baseline.mre_history[-1] if baseline.mre_history else None,
            "best_mre": float(np.min(baseline.mre_history)) if baseline.mre_history else None,
            "epochs": baseline.model.train_state.step or 0,
            "time_seconds": baseline_time,
        }
        print(f"--- âœ… åŸºçº¿ PINN è®­ç»ƒå®Œæˆï¼Œè€—æ—¶ {baseline_time/60:.2f} åˆ† ---")

    # æ±‡æ€»å†å²å¹¶ç»˜å›¾
    history = {
        "Adaptive PINN": {
            "epochs": history_epochs,
            "metrics": history_mre,
            "events": important_events,
        }
    }
    if baseline_history:
        history.update(baseline_history)

    results_dir = Path(system_cfg.get("results_dir", "results"))
    results_dir.mkdir(parents=True, exist_ok=True)

    exp_name = config.get("experiment", {}).get("name", "adaptive_experiment")
    events = important_events

    # åŠ¨æ€æ–‡ä»¶åç¼€ä¸æè¿°ï¼ˆä¸ V1 ä¿æŒä¸€è‡´ï¼‰
    if file_suffix:
        suffix = file_suffix
    else:
        if enable_kriging and enable_data_injection:
            suffix = "full_adaptive"
        elif enable_kriging and not enable_data_injection:
            suffix = "kriging_only"
        elif (not enable_kriging) and enable_data_injection:
            suffix = "data_injection_only"
        else:
            suffix = "periodic_restart"

    # ä½¿ç”¨ä¸ V1 é£æ ¼ä¸€è‡´çš„ç»˜å›¾ï¼Œè¾“å‡º png/pdf
    png_path = results_dir / f"mre_comparison_{suffix}.png"
    pdf_path = results_dir / f"mre_comparison_{suffix}.pdf"
    _plot_v1_style(
        adaptive_history=history.get("Adaptive PINN"),
        baseline_history=history.get("Baseline PINN"),
        events=events,
        suffix=suffix,
        save_png=png_path,
        save_pdf=pdf_path,
    )

    md_path = results_dir / f"pinn_comparison_{suffix}.md"
    _write_comparison_markdown(
        md_path=md_path,
        exp_name=exp_name,
        suffix=suffix,
        adaptive_stats=adaptive_summary,
        baseline_stats=baseline_summary,
    )

    np.savez(
        results_dir / f"training_history_{exp_name}.npz",
        epochs=np.array(history_epochs),
        metrics=np.array(history_mre),
        events=np.array(events, dtype=object),
    )

    print(f"\nğŸ‰ å®éªŒå®Œæˆã€‚ç»“æœå·²ä¿å­˜è‡³ {results_dir}")


def _plot_v1_style(
    adaptive_history: Dict[str, Any],
    baseline_history: Dict[str, Any],
    events: List[Tuple[int, str, str]],
    suffix: str,
    save_png: Path,
    save_pdf: Path,
):
    """å¤åˆ» V1 çš„ç®€å•ç»˜å›¾é£æ ¼ï¼Œä¾¿äºå¯¹æ¯”ã€‚"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))

    # è‡ªé€‚åº”æ›²çº¿
    if adaptive_history:
        ax.plot(
            adaptive_history.get("epochs", []),
            adaptive_history.get("metrics", []),
            label="è‡ªé€‚åº”PINN",
            linewidth=2,
            alpha=0.8,
            color="blue",
        )

    # åŸºçº¿æ›²çº¿
    if baseline_history:
        ax.plot(
            baseline_history.get("epochs", []),
            baseline_history.get("metrics", []),
            label="åŸå§‹PINN (å›ºå®šé‡‡æ ·)",
            linewidth=2,
            alpha=0.8,
            color="red",
        )

    # äº‹ä»¶æ ‡æ³¨ï¼ˆä»… data_injection/kriging_resamplingï¼Œé¢œè‰²ä¸ V1 å¯¹é½ï¼›é”™å³°é«˜åº¦é¿å…é‡å ï¼‰
    if events:
        event_styles = {
            "data_injection": {"color": "green", "linestyle": "--", "alpha": 0.7},
            "kriging_resampling": {"color": "orange", "linestyle": "-.", "alpha": 0.7},
        }
        for i, (epoch, event_type, desc) in enumerate(events):
            style = event_styles.get(event_type)
            if not style:
                continue
            ax.axvline(x=epoch, **style, linewidth=2)
            y_min, y_max = ax.get_ylim()
            # é¢„è®¾å¤šä¸ªé«˜åº¦å±‚ï¼Œäº¤æ›¿ä½¿ç”¨ï¼Œé¿å…é‡å 
            levels = [0.82, 0.68, 0.54, 0.4, 0.26]
            y_pos = y_max * levels[i % len(levels)]
            ax.annotate(
                f"{desc}\n(Epoch {epoch})",
                xy=(epoch, y_pos),
                xytext=(10, 10),
                textcoords="offset points",
                bbox=dict(boxstyle="round,pad=0.3", facecolor=style["color"], alpha=0.3),
                fontsize=9,
                ha="left",
            )

        from matplotlib.lines import Line2D

        legend_elements = [
            Line2D([0], [0], color="green", linestyle="--", label="æ•°æ®æ³¨å…¥"),
            Line2D([0], [0], color="orange", linestyle="-.", label="å…‹é‡Œé‡‘é‡é‡‡æ ·"),
        ]
        second_legend = ax.legend(
            handles=legend_elements,
            loc="upper right",
            fontsize=10,
            title="é‡è¦äº‹ä»¶",
            title_fontsize=11,
        )
        ax.add_artist(second_legend)

    ax.set_xlabel("è®­ç»ƒè½®æ•° (Epochs)", fontsize=12)
    ax.set_ylabel("å¹³å‡ç›¸å¯¹è¯¯å·® (MRE)", fontsize=12)
    ax.set_title(f"PINN è®­ç»ƒè¿‡ç¨‹å¯¹æ¯” ({suffix})", fontsize=14, fontweight="bold")
    ax.legend(loc="center right", fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_yscale("log")

    save_png.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_png, dpi=300, bbox_inches="tight")
    plt.savefig(save_pdf, bbox_inches="tight")
    plt.close(fig)
