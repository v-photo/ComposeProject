# 第二章 相关理论与技术基础

本章将详细介绍支撑本文混合计算框架的三项核心技术：克里金（Kriging）空间插值方法、物理信息神经网络（Physics-Informed Neural Networks, PINN）以及基于CuPy的GPU并行计算技术。深入理解这些技术的原理、优势与局限性，是后续章节中设计、实现与评估本文所提出框架的基础。

## 2.1 克里金插值方法 (Kriging)

克里金方法是一种源于地质统计学的最优内插方法。与反距离加权等确定性插值方法不同，克里金法是一种统计性的方法，它不仅考虑了待插点与已知样本点之间的空间距离，还充分利用了所有样本点之间的空间相关性结构信息，从而能够提供"最优线性无偏估计"（Best Linear Unbiased Estimator, BLUE）。

### 2.1.1 关键概念

在深入其数学原理之前，理解以下几个地质统计学的核心概念至关重要：

*   **区域化变量 (Regionalized Variable)**：一个在空间上分布并具有一定结构性的变量。它同时具有随机变量的特性（随机性）和普通函数的特性（结构性）。辐射场中的剂量率就是一个典型的区域化变量。
*   **空间自相关性 (Spatial Autocorrelation)**：这是地统计学的基本假设，即"地理学第一定律"——相近的事物会更相似。在空间上距离较近的样本点，其属性值（如剂量率）也更相近。
*   **二阶平稳假设 (Second-order Stationarity)**：为简化计算，克里金法通常假设区域化变量满足二阶平稳。该假设包含两个方面：
    1.  变量的期望值在整个研究区域内是一个常数。
    2.  变量的协方差（或变异函数）仅依赖于两点间的相对位置（距离和方向），而与它们的绝对位置无关。

### 2.1.2 基本原理

克里金方法的核心假设是，待插点的估计值 $\hat{Z}(x_0)$ 可以表示为所有已知样本点观测值 $Z(x_i)$ 的加权线性组合：

$$
\hat{Z}(x_0) = \sum_{i=1}^{n} w_i Z(x_i)
$$

其中，$x_0$ 是待插点的位置，$x_i$ 是第 $i$ 个样本点的位置，$Z(x_i)$ 是其对应的观测值，$w_i$ 是分配给该样本点的权重。

克里金方法的目标是找到一组最优的权重 $w_i$，使得估计值满足以下两个条件：

1.  **无偏性 (Unbiasedness)**：估计值的期望等于真实值的期望，即 $E[\hat{Z}(x_0) - Z(x_0)] = 0$。这要求所有权重的和为1：
    $$
    \sum_{i=1}^{n} w_i = 1
    $$

2.  **最优性 (Optimality)**：估计方差 $Var(\hat{Z}(x_0) - Z(x_0))$ 最小。这是通过拉格朗日乘子法求解权重 $w_i$ 实现的。

### 2.1.2 变异函数 (Variogram)

要计算最优权重，首先需要一个能够量化空间数据相关性的工具，这就是**变异函数** $\gamma(h)$。它描述了空间中两点之间的差异程度随它们之间距离 $h$ 的变化关系。其计算公式为：

$$
\gamma(h) = \frac{1}{2N(h)} \sum_{i=1}^{N(h)} [Z(x_i) - Z(x_i+h)]^2
$$

其中，$N(h)$ 是距离为 $h$ 的点对数量。一个典型的理论变异函数模型（如球状模型、指数模型、高斯模型）通常包含三个重要参数：

*   **基台值 (Sill)**：$\gamma(h)$ 趋于稳定的平台值，表示变量的总方差。
*   **变程 (Range)**：当距离 $h$ 达到该值时，$\gamma(h)$ 达到基台值。超出此范围的点被认为在空间上不相关。
*   **块金值 (Nugget)**：当 $h \to 0$ 时，$\gamma(h)$ 的值。它代表了由于测量误差或微观尺度变异引起的随机性。

通过对样本数据计算实验变异函数，并拟合一个理论模型，我们就可以获得描述该数据集空间结构的关键参数，进而计算任意两点之间的协方差。

### 2.1.4 算法流程

一个完整的普通克里金插值过程通常遵循以下步骤：

1.  **数据探索性分析**：检查样本数据的分布特征、趋势和异常值。
2.  **计算实验变异函数**：根据所有样本点对，计算不同距离间隔下的半方差值，绘制实验变异函数散点图。
3.  **拟合理论变异函数模型**：选择一个合适的理论模型（如球状、指数或高斯模型），并拟合实验变异函数散点，确定基台值、变程和块金值等关键参数。
4.  **构建并求解克里金方程组**：对于每一个待插值点，利用拟合好的变异函数模型计算其与所有样本点之间，以及所有样本点彼此之间的变异函数值，构建克里金方程组。
5.  **计算插值结果与方差**：求解方程组得到最优权重，并计算出待插值点的估计值。同时，计算出该估计的克里金方差，作为其不确定性的度量。

### 2.1.5 克里金方程组

在满足无偏性约束的条件下，最小化估计方差最终会导出一个线性方程组，即**克里金方程组**。对于普通克里金（Ordinary Kriging），其矩阵形式如下：

$$
\begin{pmatrix}
\gamma(x_1, x_1) & \gamma(x_1, x_2) & \cdots & \gamma(x_1, x_n) & 1 \\
\gamma(x_2, x_1) & \gamma(x_2, x_2) & \cdots & \gamma(x_2, x_n) & 1 \\
\vdots  & \vdots  & \ddots & \vdots  & \vdots  \\
\gamma(x_n, x_1) & \gamma(x_n, x_2) & \cdots & \gamma(x_n, x_n) & 1 \\
1 & 1 & \cdots & 1 & 0
\end{pmatrix}
\begin{pmatrix}
w_1 \\
w_2 \\
\vdots \\
w_n \\
\mu
\end{pmatrix}
=
\begin{pmatrix}
\gamma(x_1, x_0) \\
\gamma(x_2, x_0) \\
\vdots \\
\gamma(x_n, x_0) \\
1
\end{pmatrix}
$$

通过求解这个方程组，即可得到每个样本点的最优权重 $w_i$ 和拉格朗日乘子 $\mu$。将权重代入公式，便可计算出待插点 $x_0$ 的估计值。同时，克里金法还能给出该估计的方差，作为预测不确定性的度量，这是其相较于确定性插值方法的一个显著优势。

在本文的研究中，克里金方法扮演了双重角色：它既是"智能模型选择器"判断数据分布均匀时直接采用的高效插值工具，也是"自适应PINN训练"中用于高效识别PINN模型残差高值区的代理模型。

### 2.1.3 计算瓶颈与GPU加速的必要性

尽管克里金方法理论优雅且预测效果好，但在处理大规模数据集时，其计算成本会变得非常高昂。其核心计算瓶颈在于求解克里金方程组时，需要计算并求逆一个 $n \times n$ 的协方差矩阵（$n$为观测点数量）。

矩阵求逆的计算复杂度通常为 $O(n^3)$，而矩阵乘法的复杂度为 $O(n^{2.37})$ 到 $O(n^3)$ 不等。这意味着，当观测点数量 $n$ 从1000增加到10000时，计算量将增加近1000倍。对于需要处理数万甚至数十万个数据点的三维场重建问题，传统的基于CPU的串行计算方法将耗费惊人的时间，完全无法满足实际应用对效率的要求。

幸运的是，克里金计算中的核心操作——大规模矩阵的构建、相乘和求逆——本质上是高度并行的。这为使用图形处理器（GPU）进行加速提供了绝佳的机会。GPU拥有数千个计算核心，能够同时执行大量的浮点运算。通过将数据和计算任务迁移到GPU上，可以实现数量级的性能提升。因此，**实现GPU加速的克里金算法**，是将其应用于大规模三维重建问题的关键前提，也是本文的一项重要技术基础。

## 2.2 物理信息神经网络 (PINN)

物理信息神经网络（Physics-Informed Neural Networks, PINN）是一种将深度学习与物理学基本定律相结合的科学机器学习方法。其核心思想在于，将待求解的偏微分方程（PDE）信息作为正则项，直接编码进神经网络的损失函数中，从而引导网络的训练过程，使其输出的解不仅能拟合已知的观测数据，更能满足潜在的物理规律。

### 2.2.1 关键概念

*   **自动微分 (Automatic Differentiation, AD)**：这是PINN能够实现的关键技术。与数值微分（有精度误差）和符号微分（可能导致表达式爆炸）不同，AD能够精确并高效地计算出复杂函数（如神经网络）的任意阶导数。在PINN中，物理残差项里对网络输出的偏导数正是通过AD计算的。
*   **配置点 (Collocation Points)**：这些是在求解域内选取的、没有真实观测数据标签的点。PINN通过在这些点上强制物理残差为零，来保证解在整个区域内的物理一致性。它们的数量和分布对PINN的训练效果至关重要。
*   **软约束 (Soft Constraint)**：PINN将物理定律作为损失函数的一部分，而不是作为绝对必须满足的"硬约束"。这意味着在优化过程中，允许解在一定程度上偏离物理定律（即物理残差不为零），只要能使总损失最小化即可。这种方式为求解复杂问题提供了更大的灵活性。
*   **逆问题 (Inverse Problem)**：除了求解PDE（正问题），PINN尤其擅长处理逆问题。例如，在损失函数中将PDE的某个未知系数（如材料导热率、流体粘度）也设为可训练参数，PINN就可以仅利用少量观测数据，同时反演出该物理参数并求解场分布。

### 2.2.2 核心思想与网络结构

一个标准的PINN通常由一个全连接的前馈神经网络（Feed-Forward Neural Network）构成。该网络的输入是时空坐标（例如 $(t, x, y, z)$），输出是该坐标对应的物理量（例如温度、压力、位移等）。

令神经网络的输出为 $\hat{u}(t, \mathbf{x}; \theta)$，其中 $\theta$ 是网络的所有可训练参数（权重和偏置）。PINN的关键创新在于其损失函数的设计。

### 2.2.3 复合损失函数

PINN的损失函数通常由两部分组成：数据驱动的损失和物理驱动的损失。

1.  **数据损失 (Data Loss, $\mathcal{L}_{data}$)**：
    这部分损失与传统的监督学习任务相同，它衡量网络预测值与真实观测数据之间的差距，通常使用均方误差（Mean Squared Error, MSE）来计算。假设我们有 $N_d$ 个带有标签的观测数据点 $\{ (t_i, \mathbf{x}_i, u_i) \}_{i=1}^{N_d}$，则数据损失为：
    $$
    \mathcal{L}_{data} = \frac{1}{N_d} \sum_{i=1}^{N_d} | \hat{u}(t_i, \mathbf{x}_i; \theta) - u_i |^2
    $$
    这部分损失确保了网络的解能够"穿过"所有已知的观测点。

2.  **物理损失 (Physics Loss, $\mathcal{L}_{phys}$)**：
    这部分是PINN的精髓。它定义了一个物理残差 $f(t, \mathbf{x})$，该残差来自于待求解的偏微分方程。例如，对于一个通用形式的PDE：
    $$
    \frac{\partial u}{\partial t} + \mathcal{N}[u] = 0, \quad (t, \mathbf{x}) \in \Omega
    $$
    其中 $\mathcal{N}[\cdot]$ 是一个非线性微分算子。我们可以定义物理残差为：
    $$
    f(t, \mathbf{x}; \theta) := \frac{\partial \hat{u}}{\partial t} + \mathcal{N}[\hat{u}]
    $$
    网络输出 $\hat{u}$ 对时空坐标的偏导数可以通过**自动微分（Automatic Differentiation, AD）**技术精确计算，这是现代深度学习框架（如PyTorch, TensorFlow）的内置核心功能。

    为了强制使这个残差在整个求解域内都趋近于零，我们在求解域 $\Omega$ 内选取大量的配置点（Collocation Points）$\{ (t_j, \mathbf{x}_j) \}_{j=1}^{N_p}$，并计算这些点上的均方物理残差：
    $$
    \mathcal{L}_{phys} = \frac{1}{N_p} \sum_{j=1}^{N_p} | f(t_j, \mathbf{x}_j; \theta) |^2
    $$
    这部分损失强制网络的解在没有观测数据的区域也必须遵守物理定律。

总损失函数是这两部分的加权和：
$$
\mathcal{L}_{total} = \lambda_{data} \mathcal{L}_{data} + \lambda_{phys} \mathcal{L}_{phys}
$$
其中 $\lambda_{data}$ 和 $\lambda_{phys}$ 是可调节的权重超参数。通过最小化这个总损失函数，PINN能够学习到一个在整个时空域内都具有物理一致性的连续解。

### 2.2.4 训练流程

一个典型的PINN模型训练流程如下：

1.  **定义网络与损失**：构建一个全连接神经网络作为PDE的解的代理模型。定义包含数据损失和物理损失的复合损失函数。
2.  **生成训练点集**：准备两类点集。一是包含真实观测值的**数据点**；二是在求解域（及边界）上随机或均匀采样生成的大量**配置点**。
3.  **迭代优化**：在每个训练迭代中：
    a.  将数据点和配置点输入网络，进行前向传播，得到预测值。
    b.  利用自动微分计算网络输出在配置点处对输入的偏导数，进而计算物理残差。
    c.  分别计算数据损失和物理损失，并加权求和得到总损失。
    d.  根据总损失，利用反向传播计算梯度。
    e.  使用优化器（如Adam）更新网络的权重和偏置。
4.  **收敛判断**：重复步骤3，直到损失函数收敛到预设的阈值以下，或达到最大迭代次数。

相较于传统的数值求解器（如有限元法），PINN的优势在于其无网格（mesh-free）的特性，以及处理高维问题和反问题（如参数反演）的灵活性。然而，其训练过程的收敛性和对配置点分布的敏感性仍是当前的研究热点。本文提出的"克里金引导的自适应训练"策略，正是为了解决配置点选取效率的问题。

## 2.3 利用CuPy实现GPU加速的克里金计算

为了克服2.1.3节中提到的克里金计算瓶颈，本研究采用基于NVIDIA CUDA平台的CuPy库，来实现对克里金核心运算的GPU加速。

**CuPy**是一个开源的、与NumPy高度兼容的数组运算库。它允许开发者用与NumPy几乎完全相同的语法，在GPU上执行大规模的数组和矩阵运算。其核心优势在于：
*   **与NumPy兼容的API**：开发者几乎不需要学习新的API，可以将已有的基于NumPy的CPU代码，通过简单的模块替换（`import numpy as np` -> `import cupy as cp`），就能迁移到GPU上运行。
*   **高效的CUDA内核**：CuPy的底层由一系列高度优化的CUDA内核实现，能够充分利用GPU的大规模并行计算能力，在矩阵乘法、元素级运算、线性代数分解（如LU分解、Cholesky分解用于求逆）等操作上获得数十倍甚至上百倍于NumPy的性能。
*   **便捷的数据传输**：CuPy提供了简单的函数（如 `cupy.asarray()` 和 `cupy.asnumpy()`）来实现CPU内存与GPU显存之间的数据拷贝。

在本研究中，GPU加速克里金的实现主要聚焦于以下几个关键步骤：
1.  **数据传输**：将观测点的坐标和值从CPU内存传输到GPU显存，构建CuPy数组。
2.  **变异函数/协方差矩阵构建**：在GPU上并行计算所有数据点对之间的距离，并根据所选的变异函数模型，高效地构建出 $n \times n$ 的协方差矩阵。
3.  **矩阵求逆与求解**：调用CuPy的线性代数模块（`cupy.linalg`），在GPU上执行高效的矩阵求逆或求解线性方程组的操作，得到克里金权重。
4.  **预测与方差计算**：在GPU上并行计算所有待预测点与已知点之间的协方差向量，并与权重矩阵相乘，得到最终的预测结果和预测方差。

通过将整个克里金计算流程置于GPU上，本研究得以将原本耗时巨大的计算过程缩短到秒级或分钟级，这不仅使得处理大规模数据成为可能，更为第三章中提出的"克里金引导的PINN自适应训练"这一创新算法提供了**高效的性能保障**。没有GPU加速，作为"代理模型"的克里金本身就会成为效率瓶颈，整个自适应框架也就失去了实际意义。

## 2.4 本章小结

本章系统地阐述了支撑本文研究工作的三大理论与技术基石。首先，我们详细介绍了传统地质统计学中的克里金插值方法，剖析了其从变异函数理论到最优线性无偏估计的完整数学原理，并指出了其在处理大规模数据时存在的 $O(n^3)$ 计算复杂度瓶颈。

随后，我们介绍了作为科学机器学习前沿方法的物理信息神经网络（PINN），阐明了其通过复合损失函数将物理偏微分方程融入神经网络训练的核心思想，并讨论了其在求解正问题与反问题上的优势与挑战。

最后，针对克里金方法的计算瓶颈问题，我们明确了利用以CuPy为代表的GPU并行计算技术进行加速的技术路线。通过将核心矩阵运算迁移至GPU执行，为克里金方法在后续框架中的高效应用扫除了性能障碍。

综上，本章不仅各自独立地介绍了三项关键技术，更重要的是揭示了它们之间的内在联系与互补性，共同构成了下一章设计的双层自适应混合框架的理论与技术基础。 